"""
Gestionnaire de processus multiples pour l'analyzer.
Permet d'exÃ©cuter plusieurs stratÃ©gies en parallÃ¨le sur diffÃ©rents cÅ“urs CPU.
"""
import logging
import multiprocessing as mp
import os
import sys
import time
import signal
import threading
from typing import Dict, List, Any, Optional, Callable
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import queue
from functools import partial

# Ajouter le rÃ©pertoire parent au path pour les imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from shared.src.config import SYMBOLS
from shared.src.schemas import StrategySignal

from analyzer.src.strategy_loader import StrategyLoader, get_strategy_loader
from analyzer.src.redis_subscriber import RedisSubscriber

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('analyzer.log')
    ]
)
logger = logging.getLogger(__name__)

class AnalyzerManager:
    """
    Gestionnaire de processus pour l'analyzer.
    Distribue l'analyse des donnÃ©es de marchÃ© sur plusieurs processus/threads.
    """
    
    def __init__(self, symbols: List[str] = None, max_workers: int = None, use_threads: bool = False):
        """
        Initialise le gestionnaire d'analyse.
        
        Args:
            symbols: Liste des symboles Ã  analyser
            max_workers: Nombre maximum de workers (processus/threads)
            use_threads: Utiliser des threads au lieu de processus
        """
        self.symbols = symbols or SYMBOLS
        if max_workers is None:
            max_workers = max(1, int(mp.cpu_count() * 0.75))
        self.max_workers = max_workers
        self.use_threads = use_threads

        # Regrouper les symboles par worker pour rÃ©duire la surcharge
        symbols_per_worker = max(1, len(self.symbols) // self.max_workers)
        self.symbol_groups = [
            self.symbols[i:i+symbols_per_worker] 
            for i in range(0, len(self.symbols), symbols_per_worker)
        ]
    
        # Ajuster le nombre de workers en fonction des groupes
        self.max_workers = min(self.max_workers, len(self.symbol_groups))
        
        # File d'attente de donnÃ©es Ã  analyser
        self.data_queue = mp.Queue() if not use_threads else queue.Queue()
        
        # File d'attente de signaux gÃ©nÃ©rÃ©s
        self.signal_queue = mp.Queue() if not use_threads else queue.Queue()
        
        # CrÃ©er le chargeur de stratÃ©gies
        self.strategy_loader = get_strategy_loader()
        
        # Ã‰vÃ©nement d'arrÃªt
        self.stop_event = mp.Event() if not use_threads else threading.Event()
        
        # Subscriber Redis
        self.redis_subscriber = RedisSubscriber(symbols=self.symbols)
        
        # Pool de workers
        self.executor = None
        
        logger.info(f"âœ… AnalyzerManager initialisÃ© avec {self.max_workers} workers "
                   f"({'threads' if use_threads else 'processus'}) pour {len(self.symbols)} symboles")
    
    def _worker_analyze(self, data: Dict[str, Any]) -> List[StrategySignal]:
        """
        Fonction de worker qui analyse les donnÃ©es de marchÃ©.
        
        Args:
            data: DonnÃ©es de marchÃ© Ã  analyser
            
        Returns:
            Liste des signaux gÃ©nÃ©rÃ©s
        """
        try:
            # RÃ©cupÃ©rer le chargeur de stratÃ©gies (local Ã  chaque processus)
            strategy_loader = get_strategy_loader()
            
            # Traiter les donnÃ©es avec toutes les stratÃ©gies
            signals = strategy_loader.process_market_data(data)
            
            return signals
        
        except Exception as e:
            logger.error(f"âŒ Erreur dans le worker d'analyse: {str(e)}")
            return []
    
    def _handle_market_data(self, data: Dict[str, Any]) -> None:
        """
        Callback appelÃ© pour chaque donnÃ©e de marchÃ© reÃ§ue.
        Ajoute les donnÃ©es Ã  la file d'attente pour analyse.
        
        Args:
            data: DonnÃ©es de marchÃ©
        """
        # Ajouter Ã  la file d'attente d'analyse
        self.data_queue.put(data)
    
    def _publish_signals(self, signals: List[StrategySignal]) -> None:
        """
        Publie les signaux gÃ©nÃ©rÃ©s sur Redis.
        
        Args:
            signals: Liste des signaux Ã  publier
        """
        if not signals:
            return
        
        for signal in signals:
            self.redis_subscriber.publish_signal(signal)
    
    def _process_data_queue(self) -> None:
        """
        Processus/thread qui traite la file d'attente de donnÃ©es et soumet les tÃ¢ches aux workers.
        """
        logger.info("DÃ©marrage du processeur de file d'attente de donnÃ©es")
        
        # Utiliser ProcessPoolExecutor pour les processus ou ThreadPoolExecutor pour les threads
        executor_class = ThreadPoolExecutor if self.use_threads else ProcessPoolExecutor
        
        with executor_class(max_workers=self.max_workers) as executor:
            self.executor = executor
            
            while not self.stop_event.is_set():
                try:
                    # Ne pas bloquer indÃ©finiment pour pouvoir vÃ©rifier stop_event
                    try:
                        # RÃ©cupÃ©rer les donnÃ©es avec timeout
                        data = self.data_queue.get(timeout=0.1)
                    except (queue.Empty, mp.queues.Empty):
                        continue
                    
                    # Ne traiter que les chandeliers fermÃ©s
                    if not data.get('is_closed', False):
                        continue
                    
                    # Soumettre la tÃ¢che Ã  un worker
                    future = executor.submit(self._worker_analyze, data)
                    
                    # Ajouter un callback pour traiter les rÃ©sultats
                    future.add_done_callback(
                        lambda f: self._publish_signals(f.result())
                    )
                
                except Exception as e:
                    logger.error(f"âŒ Erreur dans le processeur de file d'attente: {str(e)}")
                    time.sleep(0.1)  # Pause pour Ã©viter une boucle d'erreur infinie
        
        logger.info("Processeur de file d'attente de donnÃ©es arrÃªtÃ©")
    
    def start(self) -> None:
        """
        DÃ©marre le gestionnaire d'analyse.
        """
        logger.info("ðŸš€ DÃ©marrage du gestionnaire d'analyse...")
        
        # RÃ©initialiser l'Ã©vÃ©nement d'arrÃªt
        self.stop_event.clear()
        
        # DÃ©marrer le subscriber Redis
        self.redis_subscriber.start_listening(self._handle_market_data)
        
        # DÃ©marrer le processus/thread de traitement de file d'attente
        if self.use_threads:
            import threading
            self.queue_processor = threading.Thread(
                target=self._process_data_queue,
                daemon=True
            )
        else:
            self.queue_processor = mp.Process(
                target=self._process_data_queue,
                daemon=True
            )
        
        self.queue_processor.start()
        logger.info("âœ… Gestionnaire d'analyse dÃ©marrÃ©")
    
    def stop(self) -> None:
        """
        ArrÃªte le gestionnaire d'analyse.
        """
        logger.info("ArrÃªt du gestionnaire d'analyse...")
        
        # Signaler l'arrÃªt
        self.stop_event.set()
        
        # Attendre que le processeur de file d'attente se termine
        if self.queue_processor.is_alive():
            if self.use_threads:
                self.queue_processor.join(timeout=5.0)
            else:
                self.queue_processor.join(timeout=5.0)
                if self.queue_processor.is_alive():
                    self.queue_processor.terminate()
            
            logger.info("Processeur de file d'attente arrÃªtÃ©")
        
        # ArrÃªter le subscriber Redis
        self.redis_subscriber.stop()
        
        # Vider les files d'attente
        while not self.data_queue.empty():
            try:
                self.data_queue.get_nowait()
            except (queue.Empty, mp.queues.Empty):
                break
        
        while not self.signal_queue.empty():
            try:
                self.signal_queue.get_nowait()
            except (queue.Empty, mp.queues.Empty):
                break
        
        logger.info("âœ… Gestionnaire d'analyse arrÃªtÃ©")

# Point d'entrÃ©e pour exÃ©cution directe
if __name__ == "__main__":
    try:
        # Configurer le gestionnaire de signaux pour l'arrÃªt propre
        stop_event = mp.Event()
        
        def signal_handler(sig, frame):
            logger.info(f"Signal {sig} reÃ§u, arrÃªt en cours...")
            stop_event.set()
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # CrÃ©er et dÃ©marrer le gestionnaire d'analyse
        manager = AnalyzerManager()
        manager.start()
        
        # Attendre le signal d'arrÃªt
        while not stop_event.is_set():
            time.sleep(1.0)
        
        # ArrÃªter le gestionnaire
        manager.stop()
        logger.info("Fin du programme")
        
    except KeyboardInterrupt:
        logger.info("Programme interrompu par l'utilisateur")
    except Exception as e:
        logger.error(f"Erreur critique: {str(e)}")