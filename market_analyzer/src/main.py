"""
Market Analyzer Service - Point d'entr√©e principal
Service qui calcule TOUS les indicateurs techniques √† partir des donn√©es OHLCV.
Architecture propre : Gateway ‚Üí market_data ‚Üí Market Analyzer ‚Üí analyzer_data
"""

import asyncio
import logging
import signal
import sys
import os
import time
from aiohttp import web

# Ajouter les chemins pour les imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from market_analyzer.src.data_listener import DataListener
from shared.src.config import SYMBOLS

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('market_analyzer.log')
    ]
)
logger = logging.getLogger("market_analyzer")

# Variables globales
data_listener = None
running = True
start_time = time.time()

# Routes pour l'API de diagnostic
routes = web.RouteTableDef()

@routes.get('/health')
async def health_check(request):
    """Point de terminaison sant√© du service."""
    uptime = time.time() - start_time
    return web.json_response({
        "status": "ok",
        "timestamp": time.time(),
        "uptime": uptime,
        "service": "market_analyzer",
        "mode": "active" if running else "stopping",
        "symbols": SYMBOLS,
        "architecture": "clean_calculation_engine"
    })

@routes.get('/stats')
async def get_stats(request):
    """Statistiques du Market Analyzer."""
    global data_listener
    
    if data_listener:
        stats = await data_listener.get_stats()
        return web.json_response(stats)
    else:
        return web.json_response({
            "error": "DataListener not initialized",
            "status": "not_running"
        }, status=503)

@routes.post('/process-historical')
async def process_historical(request):
    """API pour traiter les donn√©es historiques."""
    global data_listener
    
    if not data_listener:
        return web.json_response({
            "error": "DataListener not initialized"
        }, status=503)
    
    try:
        # Parser les param√®tres
        data = await request.json() if request.content_type == 'application/json' else {}
        symbol = data.get('symbol')
        timeframe = data.get('timeframe')
        limit = data.get('limit', 1000)
        
        # Lancer le traitement optimis√© en arri√®re-plan
        asyncio.create_task(
            data_listener.process_historical_optimized(symbol, timeframe, limit)
        )
        
        return web.json_response({
            "status": "started",
            "message": f"Traitement historique lanc√© (limit: {limit})",
            "symbol": symbol,
            "timeframe": timeframe
        })
        
    except Exception as e:
        return web.json_response({
            "error": f"Erreur lancement traitement: {e}"
        }, status=500)

@routes.get('/coverage')
async def get_coverage(request):
    """Analyse de couverture des donn√©es."""
    global data_listener
    
    if not data_listener:
        return web.json_response({
            "error": "DataListener not initialized"
        }, status=503)
    
    try:
        # Statistiques par symbole/timeframe
        coverage_query = """
            SELECT 
                md.symbol,
                md.timeframe,
                COUNT(md.*) as market_data_count,
                COUNT(ad.*) as analyzer_data_count,
                ROUND((COUNT(ad.*)::FLOAT / COUNT(md.*)) * 100, 2) as coverage_percent
            FROM market_data md
            LEFT JOIN analyzer_data ad ON (
                md.symbol = ad.symbol AND 
                md.timeframe = ad.timeframe AND 
                md.time = ad.time
            )
            GROUP BY md.symbol, md.timeframe
            ORDER BY md.symbol, md.timeframe
        """
        
        async with data_listener.db_pool.acquire() as conn:
            rows = await conn.fetch(coverage_query)
            
        coverage_data = []
        for row in rows:
            coverage_data.append({
                'symbol': row['symbol'],
                'timeframe': row['timeframe'],
                'market_data_count': row['market_data_count'],
                'analyzer_data_count': row['analyzer_data_count'],
                'coverage_percent': float(row['coverage_percent']),
                'missing_count': row['market_data_count'] - row['analyzer_data_count']
            })
        
        return web.json_response({
            "coverage_by_asset": coverage_data,
            "total_assets": len(set(row['symbol'] for row in coverage_data)),
            "total_timeframes": len(set(row['timeframe'] for row in coverage_data))
        })
        
    except Exception as e:
        return web.json_response({
            "error": f"Erreur analyse couverture: {e}"
        }, status=500)

async def start_http_server():
    """D√©marre le serveur HTTP pour l'API."""
    app = web.Application()
    app.add_routes(routes)
    
    runner = web.AppRunner(app)
    await runner.setup()
    
    # Port 5020 pour le Market Analyzer
    site = web.TCPSite(runner, '0.0.0.0', 5020)
    await site.start()
    
    logger.info("‚úÖ API HTTP d√©marr√©e sur le port 5020")
    return runner

async def shutdown(signal_type, loop):
    """G√®re l'arr√™t propre du service."""
    global running, data_listener
    
    logger.info(f"Signal {signal_type.name} re√ßu, arr√™t en cours...")
    running = False
    
    # Arr√™ter le DataListener
    if data_listener:
        await data_listener.stop()
    
    # Arr√™ter la boucle asyncio
    loop.stop()
    
    logger.info("Market Analyzer arr√™t√© proprement")

async def main():
    """Fonction principale du Market Analyzer."""
    global data_listener
    
    logger.info("üöÄ D√©marrage du Market Analyzer Service")
    logger.info("üéØ Architecture: Calcul TOUS les indicateurs depuis market_data")
    logger.info(f"üìä Symboles surveill√©s: {', '.join(SYMBOLS)}")
    
    # D√©marrer le serveur HTTP
    http_runner = await start_http_server()
    
    try:
        # Initialiser le DataListener
        data_listener = DataListener()
        await data_listener.initialize()
        
        logger.info("‚úÖ Market Analyzer initialis√©")
        
        # D√©marrer l'√©coute temps r√©el IMM√âDIATEMENT (non-bloquant)
        logger.info("üéß D√©marrage de l'√©coute temps r√©el...")
        listening_task = asyncio.create_task(data_listener.start_listening())
        
        # Proposer de traiter l'historique en parall√®le
        logger.info("üîç V√©rification de la couverture des donn√©es...")
        stats = await data_listener.get_stats()
        
        if stats['missing_analyses'] > 0:
            logger.info(f"‚ö†Ô∏è {stats['missing_analyses']} donn√©es non analys√©es d√©tect√©es")
            logger.info("üí° D√©marrage du traitement historique automatique...")
            
            # Utiliser la m√©thode optimis√©e qui traite par symbole et dans l'ordre
            await data_listener.process_historical_optimized(limit=1000000)
        else:
            logger.info("‚úÖ Toutes les donn√©es sont analys√©es")
        
        # Afficher les statistiques finales
        final_stats = await data_listener.get_stats()
        logger.info(f"üìä Couverture: {final_stats['coverage_percent']}% ({final_stats['total_analyzer_data']}/{final_stats['total_market_data']})")
        
        # Attendre que l'√©coute temps r√©el continue
        logger.info("‚úÖ Traitement historique termin√© - √©coute temps r√©el active")
        await listening_task
        
    except Exception as e:
        logger.error(f"‚ùå Erreur critique: {e}")
    finally:
        if data_listener:
            await data_listener.stop()
        
        # Arr√™ter le serveur HTTP
        await http_runner.cleanup()
        
        logger.info("Market Analyzer termin√©")

if __name__ == "__main__":
    # Obtenir la boucle asyncio
    loop = asyncio.get_event_loop()
    
    # Configurer les gestionnaires de signaux
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(
            sig, 
            lambda s=sig: asyncio.create_task(shutdown(s, loop))
        )
    
    try:
        # Ex√©cuter la fonction principale
        loop.run_until_complete(main())
    except KeyboardInterrupt:
        logger.info("Interruption clavier d√©tect√©e")
    finally:
        # Fermer la boucle asyncio
        loop.close()
        logger.info("Boucle asyncio ferm√©e")