"""
Module optimis√© pour la gestion du pool de connexions √† la base de donn√©es.
Am√©liore les performances et la r√©silience en cas d'erreurs de connexion.
"""
import logging
import time
import random
import threading
import queue
from typing import Optional, Any, Dict, Union, List, Tuple
from contextlib import contextmanager

import psycopg2
from psycopg2 import pool, extensions, extras
from psycopg2.extras import RealDictCursor, DictCursor

# Importer la configuration
from shared.src.config import get_db_url, DB_MIN_CONNECTIONS, DB_MAX_CONNECTIONS
# Ajouter ce code apr√®s les imports dans db_pool.py
# Compatibilit√© pour diff√©rentes versions de psycopg2
if not hasattr(psycopg2.extensions, 'STATUS_READY'):
    psycopg2.extensions.STATUS_READY = 0  # pas de transaction en cours
    
if not hasattr(psycopg2.extensions, 'STATUS_INTRANS'):
    psycopg2.extensions.STATUS_INTRANS = 1  # transaction en cours
    
if not hasattr(psycopg2.extensions, 'STATUS_INERROR'):
    psycopg2.extensions.STATUS_INERROR = 2  # erreur dans la transaction

# Configuration du logging
logger = logging.getLogger(__name__)

# Augmenter les valeurs par d√©faut pour plus de r√©silience
DEFAULT_MAX_RETRIES = 5
DEFAULT_RETRY_DELAY = 0.5
DEFAULT_IDLE_TIMEOUT = 600  # 10 minutes avant de fermer les connexions inactives

class DBMetrics:
    """Classe pour collecter des m√©triques sur l'utilisation de la base de donn√©es."""
    
    def __init__(self):
        """Initialise les m√©triques."""
        self.query_count = 0
        self.transaction_count = 0
        self.error_count = 0
        self.total_duration = 0.0
        self.max_duration = 0.0
        self.last_error = None
        self.last_error_time = None
        self.last_query_time = None
        self.slow_queries = []  # Liste des 10 requ√™tes les plus lentes
        self.query_types = {}   # Compteur par type de requ√™te
        
        # Protection thread
        self._lock = threading.RLock()
    
    def record_query(self, duration: float, query_type: str = None, query_text: str = None):
        """
        Enregistre une requ√™te ex√©cut√©e.
        
        Args:
            duration: Dur√©e d'ex√©cution en secondes
            query_type: Type de requ√™te (SELECT, INSERT, etc.)
            query_text: Texte de la requ√™te (pour debug)
        """
        with self._lock:
            self.query_count += 1
            self.total_duration += duration
            self.max_duration = max(self.max_duration, duration)
            self.last_query_time = time.time()
            
            # Enregistrer par type de requ√™te
            if query_type:
                self.query_types[query_type] = self.query_types.get(query_type, 0) + 1
            
            # Enregistrer les requ√™tes lentes
            if duration > 0.1:  # 100ms
                query_info = {
                    'duration': duration,
                    'time': self.last_query_time,
                    'type': query_type,
                    'query': query_text[:200] if query_text else None
                }
                
                # Ins√©rer la requ√™te lente de mani√®re tri√©e
                if not self.slow_queries or duration > self.slow_queries[-1]['duration']:
                    self.slow_queries.append(query_info)
                    self.slow_queries.sort(key=lambda x: x['duration'], reverse=True)
                    
                    # Garder seulement les 10 plus lentes
                    if len(self.slow_queries) > 10:
                        self.slow_queries.pop()
    
    def record_transaction(self):
        """Enregistre une transaction ex√©cut√©e."""
        with self._lock:
            self.transaction_count += 1
    
    def record_error(self, error: Exception, query_text: str = None):
        """
        Enregistre une erreur de base de donn√©es.
        
        Args:
            error: L'exception lev√©e
            query_text: Texte de la requ√™te qui a √©chou√©
        """
        with self._lock:
            self.error_count += 1
            self.last_error = str(error)
            self.last_error_time = time.time()
            
            # Enregistrer le contexte de l'erreur
            if query_text:
                self.last_error = f"{self.last_error} (Query: {query_text[:200]})"
    
    def get_stats(self) -> Dict[str, Any]:
        """
        R√©cup√®re les statistiques d'utilisation.
        
        Returns:
            Dictionnaire des statistiques
        """
        with self._lock:
            stats = {
                "query_count": self.query_count,
                "transaction_count": self.transaction_count,
                "error_count": self.error_count,
                "avg_duration": self.total_duration / max(1, self.query_count),
                "max_duration": self.max_duration,
                "last_error": self.last_error,
                "last_error_time": self.last_error_time,
                "last_query_time": self.last_query_time,
                "query_types": self.query_types,
                "slow_queries": self.slow_queries[:5]  # Top 5 des requ√™tes lentes
            }
            return stats
    
    def reset(self):
        """R√©initialise les m√©triques."""
        with self._lock:
            self.query_count = 0
            self.transaction_count = 0
            self.error_count = 0
            self.total_duration = 0.0
            # Ne pas r√©initialiser max_duration, last_error, last_query_time pour l'historique
            self.query_types = {}
            # Garder les requ√™tes lentes pour l'historique

class ConnectionWrapper:
    """
    Wrapper autour d'une connexion pour suivre son utilisation.
    """
    def __init__(self, connection, pool):
        self.connection = connection
        self.pool = pool
        self.last_used = time.time()
        self.created = time.time()
        self.usage_count = 0
        self.transaction_count = 0
        self.in_use = False
        self.idle_timeout = DEFAULT_IDLE_TIMEOUT
    
    def check_health(self) -> bool:
        """
        V√©rifie si la connexion est toujours valide.
        
        Returns:
            True si la connexion est saine, False sinon
        """
        try:
            if self.connection.closed:
                return False
                
            # V√©rifier si la connexion n'est pas trop vieille ou n'a pas √©t√© utilis√©e depuis trop longtemps
            current_time = time.time()
            if (current_time - self.created > 3600) or (not self.in_use and current_time - self.last_used > self.idle_timeout):
                return False
                
            # Si pas en cours d'utilisation, tester avec un ping
            if not self.in_use:
                cursor = self.connection.cursor()
                cursor.execute("SELECT 1")
                cursor.close()
            
            return True
        except Exception:
            return False
    
    def use(self):
        """Marque la connexion comme utilis√©e."""
        self.last_used = time.time()
        self.usage_count += 1
        self.in_use = True
    
    def release(self):
        """Marque la connexion comme lib√©r√©e."""
        self.last_used = time.time()
        self.in_use = False
    
    def begin_transaction(self):
        """Marque le d√©but d'une transaction."""
        self.transaction_count += 1
    
    def close(self):
        """Ferme la connexion."""
        if not self.connection.closed:
            self.connection.close()

class AdvancedConnectionPool:
    """
    Pool de connexions avanc√© avec gestion des erreurs et des reconnnexions.
    """
    def __init__(self, min_connections: int, max_connections: int, dsn: str):
        self.min_connections = min_connections
        self.max_connections = max_connections
        self.dsn = dsn
        
        # Cr√©er un pool pour les connexions disponibles
        self.available_connections = queue.Queue(maxsize=max_connections)
        
        # Dictionnaire des connexions en cours d'utilisation
        self.in_use_connections = {}
        
        # Verrou pour l'acc√®s au pool
        self.lock = threading.RLock()
        
        # Compteur de connexions
        self.connection_count = 0
        
        # Initialiser le pool avec les connexions minimales
        self._initialize_pool()
        
        # Thread de surveillance
        self._start_monitoring_thread()
    
    def _initialize_pool(self):
        """Initialise le pool avec les connexions minimales."""
        with self.lock:
            for _ in range(self.min_connections):
                try:
                    conn = self._create_connection()
                    self.available_connections.put(conn)
                    self.connection_count += 1
                except Exception as e:
                    logger.error(f"Erreur lors de l'initialisation du pool: {str(e)}")
    
    def _create_connection(self) -> ConnectionWrapper:
        """
        Cr√©e une nouvelle connexion.
        
        Returns:
            ConnectionWrapper contenant la connexion
        """
        try:
            connection = psycopg2.connect(dsn=self.dsn)
            connection.autocommit = True
            return ConnectionWrapper(connection, self)
        except Exception as e:
            logger.error(f"Erreur lors de la cr√©ation d'une connexion: {str(e)}")
            raise
    
    def _start_monitoring_thread(self):
        """D√©marre un thread pour nettoyer les connexions inactives."""
        def monitor_connections():
            while True:
                try:
                    # V√©rifier toutes les minutes
                    time.sleep(60)
                    self._cleanup_connections()
                except Exception as e:
                    logger.error(f"Erreur dans le thread de surveillance: {str(e)}")
        
        thread = threading.Thread(target=monitor_connections, daemon=True)
        thread.start()
    
    def _cleanup_connections(self):
        """Nettoie les connexions inactives ou invalides."""
        with self.lock:
            # R√©cup√©rer toutes les connexions disponibles
            available_connections = []
            while not self.available_connections.empty():
                try:
                    conn = self.available_connections.get_nowait()
                    available_connections.append(conn)
                except queue.Empty:
                    break
            
            # V√©rifier et remettre les connexions valides dans le pool
            for conn in available_connections:
                if conn.check_health():
                    self.available_connections.put(conn)
                else:
                    logger.info(f"Fermeture d'une connexion inactive (utilis√©e {conn.usage_count} fois)")
                    conn.close()
                    self.connection_count -= 1
            
            # Cr√©er de nouvelles connexions si n√©cessaire
            while self.connection_count < self.min_connections:
                try:
                    conn = self._create_connection()
                    self.available_connections.put(conn)
                    self.connection_count += 1
                    logger.info("Cr√©ation d'une nouvelle connexion pour maintenir le minimum")
                except Exception as e:
                    logger.error(f"Impossible de cr√©er une connexion: {str(e)}")
                    break
    
    def getconn(self, timeout: float = 30.0) -> ConnectionWrapper:
        """
        Obtient une connexion du pool.
        
        Args:
            timeout: Timeout en secondes
            
        Returns:
            ConnectionWrapper contenant la connexion
            
        Raises:
            queue.Empty: Si aucune connexion n'est disponible dans le d√©lai imparti
        """
        # Essayer d'obtenir une connexion existante
        try:
            conn = self.available_connections.get(timeout=timeout)
            
            # V√©rifier si la connexion est valide
            if not conn.check_health():
                logger.info("Connexion invalide r√©cup√©r√©e du pool, cr√©ation d'une nouvelle")
                conn.close()
                self.connection_count -= 1
                conn = self._create_connection()
                self.connection_count += 1
            
            # Marquer la connexion comme utilis√©e
            conn.use()
            
            # Enregistrer la connexion comme en cours d'utilisation
            with self.lock:
                self.in_use_connections[id(conn)] = conn
            
            return conn
            
        except queue.Empty:
            # Aucune connexion disponible, en cr√©er une nouvelle si possible
            with self.lock:
                if self.connection_count < self.max_connections:
                    try:
                        conn = self._create_connection()
                        conn.use()
                        self.connection_count += 1
                        self.in_use_connections[id(conn)] = conn
                        return conn
                    except Exception as e:
                        logger.error(f"Impossible de cr√©er une nouvelle connexion: {str(e)}")
                        raise
            
            # Toutes les connexions sont utilis√©es et le maximum est atteint
            logger.error(f"Pool de connexions √©puis√© ({self.connection_count}/{self.max_connections})")
            raise queue.Empty("Connection pool exhausted")
    
    def putconn(self, conn: ConnectionWrapper):
        """
        Remet une connexion dans le pool.
        
        Args:
            conn: Connexion √† remettre dans le pool
        """
        # V√©rifier si la connexion est valide
        if not conn.check_health():
            with self.lock:
                # Fermer la connexion invalide
                conn.close()
                
                # Retirer de la liste des connexions en cours d'utilisation
                self.in_use_connections.pop(id(conn), None)
                
                # D√©cr√©menter le compteur
                self.connection_count -= 1
                
                logger.info("Connexion invalide ferm√©e lors de sa lib√©ration")
            return
        
        # S'assurer que autocommit est activ√©
        if not conn.connection.autocommit:
            # V√©rifier s'il y a une transaction active et la rollback
            tx_status = conn.connection.get_transaction_status()
            if tx_status != 0:  # 0 = IDLE/READY (pas de transaction)
                conn.connection.rollback()
                logger.debug("Transaction nettoy√©e lors de la lib√©ration")
            
            # Remettre autocommit √† True
            conn.connection.autocommit = True
        
        # Marquer la connexion comme lib√©r√©e
        conn.release()
        
        # Retirer de la liste des connexions en cours d'utilisation
        with self.lock:
            self.in_use_connections.pop(id(conn), None)
        
        # Remettre la connexion dans le pool
        try:
            self.available_connections.put_nowait(conn)
        except queue.Full:
            # Si le pool est plein, fermer la connexion
            conn.close()
            with self.lock:
                self.connection_count -= 1
            logger.info("Connexion ferm√©e car le pool est plein")
    
    def closeall(self):
        """Ferme toutes les connexions du pool."""
        # Fermer les connexions disponibles
        while not self.available_connections.empty():
            try:
                conn = self.available_connections.get_nowait()
                conn.close()
            except queue.Empty:
                break
        
        # Fermer les connexions en cours d'utilisation
        with self.lock:
            for conn_id, conn in list(self.in_use_connections.items()):
                conn.close()
            
            # R√©initialiser les compteurs
            self.in_use_connections = {}
            self.connection_count = 0
        
        logger.info("Toutes les connexions ferm√©es")
    
    def get_stats(self) -> Dict[str, Any]:
        """
        R√©cup√®re des statistiques sur le pool.
        
        Returns:
            Dictionnaire des statistiques
        """
        with self.lock:
            available_count = self.available_connections.qsize()
            in_use_count = len(self.in_use_connections)
            
            # Calculer des statistiques d'utilisation
            usage_counts = [conn.usage_count for conn in self.in_use_connections.values()]
            avg_usage = sum(usage_counts) / max(1, len(usage_counts)) if usage_counts else 0
            
            stats = {
                "total_connections": self.connection_count,
                "available_connections": available_count,
                "in_use_connections": in_use_count,
                "min_connections": self.min_connections,
                "max_connections": self.max_connections,
                "usage_percent": (self.connection_count / self.max_connections) * 100 if self.max_connections > 0 else 0,
                "avg_usage_count": avg_usage
            }
            
            return stats

class DBConnectionPool:
    """Gestionnaire avanc√© de pool de connexions √† la base de donn√©es."""
    _instance = None
    
    @classmethod
    def get_instance(cls):
        """
        Obtient l'instance unique du pool.
        
        Returns:
            Instance DBConnectionPool
        """
        if cls._instance is None:
            cls._instance = DBConnectionPool()
        return cls._instance
    
    def __init__(self):
        """Initialise le pool de connexions."""
        # Cr√©er le pool avec connexion am√©lior√©e
        self.connection_pool = AdvancedConnectionPool(
            DB_MIN_CONNECTIONS,
            DB_MAX_CONNECTIONS,
            get_db_url()
        )
        
        # M√©triques
        self.metrics = DBMetrics()
        
        # D√©marrer un thread de surveillance
        self._start_monitoring_thread()
        
        logger.info(f"‚úÖ Pool de connexions initialis√© ({DB_MIN_CONNECTIONS}-{DB_MAX_CONNECTIONS})")
    
    def _start_monitoring_thread(self):
        """D√©marre un thread pour surveiller l'√©tat du pool."""
        def monitor_pool():
            while True:
                try:
                    # V√©rifier toutes les 30 minutes
                    time.sleep(1800)
                    
                    # R√©cup√©rer les statistiques
                    pool_stats = self.connection_pool.get_stats()
                    db_stats = self.metrics.get_stats()
                    
                    # Logguer les statistiques
                    logger.info(f"üìä DB Pool: {pool_stats['in_use_connections']}/{pool_stats['total_connections']} "
                                f"connexions utilis√©es ({pool_stats['usage_percent']:.1f}%)")
                    
                    logger.info(f"üìä DB Requ√™tes: {db_stats['query_count']} requ√™tes, "
                                f"{db_stats['transaction_count']} transactions, "
                                f"{db_stats['error_count']} erreurs, "
                                f"dur√©e moyenne {db_stats['avg_duration']:.3f}s")
                    
                    # Logguer les requ√™tes lentes si pr√©sentes
                    if db_stats['slow_queries']:
                        logger.warning(f"‚ö†Ô∏è Top requ√™tes lentes: " + 
                                      ", ".join([f"{q['type']} ({q['duration']:.3f}s)" for q in db_stats['slow_queries'][:3]]))
                    
                    # R√©initialiser certaines m√©triques
                    self.metrics.reset()
                    
                except Exception as e:
                    logger.error(f"Erreur dans le thread de surveillance du pool: {str(e)}")
        
        thread = threading.Thread(target=monitor_pool, daemon=True)
        thread.start()
    
    def get_connection(self, max_retries=DEFAULT_MAX_RETRIES, retry_delay=DEFAULT_RETRY_DELAY):
        """
        Obtient une connexion du pool avec retry et backoff exponentiel.
        
        Args:
            max_retries: Nombre maximum de tentatives
            retry_delay: D√©lai initial entre les tentatives
            
        Returns:
            Connexion √† la base de donn√©es
        """
        attempt = 0
        last_error = None
        
        while attempt <= max_retries:
            try:
                # Obtenir une connexion
                conn_wrapper = self.connection_pool.getconn()
                return conn_wrapper.connection
                
            except Exception as e:
                attempt += 1
                last_error = e
                self.metrics.record_error(e)
                
                if "connection pool exhausted" in str(e):
                    if attempt < max_retries:
                        # Calculer un d√©lai avec jitter pour √©viter la temp√™te de requ√™tes
                        wait_time = retry_delay * (2 ** attempt) + random.uniform(0, 0.1)
                        logger.warning(f"‚ö†Ô∏è Pool de connexions √©puis√© (attempt {attempt}/{max_retries}), "
                                      f"attente de {wait_time:.2f}s")
                        time.sleep(wait_time)
                        continue
                    else:
                        # Logguer des informations de diagnostic
                        logger.critical(f"üî• Pool de connexions √©puis√© apr√®s {max_retries} tentatives")
                        try:
                            pool_stats = self.connection_pool.get_stats()
                            logger.critical(f"Diagnostic: {pool_stats['in_use_connections']}/{pool_stats['total_connections']} "
                                          f"connexions utilis√©es ({pool_stats['usage_percent']:.1f}%)")
                        except:
                            pass
                
                logger.error(f"‚ùå Erreur lors de l'obtention d'une connexion: {str(e)}")
                
                if attempt >= max_retries:
                    break
                    
                # D√©lai exponentiel
                wait_time = retry_delay * (2 ** attempt) + random.uniform(0, 0.1)
                time.sleep(wait_time)
        
        logger.error(f"‚ùå √âchec apr√®s {max_retries} tentatives: {str(last_error)}")
        raise last_error
    
    def release_connection(self, conn):
        """
        Lib√®re une connexion et la remet dans le pool.
        
        Args:
            conn: Connexion √† lib√©rer
        """
        if conn is None:
            return
            
        try:
            # Trouver le wrapper associ√© √† cette connexion
            conn_wrapper = None
            
            for wrapper in self.connection_pool.in_use_connections.values():
                if wrapper.connection is conn:
                    conn_wrapper = wrapper
                    break
            
            if conn_wrapper:
                # V√©rifier si une transaction est encore en cours et la rollback
                if not conn.closed and conn.get_transaction_status() != 0:  # 0 = STATUS_READY
                    conn.rollback()
                    logger.debug("Transaction nettoy√©e lors de la lib√©ration")
                
                # Remettre autocommit √† True
                conn.autocommit = True
                
                # Rendre la connexion au pool
                self.connection_pool.putconn(conn_wrapper)
            else:
                logger.warning("Tentative de lib√©ration d'une connexion inconnue")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la lib√©ration d'une connexion: {str(e)}")
            self.metrics.record_error(e)
            
            # Essayer de fermer la connexion si possible
            try:
                if conn and not conn.closed:
                    conn.close()
            except:
                pass
    
    def close(self):
        """Ferme toutes les connexions du pool."""
        if self.connection_pool:
            self.connection_pool.closeall()
            logger.info("Pool de connexions ferm√©")
    
    def get_diagnostics(self) -> Dict[str, Any]:
        """
        R√©cup√®re des informations de diagnostic sur le pool.
        
        Returns:
            Dictionnaire d'informations de diagnostic
        """
        pool_stats = self.connection_pool.get_stats()
        db_stats = self.metrics.get_stats()
        
        return {
            "pool": pool_stats,
            "metrics": db_stats
        }

class DBContextManager:
    """Gestionnaire de contexte pour utiliser une connexion du pool."""
    
    def __init__(self, auto_transaction=True, max_retries=DEFAULT_MAX_RETRIES, cursor_factory=None):
        """
        Initialise le gestionnaire de contexte.
        
        Args:
            auto_transaction: Si True, d√©marre une transaction automatiquement
            max_retries: Nombre maximum de tentatives pour obtenir une connexion
            cursor_factory: Type de curseur √† utiliser (DictCursor, RealDictCursor, etc.)
        """
        self.pool = DBConnectionPool.get_instance()
        self.conn = None
        self.cursor = None
        self.auto_transaction = auto_transaction
        self.max_retries = max_retries
        self.cursor_factory = cursor_factory
        self.start_time = None
        self.query_type = None
        self.query_text = None
    
    def __enter__(self):
        self.start_time = time.time()
        self.conn = self.pool.get_connection(max_retries=self.max_retries)
        
        # V√©rifier et nettoyer toute transaction r√©siduelle
        if self.conn.get_transaction_status() != extensions.STATUS_READY:
            logger.debug("Transaction r√©siduelle nettoy√©e")
            self.conn.rollback()
        
        # Configurer la gestion de transaction
        if self.auto_transaction:
            self.conn.autocommit = False
        
        # Cr√©er un curseur avec le factory sp√©cifi√©
        cursor_args = {}
        if self.cursor_factory:
            cursor_args['cursor_factory'] = self.cursor_factory
        
        self.cursor = self.conn.cursor(**cursor_args)
        return self.cursor
    
    def execute(self, query, params=None):
        """
        Ex√©cute une requ√™te et enregistre son type.
        
        Args:
            query: Requ√™te SQL
            params: Param√®tres pour la requ√™te
            
        Returns:
            R√©sultat de l'ex√©cution
        """
        # D√©tecter le type de requ√™te (SELECT, INSERT, etc.)
        query_start = query.strip().upper()[:10]
        if "SELECT" in query_start:
            self.query_type = "SELECT"
        elif "INSERT" in query_start:
            self.query_type = "INSERT"
        elif "UPDATE" in query_start:
            self.query_type = "UPDATE"
        elif "DELETE" in query_start:
            self.query_type = "DELETE"
        else:
            self.query_type = "OTHER"
        
        self.query_text = query
        
        return self.cursor.execute(query, params)
    
    def commit(self):
        """Valide la transaction en cours."""
        if self.conn and not self.conn.closed:
            if self.conn.get_transaction_status() == 1:  # 1 = STATUS_INTRANS
                self.conn.commit()
                # Enregistrer la transaction dans les m√©triques
                self.pool.metrics.record_transaction()
                logger.debug("Transaction valid√©e explicitement")
            else:
                logger.debug("Aucune transaction active √† valider")

    def rollback(self):
        """Annule la transaction en cours."""
        if self.conn and not self.conn.closed:
            tx_status = self.conn.get_transaction_status()
            if tx_status in (1, 2):  # 1 = STATUS_INTRANS, 2 = STATUS_INERROR
                self.conn.rollback()
                logger.debug("Transaction annul√©e explicitement")
            else:
                logger.debug("Aucune transaction active √† annuler")
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        end_time = time.time()
        duration = end_time - self.start_time
        
        # Enregistrer l'ex√©cution dans les m√©triques
        if exc_type:
            self.pool.metrics.record_error(exc_val, self.query_text)
        else:
            self.pool.metrics.record_query(duration, self.query_type, self.query_text)
        
        try:
            # 1) fermer le curseur s'il existe encore
            if self.cursor and not self.cursor.closed:
                self.cursor.close()

            # 2) g√©rer la transaction si n√©cessaire
            if self.conn and not self.conn.closed:
                status = self.conn.get_transaction_status()
                
                if self.auto_transaction:
                    if exc_type is None:
                        # Pas d'erreur ‚Üí commit si transaction active
                        if status == extensions.STATUS_INTRANS:
                            self.conn.commit()
                            # Enregistrer la transaction dans les m√©triques
                            self.pool.metrics.record_transaction()
                            logger.debug("Transaction valid√©e automatiquement")
                    else:
                        # Erreur ‚Üí rollback si n√©cessaire
                        if status in (extensions.STATUS_INTRANS, extensions.STATUS_INERROR):
                            self.conn.rollback()
                            logger.debug(f"Transaction annul√©e automatiquement suite √† {exc_type.__name__}: {exc_val}")
                else:
                    # En mode sans auto_transaction, v√©rifier qu'aucune transaction n'est encore active
                    if status in (extensions.STATUS_INTRANS, extensions.STATUS_INERROR):
                        logger.debug("Transaction non termin√©e nettoy√©e")
                        self.conn.rollback()
        finally:
            # 3) toujours s'assurer qu'aucune transaction n'est active avant de changer autocommit
            if self.conn and not self.conn.closed:
                # V√©rifier qu'il n'y a plus de transactions actives 
                if self.conn.get_transaction_status() != extensions.STATUS_READY:
                    logger.debug("Nettoyage de transaction avant lib√©ration")
                    self.conn.rollback()
                
                # Maintenant on peut changer autocommit en toute s√©curit√©
                self.conn.autocommit = True
                self.pool.release_connection(self.conn)
            
        # Logguer les requ√™tes lentes (plus de 500ms)
        if duration > 0.5:
            logger.warning(f"‚ö†Ô∏è Requ√™te SQL lente ({self.query_type}): {duration:.3f}s")

# Helper contextmanager pour les transactions explicites
@contextmanager
def transaction(cursor_factory=None):
    """
    Gestionnaire de contexte pour ex√©cuter du code dans une transaction.
    Assure que la transaction est correctement valid√©e ou annul√©e.
    
    Args:
        cursor_factory: Type de curseur √† utiliser (DictCursor, RealDictCursor, etc.)
    
    Exemple:
        with transaction() as cursor:
            cursor.execute("INSERT INTO...")
            cursor.execute("UPDATE...")
    """
    db_ctx = None
    try:
        # Create connection with explicit transaction mode
        db_ctx = DBContextManager(auto_transaction=True, cursor_factory=cursor_factory)
        cursor = db_ctx.__enter__()
        
        # V√©rifier que la transaction est bien d√©marr√©e
        if cursor.connection.get_transaction_status() != extensions.STATUS_INTRANS:
            # S'assurer qu'aucune transaction n'est active
            if cursor.connection.get_transaction_status() != extensions.STATUS_READY:
                cursor.connection.rollback()
                logger.debug("Transaction nettoy√©e avant d√©marrage")
            
            # D√©marrer une nouvelle transaction propre
            cursor.connection.autocommit = False
        
        yield cursor
        
        # Commit changes if no exception occurred
        if cursor and cursor.connection and not cursor.connection.closed:
            cursor.connection.commit()
            logger.debug("Transaction committed")
            
    except Exception as e:
        # Rollback on exception
        logger.error(f"‚ùå Transaction error: {str(e)}")
        if cursor and cursor.connection and not cursor.connection.closed:
            cursor.connection.rollback()
            logger.debug("Transaction rolled back due to error")
        raise
    
    finally:
        # Clean up resources
        if db_ctx:
            db_ctx.__exit__(None, None, None)

# Helper pour les requ√™tes avec DictCursor
@contextmanager
def dict_cursor(auto_transaction=False):
    """
    Gestionnaire de contexte pour utiliser un DictCursor.
    
    Args:
        auto_transaction: Si True, d√©marre une transaction automatiquement
    
    Exemple:
        with dict_cursor() as cursor:
            cursor.execute("SELECT * FROM users WHERE id = %s", (user_id,))
            user = cursor.fetchone()  # Retourne un dictionnaire
    """
    db = DBContextManager(auto_transaction=auto_transaction, cursor_factory=DictCursor)
    try:
        cursor = db.__enter__()
        yield cursor
    finally:
        db.__exit__(None, None, None)

# Helper pour les requ√™tes avec RealDictCursor
@contextmanager
def real_dict_cursor(auto_transaction=False):
    """
    Gestionnaire de contexte pour utiliser un RealDictCursor.
    
    Args:
        auto_transaction: Si True, d√©marre une transaction automatiquement
    
    Exemple:
        with real_dict_cursor() as cursor:
            cursor.execute("SELECT * FROM users WHERE id = %s", (user_id,))
            user = cursor.fetchone()  # Retourne un dictionnaire avec les noms de colonnes pr√©serv√©s
    """
    db = DBContextManager(auto_transaction=auto_transaction, cursor_factory=RealDictCursor)
    try:
        cursor = db.__enter__()
        yield cursor
    finally:
        db.__exit__(None, None, None)

# Fonctions utilitaires pour les requ√™tes communes

def fetch_one(query, params=None, dict_result=True):
    """
    Ex√©cute une requ√™te et retourne une seule ligne.
    
    Args:
        query: Requ√™te SQL
        params: Param√®tres pour la requ√™te
        dict_result: Si True, retourne un dictionnaire
        
    Returns:
        Une ligne de r√©sultat ou None
    """
    cursor_factory = DictCursor if dict_result else None
    
    with DBContextManager(auto_transaction=False, cursor_factory=cursor_factory) as cursor:
        cursor.execute(query, params)
        return cursor.fetchone()

def fetch_all(query, params=None, dict_result=True):
    """
    Ex√©cute une requ√™te et retourne toutes les lignes.
    
    Args:
        query: Requ√™te SQL
        params: Param√®tres pour la requ√™te
        dict_result: Si True, retourne une liste de dictionnaires
        
    Returns:
        Liste des r√©sultats
    """
    cursor_factory = DictCursor if dict_result else None
    
    with DBContextManager(auto_transaction=False, cursor_factory=cursor_factory) as cursor:
        cursor.execute(query, params)
        return cursor.fetchall()

def execute(query, params=None, auto_transaction=True):
    """
    Ex√©cute une requ√™te sans retourner de r√©sultat.
    
    Args:
        query: Requ√™te SQL
        params: Param√®tres pour la requ√™te
        auto_transaction: Si True, d√©marre une transaction automatiquement
        
    Returns:
        Nombre de lignes affect√©es
    """
    with DBContextManager(auto_transaction=auto_transaction) as cursor:
        cursor.execute(query, params)
        return cursor.rowcount

def execute_batch(query, params_list, auto_transaction=True, page_size=100):
    """
    Ex√©cute une requ√™te en batch.
    
    Args:
        query: Requ√™te SQL
        params_list: Liste de param√®tres pour la requ√™te
        auto_transaction: Si True, d√©marre une transaction automatiquement
        page_size: Nombre d'op√©rations par page
        
    Returns:
        Nombre de lignes affect√©es
    """
    with DBContextManager(auto_transaction=auto_transaction) as cursor:
        extras.execute_batch(cursor, query, params_list, page_size=page_size)
        return cursor.rowcount

def execute_values(query, values, auto_transaction=True, page_size=100):
    """
    Ex√©cute une requ√™te INSERT avec des valeurs en masse.
    
    Args:
        query: Requ√™te SQL de base (ex: "INSERT INTO table (col1, col2) VALUES %s")
        values: Liste de tuples de valeurs
        auto_transaction: Si True, d√©marre une transaction automatiquement
        page_size: Nombre d'op√©rations par page
        
    Returns:
        Nombre de lignes affect√©es
    """
    with DBContextManager(auto_transaction=auto_transaction) as cursor:
        extras.execute_values(cursor, query, values, page_size=page_size)
        return cursor.rowcount

# Acc√®s simplifi√© aux m√©triques de la base de donn√©es
def get_db_metrics():
    """
    R√©cup√®re les m√©triques de la base de donn√©es.
    
    Returns:
        Dictionnaire des m√©triques
    """
    pool = DBConnectionPool.get_instance()
    return pool.get_diagnostics()