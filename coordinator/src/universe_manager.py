"""Universe Manager - S√©lection dynamique des cryptos √† trader"""

import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Set, Optional, Tuple
from dataclasses import dataclass, field
import numpy as np
from scipy import stats
import json

logger = logging.getLogger(__name__)

@dataclass
class PairScore:
    """Score de tradeabilit√© d'une paire"""
    symbol: str
    score: float
    atr_pct: float
    roc: float
    volume_ratio: float
    is_ranging: bool
    timestamp: datetime
    components: Dict[str, float] = field(default_factory=dict)

@dataclass
class PairState:
    """√âtat d'une paire dans le syst√®me de s√©lection"""
    symbol: str
    is_selected: bool
    score_history: List[float] = field(default_factory=list)
    last_selected: Optional[datetime] = None
    last_deselected: Optional[datetime] = None
    cooldown_until: Optional[datetime] = None
    consecutive_above_threshold: int = 0
    consecutive_below_threshold: int = 0

class UniverseManager:
    """Gestionnaire de l'univers tradable avec s√©lection dynamique"""
    
    def __init__(self, redis_client, db_pool=None, config: Optional[Dict] = None):
        self.redis = redis_client
        self.db_pool = db_pool
        self.config = config or self._default_config()
        
        # √âtat des paires
        self.pair_states: Dict[str, PairState] = {}
        self.selected_universe: Set[str] = set()
        self.core_pairs: Set[str] = set(self.config['core_pairs'])
        
        # Cache des donn√©es de march√©
        self.market_data_cache: Dict[str, Dict] = {}
        self.last_update = datetime.now()
        
        # V√©rifier le pool DB
        if not self.db_pool:
            logger.warning("Pas de pool DB fourni, utilisation de Redis uniquement")
        
        logger.info(f"UniverseManager initialis√© avec {len(self.core_pairs)} paires core")
    
    def _default_config(self) -> Dict:
        """Configuration par d√©faut"""
        return {
            # Paires toujours actives (format USDC pour Binance)
            # BTC/ETH = bases incontournables, top liquidit√©
            # SOL = Solana, tr√®s liquide, mouvements rapides
            # XRP = Ripple, √©norme volume, bonne volatilit√©
            # ADA = Cardano, stable et liquide
            # LINK = Chainlink, oracle leader, patterns fiables
            'core_pairs': ['BTCUSDC', 'ETHUSDC', 'SOLUSDC', 'XRPUSDC', 'ADAUSDC', 'LINKUSDC'],
            
            # Nombre max de satellites (en plus des core)
            'max_satellites': 6,  # 6 core + 6 satellites = 12 cryptos max

            # Seuils de score
            'score_threshold_enter': 0.2,  # Abaiss√© pour permettre plus de satellites
            'score_threshold_exit': -0.3,  # Abaiss√© aussi pour coh√©rence
            
            # Hyst√©r√©sis (nombre de p√©riodes)
            'periods_above_to_enter': 3,
            'periods_below_to_exit': 6,
            
            # Cool-down apr√®s d√©s√©lection (minutes)
            'cooldown_minutes': 45,  # Augment√© pour √©viter r√©activation trop rapide
            
            # Poids des composants du score
            'weights': {
                'atr': 0.3,
                'roc': 0.3,
                'volume': 0.15,
                'trend': 0.25  # Nouveau: bonus pour tendance directionnelle
            },
            
            # Param√®tres de calcul
            'atr_period': 14,
            'roc_period_fast': 15,
            'roc_period_slow': 30,
            'volume_period': 20,
            
            # Seuils de range
            'bb_squeeze_threshold': 0.02,  # Bollinger Band squeeze %
            'adx_range_threshold': 20,     # ADX < 20 = ranging
            
            # Hard risk (for√ßage de sortie)
            'hard_risk': {
                'enabled': True,
                'atr_spike_threshold': 0.5,  # % ATR
                'spread_multiplier': 3,      # x median spread
                'slippage_multiplier': 2     # x baseline slippage
            }
        }
    
    def update_market_data(self, symbol: str, data: Dict) -> None:
        """Met √† jour les donn√©es de march√© pour une paire"""
        self.market_data_cache[symbol] = {
            **data,
            'timestamp': datetime.now()
        }
    
    def calculate_score(self, symbol: str) -> PairScore:
        """Calcule le score de tradeabilit√© d'une paire en utilisant les donn√©es de la DB"""
        try:
            # Utiliser la DB si disponible (priorit√© car donn√©es d√©j√† calcul√©es)
            if self.db_pool:
                return self._calculate_score_from_db(symbol)
            else:
                # Fallback sur Redis/calculs manuels si pas de DB
                return self._calculate_score_from_redis(symbol)
                
        except Exception as e:
            logger.error(f"Erreur calcul score {symbol}: {e}")
            return PairScore(symbol, -1.0, 0, 0, 0, True, datetime.now())
    
    def _calculate_score_from_db(self, symbol: str) -> PairScore:
        """Calcule le score depuis analyzer_data (tout est d√©j√† calcul√©)"""
        try:
            from shared.src.db_pool import real_dict_cursor

            with real_dict_cursor() as cursor:
                # R√©cup√©rer toutes les donn√©es calcul√©es depuis analyzer_data
                query = """
                    SELECT * FROM analyzer_data
                    WHERE symbol = %s AND timeframe = '3m'
                    ORDER BY time DESC LIMIT 1
                """
                cursor.execute(query, (symbol,))
                data = cursor.fetchone()

                if not data:
                    logger.warning(f"Pas de donn√©es analyzer pour {symbol}")
                    return PairScore(symbol, -1.0, 0, 0, 0, True, datetime.now())

                # Extraire m√©triques (tout est d√©j√† calcul√© !)
                atr_pct = float(data['natr']) if data['natr'] else 0
                roc = (float(data['roc_10']) + float(data['roc_20'])) / 2 if data['roc_10'] and data['roc_20'] else 0
                volume_ratio = float(data['volume_ratio']) if data['volume_ratio'] else 1.0
                is_ranging = data['bb_squeeze'] if data['bb_squeeze'] is not None else False

                # Calculer trend_score depuis donn√©es DB
                trend_score = self._calculate_trend_score_from_db(data)

                # Population pour z-scores
                all_scores = self._get_all_scores_from_db()

                # Z-scores (normalisation relative)
                if len(all_scores) < 3:
                    # Normalisation simple si pas assez de population
                    z_atr = min(1.0, atr_pct / 2.0) if atr_pct > 0 else 0
                    z_roc = min(1.0, abs(roc) / 5.0) * (1 if roc > 0 else -1)
                    z_volume = min(2.0, volume_ratio) - 1.0
                else:
                    z_atr = self._calculate_zscore(atr_pct, [s.atr_pct for s in all_scores])
                    z_roc = self._calculate_zscore(roc, [s.roc for s in all_scores])
                    z_volume = self._calculate_zscore(volume_ratio, [s.volume_ratio for s in all_scores])

                # Score final pond√©r√©
                score = (
                    z_atr * self.config['weights']['atr'] +
                    z_roc * self.config['weights']['roc'] +
                    z_volume * self.config['weights']['volume'] +
                    trend_score * self.config['weights']['trend']
                )

                # P√©nalit√© ranging (utiliser ADX de la DB)
                if is_ranging:
                    adx = float(data['adx_14']) if data['adx_14'] else 0
                    range_penalty = self._calculate_range_penalty(adx, atr_pct)
                    score -= range_penalty

                # Bonus DB
                if data.get('confluence_score') and float(data['confluence_score']) > 70:
                    score += 0.3
                if data.get('volume_context') in ['BREAKOUT', 'PUMP_START']:
                    score += 0.2

                return PairScore(
                    symbol=symbol,
                    score=score,
                    atr_pct=atr_pct,
                    roc=roc,
                    volume_ratio=volume_ratio,
                    is_ranging=is_ranging,
                    timestamp=datetime.now(),
                    components={
                        'z_atr': z_atr,
                        'z_roc': z_roc,
                        'z_volume': z_volume,
                        'trend_bias': trend_score,
                        'market_regime': data.get('market_regime', 'UNKNOWN'),
                        'confluence_score': float(data['confluence_score']) if data.get('confluence_score') else 0
                    }
                )

        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration donn√©es DB pour {symbol}: {e}")
            return self._calculate_score_from_redis(symbol)

    def _get_all_scores_from_db(self) -> List[PairScore]:
        """R√©cup√®re les scores r√©cents de toutes les paires depuis la DB"""
        scores = []

        try:
            from shared.src.db_pool import real_dict_cursor

            with real_dict_cursor() as cursor:
                # R√©cup√©rer les donn√©es de toutes les paires des 15 derni√®res minutes
                query = """
                    SELECT DISTINCT ON (a.symbol)
                        a.symbol,
                        a.natr,
                        a.roc_10,
                        a.roc_20,
                        a.volume_ratio,
                        a.bb_squeeze,
                        a.adx_14,
                        a.trend_strength,
                        a.market_regime
                    FROM analyzer_data a
                    WHERE a.timeframe = '3m'
                    AND a.time > NOW() - INTERVAL '15 minutes'
                    ORDER BY a.symbol, a.time DESC
                """
                cursor.execute(query)
                results = cursor.fetchall()

                for data in results:
                    atr_pct = float(data['natr']) if data['natr'] else 0
                    roc = (float(data['roc_10']) + float(data['roc_20'])) / 2 if data['roc_10'] and data['roc_20'] else 0
                    volume_ratio = float(data['volume_ratio']) if data['volume_ratio'] else 1.0
                    is_ranging = data['bb_squeeze'] if data['bb_squeeze'] is not None else False

                    # Cr√©er un PairScore basique pour la normalisation
                    score = PairScore(
                        symbol=data['symbol'],
                        score=0.0,  # Sera calcul√© plus tard
                        atr_pct=atr_pct,
                        roc=roc,
                        volume_ratio=volume_ratio,
                        is_ranging=is_ranging,
                        timestamp=datetime.now()
                    )
                    scores.append(score)

        except Exception as e:
            logger.debug(f"Erreur r√©cup√©ration population DB: {e}")
            # Fallback sur cache Redis si erreur DB
            scores = self._get_all_recent_scores()

        return scores

    def _calculate_score_from_redis(self, symbol: str) -> PairScore:
        """Fallback minimal si pas de DB (ne devrait jamais arriver)"""
        logger.error(f"Pas de donn√©es DB disponibles pour {symbol} - retour score par d√©faut")
        return PairScore(symbol, -1.0, 0, 0, 0, True, datetime.now())
    
    def _calculate_zscore(self, value: float, population: List[float]) -> float:
        """Calcule le z-score d'une valeur par rapport √† la population"""
        if len(population) < 2:
            return 0.0
        
        mean = np.mean(population)
        std = np.std(population, ddof=1)  # Sample standard deviation
        
        if std == 0:
            return 0.0
        
        return (value - mean) / std

    def _calculate_range_penalty(self, adx: float, atr_pct: float) -> float:
        """Calcule la p√©nalit√© ranging bas√©e sur ADX et ATR"""
        base_penalty = 0.15

        # Multiplicateur ADX
        if adx < 10:
            adx_multiplier = 2.0
        elif adx < 15:
            adx_multiplier = 1.5
        elif adx < 20:
            adx_multiplier = 1.0
        else:
            adx_multiplier = 0.5

        # Ajustement ATR
        if atr_pct < 0.5:
            atr_adjustment = 1.5
        elif atr_pct > 2.0:
            atr_adjustment = 0.7
        else:
            atr_adjustment = 1.0

        return min(base_penalty * adx_multiplier * atr_adjustment, 0.4)

    def _get_forced_pairs(self) -> List[str]:
        """R√©cup√®re les paires forc√©es (consensus fort) non expir√©es"""
        forced_pairs = []
        current_time = time.time()

        try:
            # Chercher toutes les cl√©s forced_pair:*
            forced_keys = []
            # Redis scan pattern pour trouver les cl√©s - utiliser redis directement
            for key in self.redis.redis.scan_iter(match="forced_pair:*"):
                if isinstance(key, bytes):
                    key = key.decode('utf-8')
                forced_keys.append(key)

            for key in forced_keys:
                try:
                    forced_until_str = self.redis.get(key)
                    if forced_until_str:
                        forced_until = float(forced_until_str)
                        if current_time < forced_until:
                            # Extraire le symbole de la cl√©
                            symbol = key.replace("forced_pair:", "")
                            forced_pairs.append(symbol)
                        else:
                            # Expirer la cl√© manuellement
                            self.redis.delete(key)
                            logger.debug(f"For√ßage expir√© supprim√©: {key}")
                except Exception as e:
                    logger.error(f"Erreur traitement for√ßage {key}: {e}")

        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration paires forc√©es: {e}")

        return forced_pairs

    def _batch_calculate_scores_from_db(self, symbols: List[str]) -> Dict[str, PairScore]:
        """Calcule tous les scores depuis analyzer_data en batch"""
        scores = {}

        try:
            from shared.src.db_pool import real_dict_cursor

            with real_dict_cursor() as cursor:
                # R√©cup√©rer toutes les donn√©es calcul√©es depuis analyzer_data
                query = """
                    SELECT DISTINCT ON (symbol)
                        symbol, natr, roc_10, roc_20, volume_ratio, bb_squeeze,
                        adx_14, trend_strength, trend_angle, directional_bias,
                        market_regime, confluence_score, volume_context
                    FROM analyzer_data
                    WHERE symbol = ANY(%s) AND timeframe = '3m'
                    AND time > NOW() - INTERVAL '15 minutes'
                    ORDER BY symbol, time DESC
                """
                cursor.execute(query, (symbols,))
                results = cursor.fetchall()

                # Extraire toutes les m√©triques pour z-scores
                all_atr = [float(r['natr']) if r['natr'] else 0 for r in results]
                all_roc = [(float(r['roc_10']) + float(r['roc_20'])) / 2 if r['roc_10'] and r['roc_20'] else 0 for r in results]
                all_volume = [float(r['volume_ratio']) if r['volume_ratio'] else 1.0 for r in results]

                # Traiter chaque r√©sultat
                for i, data in enumerate(results):
                    symbol = data['symbol']
                    atr_pct = all_atr[i]
                    roc = all_roc[i]
                    volume_ratio = all_volume[i]
                    is_ranging = data['bb_squeeze'] if data['bb_squeeze'] is not None else False

                    # Z-scores
                    z_atr = self._calculate_zscore(atr_pct, all_atr)
                    z_roc = self._calculate_zscore(roc, all_roc)
                    z_volume = self._calculate_zscore(volume_ratio, all_volume)

                    # Trend score et p√©nalit√©s
                    trend_score = self._calculate_trend_score_from_db(data)

                    # Score final
                    score = (
                        z_atr * self.config['weights']['atr'] +
                        z_roc * self.config['weights']['roc'] +
                        z_volume * self.config['weights']['volume'] +
                        trend_score * self.config['weights']['trend']
                    )

                    # P√©nalit√© ranging
                    if is_ranging:
                        adx = float(data['adx_14']) if data['adx_14'] else 0
                        score -= self._calculate_range_penalty(adx, atr_pct)

                    # Bonus
                    if data.get('confluence_score') and float(data['confluence_score']) > 70:
                        score += 0.3
                    if data.get('volume_context') in ['BREAKOUT', 'PUMP_START']:
                        score += 0.2

                    scores[symbol] = PairScore(
                        symbol=symbol, score=score, atr_pct=atr_pct, roc=roc,
                        volume_ratio=volume_ratio, is_ranging=is_ranging,
                        timestamp=datetime.now(),
                        components={
                            'z_atr': z_atr, 'z_roc': z_roc, 'z_volume': z_volume,
                            'trend_bias': trend_score,
                            'market_regime': data.get('market_regime', 'UNKNOWN')
                        }
                    )

                    # Cache
                    self.market_data_cache[symbol] = {'score': scores[symbol], 'timestamp': datetime.now()}

                # Symboles manquants = score par d√©faut
                for symbol in symbols:
                    if symbol not in scores:
                        scores[symbol] = PairScore(symbol, -1.0, 0, 0, 0, True, datetime.now())

        except Exception as e:
            logger.error(f"Erreur batch calculate scores: {e}")
            # Fallback : score par d√©faut pour tous
            for symbol in symbols:
                scores[symbol] = PairScore(symbol, -1.0, 0, 0, 0, True, datetime.now())

        return scores
    
    def _calculate_trend_score_from_db(self, data: Dict) -> float:
        """Calcule le score de tendance depuis les donn√©es DB existantes"""
        trend_score = 0.0

        # ADX (d√©j√† calcul√© dans analyzer_data)
        adx = float(data['adx_14']) if data['adx_14'] else 0
        if adx > 25:
            trend_score += 0.8
        elif adx > 20:
            trend_score += 0.4

        # Trend strength
        if data['trend_strength'] == 'VERY_STRONG':
            trend_score += 0.5
        elif data['trend_strength'] == 'STRONG':
            trend_score += 0.3
        elif data['trend_strength'] == 'MODERATE':
            trend_score += 0.15

        # Trend angle (pente de la tendance)
        if data.get('trend_angle'):
            angle = float(data['trend_angle'])
            if abs(angle) > 0.5:
                trend_score += 0.3 * np.sign(angle)
            elif abs(angle) > 0.2:
                trend_score += 0.15 * np.sign(angle)

        # Directional bias
        if data.get('directional_bias') == 'BULLISH':
            trend_score += 0.2
        elif data.get('directional_bias') == 'BEARISH':
            trend_score -= 0.2

        # Market regime (avec gestion NULL)
        market_regime = data.get('market_regime')
        if market_regime in ['TRENDING_BULL', 'BREAKOUT_BULL']:
            trend_score += 0.3
        elif market_regime in ['TRENDING_BEAR', 'BREAKOUT_BEAR']:
            trend_score -= 0.3
        elif market_regime == 'TRANSITION':
            trend_score += 0.1  # L√©ger bonus pour transition
        elif market_regime == 'RANGING':
            trend_score *= 0.5  # Att√©nuer plut√¥t qu'annuler

        return max(-1, min(1, trend_score))
    
    def _get_all_recent_scores(self) -> List[PairScore]:
        """R√©cup√®re les scores r√©cents de toutes les paires"""
        scores = []
        
        # R√©cup√©rer la liste des symboles depuis Redis
        symbols_data = self.redis.get("trading:symbols")
        if not symbols_data:
            return scores
        
        symbols = json.loads(symbols_data)
        
        for symbol in symbols:
            if symbol in self.market_data_cache:
                cache_entry = self.market_data_cache[symbol]
                if (datetime.now() - cache_entry['timestamp']).seconds < 180:
                    scores.append(cache_entry.get('score'))
        
        return [s for s in scores if s is not None]
    
    def apply_hysteresis(self, symbol: str, current_score: float) -> bool:
        """Applique l'hyst√©r√©sis pour √©viter le ping-pong"""
        if symbol not in self.pair_states:
            self.pair_states[symbol] = PairState(symbol=symbol, is_selected=False)
        
        state = self.pair_states[symbol]
        
        # Ajouter le score √† l'historique
        state.score_history.append(current_score)
        if len(state.score_history) > 10:
            state.score_history.pop(0)
        
        # V√©rifier cool-down
        if state.cooldown_until and datetime.now() < state.cooldown_until:
            return False
        
        # Logique d'hyst√©r√©sis
        if not state.is_selected:
            # Pour entrer : score > seuil pendant N p√©riodes
            if current_score > self.config['score_threshold_enter']:
                state.consecutive_above_threshold += 1
                state.consecutive_below_threshold = 0
                
                if state.consecutive_above_threshold >= self.config['periods_above_to_enter']:
                    state.is_selected = True
                    state.last_selected = datetime.now()
                    state.consecutive_above_threshold = 0
                    return True
            else:
                state.consecutive_above_threshold = 0
        else:
            # Pour sortir : score < seuil pendant M p√©riodes
            if current_score < self.config['score_threshold_exit']:
                state.consecutive_below_threshold += 1
                state.consecutive_above_threshold = 0
                
                if state.consecutive_below_threshold >= self.config['periods_below_to_exit']:
                    state.is_selected = False
                    state.last_deselected = datetime.now()
                    state.cooldown_until = datetime.now() + timedelta(
                        minutes=self.config['cooldown_minutes']
                    )
                    state.consecutive_below_threshold = 0
                    return False
            else:
                state.consecutive_below_threshold = 0
        
        return state.is_selected
    
    def update_universe(self) -> Tuple[Set[str], Dict[str, PairScore]]:
        """Met √† jour l'univers tradable"""
        try:
            # R√©cup√©rer tous les symboles
            symbols_data = self.redis.get("trading:symbols")
            if not symbols_data:
                logger.warning("Pas de symboles configur√©s")
                return self.core_pairs, {}
            
            # symbols_data peut √™tre une string JSON ou d√©j√† une liste
            if isinstance(symbols_data, str):
                all_symbols = json.loads(symbols_data)
            else:
                all_symbols = symbols_data
            
            # Calculer les scores depuis analyzer_data (tout est d√©j√† calcul√©)
            if not self.db_pool:
                logger.error("Pas de DB disponible - impossible de calculer les scores")
                return self.core_pairs, {}

            scores = self._batch_calculate_scores_from_db(all_symbols)
            
            # Enregistrer l'√©tat actuel avant modification
            previous_universe = self.selected_universe.copy()
            
            # Toujours inclure les paires core (jamais retir√©es)
            selected = set(self.core_pairs)

            # Ajouter les paires forc√©es (consensus fort) non expir√©es
            forced_pairs = self._get_forced_pairs()
            for forced_symbol in forced_pairs:
                selected.add(forced_symbol)
                logger.info(f"üöÄ Paire forc√©e active: {forced_symbol}")

            # Filtrer les satellites √©ligibles avec hard_risk
            eligible_satellites = []
            for symbol, score in scores.items():
                if symbol not in self.core_pairs and score.score > -1:
                    # V√©rifier hard_risk avant hyst√©r√©sis
                    if self.check_hard_risk(symbol):
                        logger.warning(f"Paire {symbol} exclue pour hard_risk (ATR spike + spread + slippage)")
                        continue

                    # Appliquer hyst√©r√©sis
                    if self.apply_hysteresis(symbol, score.score):
                        eligible_satellites.append((symbol, score.score))
            
            # S√©lectionner les meilleurs satellites
            eligible_satellites.sort(key=lambda x: x[1], reverse=True)
            for symbol, _ in eligible_satellites[:self.config['max_satellites']]:
                selected.add(symbol)
            
            # Mettre √† jour l'univers
            self.selected_universe = selected
            self.last_update = datetime.now()
            
            # Publier dans Redis
            self.redis.set(
                "universe:selected",
                json.dumps(list(selected)),
                expiration=180  # TTL 3 minutes
            )
            
            # Log les changements (utiliser previous_universe)
            added = selected - previous_universe
            removed = previous_universe - selected
            
            if added:
                logger.info(f"Paires ajout√©es √† l'univers: {added}")
            if removed:
                logger.info(f"Paires retir√©es de l'univers: {removed}")
            
            return selected, scores
            
        except Exception as e:
            logger.error(f"Erreur update_universe: {e}")
            return self.core_pairs, {}
    
    def is_pair_tradable(self, symbol: str) -> bool:
        """V√©rifie si une paire peut ouvrir de nouvelles positions"""
        return symbol in self.selected_universe
    
    def check_hard_risk(self, symbol: str) -> bool:
        """V√©rifie les conditions de risque extr√™me"""
        if not self.config['hard_risk']['enabled']:
            return False
        
        try:
            # R√©cup√©rer les m√©triques de risque depuis Redis
            risk_key = f"risk:{symbol}"
            risk_data = self.redis.get(risk_key)
            
            if not risk_data:
                return False
            
            risk = json.loads(risk_data)
            
            # V√©rifier les conditions
            atr_spike = risk.get('atr_spike', 0) > self.config['hard_risk']['atr_spike_threshold']
            spread_high = risk.get('spread_ratio', 0) > self.config['hard_risk']['spread_multiplier']
            slippage_high = risk.get('slippage_ratio', 0) > self.config['hard_risk']['slippage_multiplier']
            
            # Toutes les conditions doivent √™tre vraies
            return atr_spike and spread_high and slippage_high
            
        except Exception as e:
            logger.error(f"Erreur check_hard_risk {symbol}: {e}")
            return False

    def get_universe_stats(self) -> Dict:
        """Retourne les statistiques de l'univers"""
        stats = {
            'selected_count': len(self.selected_universe),
            'selected_symbols': list(self.selected_universe),
            'core_pairs': list(self.core_pairs),
            'satellites': list(self.selected_universe - self.core_pairs),
            'last_update': self.last_update.isoformat() if self.last_update else None,
            'pair_states': {}
        }
        
        for symbol, state in self.pair_states.items():
            stats['pair_states'][symbol] = {
                'is_selected': state.is_selected,
                'recent_scores': state.score_history[-5:] if state.score_history else [],
                'cooldown_until': state.cooldown_until.isoformat() if state.cooldown_until else None
            }
        
        return stats
    
    def force_pair_selection(self, symbol: str, duration_minutes: int = 60) -> None:
        """Force la s√©lection d'une paire pour consensus fort"""
        # Stocker le for√ßage avec expiration
        forced_until = time.time() + (duration_minutes * 60)
        forced_key = f"forced_pair:{symbol}"
        self.redis.set(forced_key, str(forced_until), expiration=duration_minutes * 60 + 60)  # +60s marge

        # Ajouter √† l'univers actuel
        self.selected_universe.add(symbol)
        logger.info(f"Paire {symbol} forc√©e dans l'univers pour {duration_minutes} minutes (jusqu'√† {time.strftime('%H:%M:%S', time.localtime(forced_until))})")

        # Publier dans Redis avec TTL coh√©rent
        self.redis.set(
            "universe:selected",
            json.dumps(list(self.selected_universe)),
            expiration=max(300, duration_minutes * 60)  # Au moins 5min, ou la dur√©e demand√©e
        )
    
