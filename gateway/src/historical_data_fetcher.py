"""
Module de r√©cup√©ration des donn√©es historiques de Binance.
Permet d'initialiser le syst√®me avec suffisamment de donn√©es historiques.
"""
import logging
import time
from typing import List, Dict, Any
import aiohttp
from datetime import datetime, timedelta
import asyncio

# Configuration du logging
logger = logging.getLogger(__name__)

class HistoricalDataFetcher:
    """
    R√©cup√®re les donn√©es historiques de Binance pour initialiser l'Analyzer.
    """
    
    def __init__(self, kafka_producer=None):
        """
        Initialise le r√©cup√©rateur de donn√©es historiques.
        
        Args:
            kafka_producer: Producteur Kafka pour publier les donn√©es
        """
        self.kafka_producer = kafka_producer
        self.base_url = "https://api.binance.com/api/v3"
        
        # Limites de l'API
        self.rate_limit_per_second = 20
        self.last_request_time = 0
        
        # Session HTTP pour les requ√™tes
        self.session = None
        
        logger.info("‚úÖ HistoricalDataFetcher initialis√©")
    
    async def _respect_rate_limit(self):
        """
        Respecte les limites de taux de l'API Binance.
        """
        current_time = time.time()
        elapsed = current_time - self.last_request_time
        
        # S'assurer d'au moins 50ms entre les requ√™tes (20 requ√™tes/s)
        if elapsed < 0.05:
            await asyncio.sleep(0.05 - elapsed)
        
        self.last_request_time = time.time()
    
    async def _ensure_session(self):
        """
        S'assure qu'une session HTTP est disponible pour les requ√™tes.
        """
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession()
    
    async def get_klines(self, symbol: str, interval: str, limit: int = 1000, start_time: int = None) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les chandeliers historiques de Binance.
        
        Args:
            symbol: Symbole (ex: 'BTCUSDC')
            interval: Intervalle (ex: '1m', '5m', '1h')
            limit: Nombre max de chandeliers √† r√©cup√©rer (max 1000)
            start_time: Timestamp de d√©but en millisecondes
            
        Returns:
            Liste des chandeliers
        """
        await self._respect_rate_limit()
        await self._ensure_session()
        
        url = f"{self.base_url}/klines"
        params = {
            "symbol": symbol,
            "interval": interval,
            "limit": min(limit, 1000)  # Max 1000 par requ√™te
        }
        
        if start_time:
            params["startTime"] = start_time
        
        try:
            async with self.session.get(url, params=params) as response:
                if response.status != 200:
                    error_msg = await response.text()
                    logger.error(f"‚ùå Erreur API Binance ({response.status}): {error_msg}")
                    return []
                
                response_data = await response.json()
                
                # V√©rifier le format de la r√©ponse
                if not isinstance(response_data, list):
                    logger.error(f"‚ùå Format de r√©ponse inattendu: {response_data}")
                    return []
                
                # Formater les donn√©es
                klines = []
                for k in response_data:
                    if len(k) < 7:  # V√©rifier le nombre minimal de champs
                        logger.warning(f"‚ö†Ô∏è Chandelier incomplet ignor√©: {k}")
                        continue
                    
                    try:
                        kline = {
                            "symbol": symbol,
                            "start_time": k[0],  # Open time
                            "close_time": k[6],  # Close time
                            "open": float(k[1]),
                            "high": float(k[2]),
                            "low": float(k[3]),
                            "close": float(k[4]),
                            "volume": float(k[5]),
                            "is_closed": True,  # Toutes ces donn√©es sont des chandeliers ferm√©s
                        }
                        klines.append(kline)
                    except (ValueError, IndexError) as e:
                        logger.warning(f"‚ö†Ô∏è Erreur lors du traitement du chandelier {k}: {str(e)}")
                
                return klines
            
        except aiohttp.ClientError as e:
            logger.error(f"‚ùå Erreur HTTP lors de la r√©cup√©ration des chandeliers: {str(e)}")
            return []
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des chandeliers: {str(e)}")
            return []
    
    async def fetch_and_publish_history(self, symbols: List[str], interval: str, days_back: int = 3) -> int:
        """
        R√©cup√®re l'historique et publie les donn√©es via Kafka.
        
        Args:
            symbols: Liste des symboles
            interval: Intervalle des chandeliers
            days_back: Nombre de jours d'historique √† r√©cup√©rer
            
        Returns:
            Nombre total de chandeliers r√©cup√©r√©s
        """
        if not self.kafka_producer:
            logger.error("‚ùå Kafka Producer non configur√©")
            return 0
        
        total_klines = 0
        
        try:
            # Cr√©er une session HTTP pour toutes les requ√™tes
            async with aiohttp.ClientSession() as session:
                self.session = session
                
                # Calculer le timestamp de d√©but
                start_time = int((datetime.now() - timedelta(days=days_back)).timestamp() * 1000)
                
                for symbol in symbols:
                    logger.info(f"üìà R√©cup√©ration de l'historique pour {symbol} @ {interval} (depuis {days_back} jours)...")
                    
                    # R√©cup√©rer les donn√©es par lots
                    current_start = start_time
                    all_klines = []
                    
                    while True:
                        klines = await self.get_klines(symbol, interval, 1000, current_start)
                        
                        if not klines:
                            break
                        
                        all_klines.extend(klines)
                        
                        # Mettre √† jour le timestamp de d√©but pour la prochaine requ√™te
                        current_start = klines[-1]["close_time"] + 1
                        
                        # Si on a atteint le pr√©sent, arr√™ter
                        if current_start > int(time.time() * 1000):
                            break
                        
                        # Petite pause pour respecter les limites
                        await asyncio.sleep(0.1)
                    
                    # Publier les donn√©es
                    logger.info(f"üìä Publication de {len(all_klines)} chandeliers pour {symbol}...")
                    
                    for kline in all_klines:
                        # Publier via Kafka
                        topic = f"market.data.{symbol.lower()}"
                        self.kafka_producer.publish_market_data(kline)
                    
                    total_klines += len(all_klines)
                    
                    # Pause entre les symboles
                    await asyncio.sleep(1)
        finally:
            # S'assurer que la session est ferm√©e
            if self.session and not self.session.closed:
                await self.session.close()
                self.session = None
        
        logger.info(f"‚úÖ Total: {total_klines} chandeliers historiques r√©cup√©r√©s et publi√©s")
        return total_klines
    
    async def close(self):
        """Ferme proprement les ressources."""
        if self.session and not self.session.closed:
            await self.session.close()
            self.session = None