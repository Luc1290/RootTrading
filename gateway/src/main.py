"""
Point d'entr√©e principal pour le microservice Gateway.
G√®re les connexions WebSocket √† Binance et la publication des donn√©es vers Kafka.
"""
import asyncio
import logging
import signal
import sys
import os
import time
from aiohttp import web
import argparse

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from binance_ws import BinanceWebSocket
from kafka_producer import get_producer
from ultra_data_fetcher import UltraDataFetcher
from shared.src.config import BINANCE_API_KEY, BINANCE_SECRET_KEY, SYMBOLS, INTERVAL

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('gateway.log')
    ]
)
logger = logging.getLogger("gateway")


if not BINANCE_API_KEY or not BINANCE_SECRET_KEY:
    logger.warning("‚ö†Ô∏è Cl√©s API Binance non configur√©es ou incompl√®tes!")

# Variables globales
ws_client = None
running = True
start_time = time.time()

# Routes pour le serveur HTTP
routes = web.RouteTableDef()

@routes.get('/health')
async def health_check(request):
    """
    Point de terminaison pour v√©rifier l'√©tat du service.
    """
    uptime = time.time() - start_time
    return web.json_response({
        "status": "ok",
        "timestamp": time.time(),
        "uptime": uptime,
        "mode": "active" if running else "stopping",
        "symbols": SYMBOLS,
        "interval": INTERVAL
    })

@routes.get('/diagnostic')
async def diagnostic(request):
    """
    Point de terminaison pour le diagnostic du service.
    """
    global ws_client
    
    # R√©cup√©rer l'√©tat du client WebSocket
    ws_status = {
        "connected": ws_client.ws is not None,
        "running": ws_client.running,
        "reconnect_delay": ws_client.reconnect_delay,
        "last_message_time": ws_client.last_message_time,
        "stream_paths": ws_client.stream_paths,
    }
    
    # Construire la r√©ponse
    diagnostic_info = {
        "status": "operational" if ws_client.running else "stopped",
        "timestamp": time.time(),
        "uptime": time.time() - start_time,
        "websocket": ws_status,
        "symbols": SYMBOLS,
        "interval": INTERVAL,
        "kafka_connected": True,  # Simplification, √† am√©liorer avec un vrai check
    }
    
    return web.json_response(diagnostic_info)

async def start_http_server():
    """
    D√©marre le serveur HTTP pour les endpoints de sant√©.
    """
    app = web.Application()
    app.add_routes(routes)
    
    runner = web.AppRunner(app)
    await runner.setup()
    
    # Utiliser le port 5010 pour l'API REST
    site = web.TCPSite(runner, '0.0.0.0', 5010)
    await site.start()
    
    logger.info("‚úÖ Serveur HTTP d√©marr√© sur le port 5010")
    
    return runner

async def shutdown(signal_type, loop):
    """
    G√®re l'arr√™t propre du service en cas de signal (SIGINT, SIGTERM).
    
    Args:
        signal_type: Type de signal re√ßu
        loop: Boucle asyncio en cours
    """
    global running, ws_client
    
    logger.info(f"Signal {signal_type.name} re√ßu, arr√™t en cours...")
    running = False
    
    # Arr√™ter le WebSocket
    if ws_client:
        await ws_client.stop()
    
    # Fermer le producteur Kafka
    producer = get_producer()
    producer.close()
    
    # Arr√™ter la boucle asyncio
    loop.stop()
    
    logger.info("Service Gateway arr√™t√© proprement")

def parse_arguments():
    """Parse les arguments de ligne de commande."""
    parser = argparse.ArgumentParser(description='Gateway RootTrading Ultra-Enrichi')
    parser.add_argument(
        '--skip-init', 
        action='store_true', 
        help='Ignorer l\'initialisation des donn√©es ultra-enrichies'
    )
    parser.add_argument(
        '--debug', 
        action='store_true', 
        help='Activer le mode debug pour plus de logs'
    )
    return parser.parse_args()

async def sync_historical_to_realtime_cache(ws_client):
    """
    Synchronise TOUS les indicateurs calcul√©s historiquement avec le cache temps r√©el du WebSocket.
    CRITIQUE pour maintenir la continuit√© de TOUS les indicateurs (extensible pour futurs ajouts).
    """
    from shared.src.technical_indicators import indicator_cache
    
    try:
        timeframes = ['1m', '5m', '15m', '1h', '4h']
        synced_count = 0
        indicator_types = set()
        
        for symbol in SYMBOLS:
            for timeframe in timeframes:
                # **NOUVEAU**: R√©cup√©rer TOUS les indicateurs calcul√©s historiquement
                all_historical_indicators = indicator_cache.get_all_indicators(symbol, timeframe)
                
                # V√©rifier que le symbole/timeframe existe dans le cache WebSocket
                if symbol in ws_client.incremental_cache and timeframe in ws_client.incremental_cache[symbol]:
                    cache_ref = ws_client.incremental_cache[symbol][timeframe]
                    
                    # **EXTENSIBLE**: Transf√©rer TOUS les indicateurs disponibles
                    for indicator_name, indicator_value in all_historical_indicators.items():
                        if indicator_value is not None:
                            cache_ref[indicator_name] = indicator_value
                            synced_count += 1
                            indicator_types.add(indicator_name)
                    
                    if all_historical_indicators:
                        key_indicators = {k: v for k, v in all_historical_indicators.items() 
                                        if k in ['ema_12', 'ema_26', 'macd_line', 'rsi_14'] and v is not None}
                        logger.debug(f"Sync {symbol} {timeframe}: {len(all_historical_indicators)} indicateurs ‚Üí " +
                                   ', '.join([f"{k}={v:.4f}" for k, v in key_indicators.items()]))
                else:
                    logger.warning(f"Cache WebSocket non initialis√© pour {symbol} {timeframe}")
        
        logger.info(f"üìä Synchronisation termin√©e: {synced_count} indicateurs transf√©r√©s")
        logger.info(f"üîß Types d'indicateurs synchronis√©s: {', '.join(sorted(indicator_types))}")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur synchronisation cache: {e}")
        # Ne pas faire √©chouer le d√©marrage pour un probl√®me de sync

async def main():
    """
    Fonction principale qui d√©marre le Gateway.
    """
    global ws_client
    validation_fetcher = None
    
    # Parser les arguments
    args = parse_arguments()
    
    logger.info("üöÄ D√©marrage du service Gateway RootTrading...")
    logger.info(f"Configuration: {', '.join(SYMBOLS)} @ {INTERVAL}")
    
    # D√©marrer le serveur HTTP
    http_runner = await start_http_server()
    
    # Obtenir le producteur Kafka
    producer = get_producer()
    
    try:
        # Initialiser les donn√©es ultra-enrichies au d√©marrage si demand√©
        if not args.skip_init:
            logger.info(f"üî• Initialisation des donn√©es ultra-enrichies multi-timeframes...")
            
            # Cr√©er l'UltraDataFetcher pour l'initialisation
            init_fetcher = UltraDataFetcher()
            
            # **NOUVEAU**: Charger 5 jours de donn√©es historiques pour tous les timeframes
            try:
                logger.info(f"üìö Chargement de 5 jours de donn√©es historiques...")
                await init_fetcher.load_historical_data(days=5)
                logger.info(f"‚úÖ Donn√©es historiques charg√©es avec succ√®s")
            except Exception as e:
                logger.error(f"‚ùå Erreur chargement donn√©es historiques: {e}")
                logger.warning(f"‚ö†Ô∏è Poursuite sans donn√©es historiques compl√®tes")
            
            # Ex√©cuter un cycle d'initialisation pour remplir les caches Redis
            try:
                await init_fetcher._fetch_initialization_data()
                logger.info(f"‚úÖ Donn√©es ultra-enrichies initialis√©es avec succ√®s")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur lors de l'initialisation: {e}")
        else:
            logger.info("‚è© Initialisation des donn√©es ultra-enrichies ignor√©e")
        
        # Cr√©er le client WebSocket Binance
        ws_client = BinanceWebSocket(symbols=SYMBOLS, interval=INTERVAL)
        
        # **FIX CRITIQUE**: Synchroniser les indicateurs historiques avec le cache temps r√©el
        if not args.skip_init:
            logger.info("üîÑ Synchronisation cache historique ‚Üí temps r√©el...")
            await sync_historical_to_realtime_cache(ws_client)
            logger.info("‚úÖ Cache temps r√©el synchronis√© avec donn√©es historiques")
        
        # Cr√©er le service ultra-enrichi multi-timeframes
        ultra_fetcher = UltraDataFetcher()
        
        # D√©marrer les services en parall√®le
        logger.info("üöÄ D√©marrage WebSocket + UltraDataFetcher")
        await asyncio.gather(
            ws_client.start(),
            ultra_fetcher.start()
        )
    except Exception as e:
        logger.error(f"‚ùå Erreur critique dans le Gateway: {str(e)}")
    finally:
        if ws_client:
            await ws_client.stop()
        if ultra_fetcher:
            await ultra_fetcher.stop()
        
        # Arr√™ter le serveur HTTP
        await http_runner.cleanup()
        
        logger.info("Service Gateway termin√©")

if __name__ == "__main__":
    # Obtenir la boucle asyncio
    loop = asyncio.get_event_loop()
    
    # Configurer les gestionnaires de signaux pour l'arr√™t propre
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(
            sig, 
            lambda s=sig: asyncio.create_task(shutdown(s, loop))
        )
    
    try:
        # Ex√©cuter la fonction principale
        loop.run_until_complete(main())
    except KeyboardInterrupt:
        logger.info("Interruption clavier d√©tect√©e")
    finally:
        # Fermer la boucle asyncio
        loop.close()
        logger.info("Boucle asyncio ferm√©e")