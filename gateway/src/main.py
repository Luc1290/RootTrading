"""
Point d'entr√©e principal pour le microservice Gateway.
G√®re les connexions WebSocket √† Binance et la publication des donn√©es vers Kafka.
"""
import asyncio
import logging
import signal
import sys
import os
import time
from aiohttp import web
import argparse

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from binance_ws import BinanceWebSocket
from kafka_producer import get_producer
from ultra_data_fetcher import UltraDataFetcher
from shared.src.config import BINANCE_API_KEY, BINANCE_SECRET_KEY, SYMBOLS, INTERVAL

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('gateway.log')
    ]
)
logger = logging.getLogger("gateway")


if not BINANCE_API_KEY or not BINANCE_SECRET_KEY:
    logger.warning("‚ö†Ô∏è Cl√©s API Binance non configur√©es ou incompl√®tes!")

# Variables globales
ws_client = None
running = True
start_time = time.time()

# Routes pour le serveur HTTP
routes = web.RouteTableDef()

@routes.get('/health')
async def health_check(request):
    """
    Point de terminaison pour v√©rifier l'√©tat du service.
    """
    uptime = time.time() - start_time
    return web.json_response({
        "status": "ok",
        "timestamp": time.time(),
        "uptime": uptime,
        "mode": "active" if running else "stopping",
        "symbols": SYMBOLS,
        "interval": INTERVAL
    })

@routes.get('/diagnostic')
async def diagnostic(request):
    """
    Point de terminaison pour le diagnostic du service.
    """
    global ws_client
    
    # R√©cup√©rer l'√©tat du client WebSocket
    ws_status = {
        "connected": ws_client.ws is not None,
        "running": ws_client.running,
        "reconnect_delay": ws_client.reconnect_delay,
        "last_message_time": ws_client.last_message_time,
        "stream_paths": ws_client.stream_paths,
    }
    
    # Construire la r√©ponse
    diagnostic_info = {
        "status": "operational" if ws_client.running else "stopped",
        "timestamp": time.time(),
        "uptime": time.time() - start_time,
        "websocket": ws_status,
        "symbols": SYMBOLS,
        "interval": INTERVAL,
        "kafka_connected": True,  # Simplification, √† am√©liorer avec un vrai check
    }
    
    return web.json_response(diagnostic_info)

async def start_http_server():
    """
    D√©marre le serveur HTTP pour les endpoints de sant√©.
    """
    app = web.Application()
    app.add_routes(routes)
    
    runner = web.AppRunner(app)
    await runner.setup()
    
    # Utiliser le port 5010 pour l'API REST
    site = web.TCPSite(runner, '0.0.0.0', 5010)
    await site.start()
    
    logger.info("‚úÖ Serveur HTTP d√©marr√© sur le port 5010")
    
    return runner

async def shutdown(signal_type, loop):
    """
    G√®re l'arr√™t propre du service en cas de signal (SIGINT, SIGTERM).
    
    Args:
        signal_type: Type de signal re√ßu
        loop: Boucle asyncio en cours
    """
    global running, ws_client
    
    logger.info(f"Signal {signal_type.name} re√ßu, arr√™t en cours...")
    running = False
    
    # Arr√™ter le WebSocket
    if ws_client:
        await ws_client.stop()
    
    # Fermer le producteur Kafka
    producer = get_producer()
    producer.close()
    
    # Arr√™ter la boucle asyncio
    loop.stop()
    
    logger.info("Service Gateway arr√™t√© proprement")

def parse_arguments():
    """Parse les arguments de ligne de commande."""
    parser = argparse.ArgumentParser(description='Gateway RootTrading Ultra-Enrichi')
    parser.add_argument(
        '--skip-init', 
        action='store_true', 
        help='Ignorer l\'initialisation des donn√©es ultra-enrichies'
    )
    parser.add_argument(
        '--debug', 
        action='store_true', 
        help='Activer le mode debug pour plus de logs'
    )
    return parser.parse_args()

async def sync_historical_to_realtime_cache(ws_client):
    """
    Synchronise TOUS les indicateurs calcul√©s historiquement avec le cache temps r√©el du WebSocket.
    CRITIQUE pour maintenir la continuit√© de TOUS les indicateurs (extensible pour futurs ajouts).
    """
    from shared.src.technical_indicators import indicator_cache
    
    try:
        timeframes = ['1m', '5m', '15m', '1h', '4h']
        synced_count = 0
        indicator_types = set()
        
        for symbol in SYMBOLS:
            for timeframe in timeframes:
                # **NOUVEAU**: R√©cup√©rer TOUS les indicateurs calcul√©s historiquement
                all_historical_indicators = indicator_cache.get_all_indicators(symbol, timeframe)
                
                # V√©rifier que le symbole/timeframe existe dans le cache WebSocket
                if symbol in ws_client.incremental_cache and timeframe in ws_client.incremental_cache[symbol]:
                    cache_ref = ws_client.incremental_cache[symbol][timeframe]
                    
                    # **EXTENSIBLE**: Transf√©rer TOUS les indicateurs disponibles
                    for indicator_name, indicator_value in all_historical_indicators.items():
                        if indicator_value is not None:
                            cache_ref[indicator_name] = indicator_value
                            synced_count += 1
                            indicator_types.add(indicator_name)
                    
                    if all_historical_indicators:
                        key_indicators = {k: v for k, v in all_historical_indicators.items() 
                                        if k in ['ema_12', 'ema_26', 'macd_line', 'rsi_14'] and v is not None}
                        logger.debug(f"Sync {symbol} {timeframe}: {len(all_historical_indicators)} indicateurs ‚Üí " +
                                   ', '.join([f"{k}={v:.4f}" for k, v in key_indicators.items()]))
                else:
                    logger.warning(f"Cache WebSocket non initialis√© pour {symbol} {timeframe}")
        
        logger.info(f"üìä Synchronisation termin√©e: {synced_count} indicateurs transf√©r√©s")
        logger.info(f"üîß Types d'indicateurs synchronis√©s: {', '.join(sorted(indicator_types))}")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur synchronisation cache: {e}")
        # Ne pas faire √©chouer le d√©marrage pour un probl√®me de sync

async def restore_indicators_from_db():
    """
    Restaure les indicateurs techniques depuis la base de donn√©es PostgreSQL.
    Charge les derni√®res valeurs d'indicateurs pour chaque symbole/timeframe pour maintenir la continuit√©.
    
    Returns:
        int: Nombre d'indicateurs restaur√©s
    """
    from shared.src.technical_indicators import indicator_cache
    from shared.src.config import get_db_config
    import asyncpg
    
    restored_count = 0
    
    try:
        # Connexion √† la base de donn√©es
        db_config = get_db_config()
        conn = await asyncpg.connect(
            host=db_config['host'],
            port=db_config['port'],
            database=db_config['database'],
            user=db_config['user'],
            password=db_config['password']
        )
        
        # Requ√™te pour r√©cup√©rer les derniers indicateurs pour chaque symbole/timeframe
        query = """
            WITH latest_data AS (
                SELECT DISTINCT ON (symbol, timeframe) 
                    symbol, timeframe, time,
                    rsi_14, ema_12, ema_26, ema_50, sma_20, sma_50,
                    macd_line, macd_signal, macd_histogram,
                    bb_upper, bb_middle, bb_lower, bb_position, bb_width,
                    atr_14, momentum_10, volume_ratio, avg_volume_20,
                    stoch_k, stoch_d, stoch_rsi, adx_14, plus_di, minus_di,
                    williams_r, cci_20, mfi_14, vwap_10, roc_10, roc_20,
                    obv, trend_angle, pivot_count
                FROM market_data 
                WHERE enhanced = true 
                    AND symbol = ANY($1)
                    AND timeframe = ANY($2)
                ORDER BY symbol, timeframe, time DESC
            )
            SELECT * FROM latest_data
        """
        
        timeframes = ['1m', '5m', '15m', '1h', '4h']
        result = await conn.fetch(query, SYMBOLS, timeframes)
        
        # Restaurer les indicateurs dans le cache
        for row in result:
            symbol = row['symbol']
            timeframe = row['timeframe']
            
            # Construire le dictionnaire des indicateurs
            indicators = {}
            
            # Parcourir toutes les colonnes d'indicateurs
            for field_name in row.keys():
                if field_name not in ['symbol', 'timeframe', 'time'] and row[field_name] is not None:
                    indicators[field_name] = float(row[field_name])
            
            # Restaurer dans le cache si des indicateurs sont trouv√©s
            if indicators:
                for indicator_name, value in indicators.items():
                    indicator_cache.set(symbol, timeframe, indicator_name, value)
                    restored_count += 1
                
                logger.debug(f"üîÑ Restaur√© {symbol} {timeframe}: {len(indicators)} indicateurs depuis {row['time']}")
        
        await conn.close()
        
        if restored_count > 0:
            logger.info(f"‚úÖ {restored_count} indicateurs restaur√©s depuis la DB pour {len(result)} symbole/timeframe")
        
        return restored_count
        
    except Exception as e:
        logger.error(f"‚ùå Erreur restoration indicateurs depuis DB: {e}")
        return 0


async def main():
    """
    Fonction principale qui d√©marre le Gateway.
    """
    global ws_client
    validation_fetcher = None
    
    # Parser les arguments
    args = parse_arguments()
    
    logger.info("üöÄ D√©marrage du service Gateway RootTrading...")
    logger.info(f"Configuration: {', '.join(SYMBOLS)} @ {INTERVAL}")
    
    # D√©marrer le serveur HTTP
    http_runner = await start_http_server()
    
    # Obtenir le producteur Kafka
    producer = get_producer()
    
    try:
        # Initialiser les donn√©es ultra-enrichies au d√©marrage si demand√©
        if not args.skip_init:
            logger.info(f"üî• Initialisation des donn√©es ultra-enrichies multi-timeframes...")
            
            # Cr√©er l'UltraDataFetcher pour l'initialisation
            init_fetcher = UltraDataFetcher()
            
            # **NOUVEAU**: Charger 5 jours de donn√©es historiques pour tous les timeframes
            try:
                logger.info(f"üìö Chargement de 5 jours de donn√©es historiques...")
                await init_fetcher.load_historical_data(days=5)
                logger.info(f"‚úÖ Donn√©es historiques charg√©es avec succ√®s")
            except Exception as e:
                logger.error(f"‚ùå Erreur chargement donn√©es historiques: {e}")
                logger.warning(f"‚ö†Ô∏è Poursuite sans donn√©es historiques compl√®tes")
            
            # Ex√©cuter un cycle d'initialisation pour remplir les caches Redis
            try:
                await init_fetcher._fetch_initialization_data()
                logger.info(f"‚úÖ Donn√©es ultra-enrichies initialis√©es avec succ√®s")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur lors de l'initialisation: {e}")
        else:
            logger.info("‚è© Initialisation des donn√©es ultra-enrichies ignor√©e")
        
        # Cr√©er le client WebSocket Binance
        ws_client = BinanceWebSocket(symbols=SYMBOLS, interval=INTERVAL)
        
        # **NOUVELLE LOGIQUE**: Restoration automatique du cache d'indicateurs depuis la DB
        from shared.src.technical_indicators import indicator_cache
        
        logger.info("üîÑ Restoration automatique du cache d'indicateurs depuis la DB...")
        restored_indicators = await restore_indicators_from_db()
        
        if restored_indicators > 0:
            logger.info(f"‚úÖ {restored_indicators} indicateurs restaur√©s depuis la DB - CONTINUIT√â PR√âSERV√âE")
            
            # Afficher les statistiques de restoration
            cache_stats = indicator_cache.get_cache_stats()
            logger.info(f"üìä Cache Statistics: {cache_stats['local_entries']} entr√©es locales")
        else:
            logger.warning("‚ö†Ô∏è Aucun indicateur restaur√© - Premier d√©marrage ou DB vide")
            
            # Seulement si pas de restoration, faire l'initialisation compl√®te
            if not args.skip_init:
                logger.info("üîß Recalcul complet des indicateurs (pas de donn√©es persist√©es)...")
                
                # Forcer un calcul point par point pour remplir le cache
                init_fetcher = UltraDataFetcher()
                for symbol in SYMBOLS:
                    for timeframe in ['1m', '5m', '15m', '1h', '4h']:
                        try:
                            # Utiliser UltraDataFetcher pour r√©cup√©rer et calculer
                            await init_fetcher._fetch_ultra_enriched_data(symbol, timeframe)
                            logger.debug(f"‚úÖ Cache recalcul√© pour {symbol} {timeframe}")
                        except Exception as e:
                            logger.warning(f"Erreur calcul initial {symbol} {timeframe}: {e}")
        
        # **FIX CRITIQUE**: Synchroniser les indicateurs restaur√©s/calcul√©s avec le cache temps r√©el WebSocket
        logger.info("üîÑ Synchronisation cache ‚Üí WebSocket temps r√©el...")
        await sync_historical_to_realtime_cache(ws_client)
        
        # V√©rifier la synchronisation
        final_cache_stats = {"total": 0, "symbols": set()}
        for symbol in SYMBOLS:
            for timeframe in ['1m', '5m', '15m', '1h', '4h']:
                indicators = indicator_cache.get_all_indicators(symbol, timeframe)
                final_cache_stats["total"] += len(indicators)
                if indicators:
                    final_cache_stats["symbols"].add(symbol)
        
        logger.info(f"‚úÖ Synchronisation termin√©e: {final_cache_stats['total']} indicateurs pour {len(final_cache_stats['symbols'])} symboles")
        
        # Force sauvegarde pour s'assurer que les donn√©es sont persist√©es
        if final_cache_stats["total"] > 0:
            saved_count = indicator_cache.force_save_all()
            logger.info(f"üíæ {saved_count} indicateurs sauvegard√©s pour la prochaine restoration")
        
        # Cr√©er le service ultra-enrichi multi-timeframes
        ultra_fetcher = UltraDataFetcher()
        
        # D√©marrer les services en parall√®le
        logger.info("üöÄ D√©marrage WebSocket + UltraDataFetcher")
        await asyncio.gather(
            ws_client.start(),
            ultra_fetcher.start()
        )
    except Exception as e:
        logger.error(f"‚ùå Erreur critique dans le Gateway: {str(e)}")
    finally:
        if ws_client:
            await ws_client.stop()
        if ultra_fetcher:
            await ultra_fetcher.stop()
        
        # Arr√™ter le serveur HTTP
        await http_runner.cleanup()
        
        logger.info("Service Gateway termin√©")

if __name__ == "__main__":
    # Obtenir la boucle asyncio
    loop = asyncio.get_event_loop()
    
    # Configurer les gestionnaires de signaux pour l'arr√™t propre
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(
            sig, 
            lambda s=sig: asyncio.create_task(shutdown(s, loop))
        )
    
    try:
        # Ex√©cuter la fonction principale
        loop.run_until_complete(main())
    except KeyboardInterrupt:
        logger.info("Interruption clavier d√©tect√©e")
    finally:
        # Fermer la boucle asyncio
        loop.close()
        logger.info("Boucle asyncio ferm√©e")