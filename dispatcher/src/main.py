"""
Point d'entr√©e principal pour le microservice Dispatcher.
Re√ßoit les messages Kafka et les route vers les bons destinataires.
"""
import logging
import signal
import sys
import time
import os
import threading
from typing import Dict, Any
import json
from http.server import HTTPServer, BaseHTTPRequestHandler

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from shared.src.config import KAFKA_BROKER, KAFKA_GROUP_ID, SYMBOLS, LOG_LEVEL
from shared.src.kafka_client import KafkaClient
from shared.src.redis_client import RedisClient

from dispatcher.src.message_router import MessageRouter

# Configuration du logging
log_level = getattr(logging, LOG_LEVEL.upper(), logging.INFO)
logging.basicConfig(
    level=log_level,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('dispatcher.log')
    ]
)
logger = logging.getLogger("dispatcher")


class HealthHandler(BaseHTTPRequestHandler):
    """Gestionnaire des requ√™tes HTTP pour les endpoints de sant√©."""
    
    def do_GET(self):
        """G√®re les requ√™tes GET pour les endpoints de sant√© et diagnostic."""
        if self.path == '/health':
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            
            # R√©cup√©rer les statistiques du routeur
            router_stats = self.server.dispatcher_service.router.get_stats() if self.server.dispatcher_service.router else {}
            
            health_info = {
                "status": "healthy" if self.server.dispatcher_service.running else "stopping",
                "timestamp": time.time(),
                "uptime": time.time() - self.server.dispatcher_service.start_time,
                "stats": router_stats
            }
            
            self.wfile.write(json.dumps(health_info).encode())
        
        elif self.path == '/diagnostic':
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            
            # Informations diagnostiques plus d√©taill√©es
            kafka_status = "connected" if self.server.dispatcher_service.kafka_client else "disconnected"
            redis_status = "connected" if self.server.dispatcher_service.redis_client else "disconnected"
            
            diagnostic_info = {
                "status": "operational" if self.server.dispatcher_service.running else "stopping",
                "timestamp": time.time(),
                "uptime": time.time() - self.server.dispatcher_service.start_time,
                "connections": {
                    "kafka": kafka_status,
                    "redis": redis_status
                },
                "topics": self.server.dispatcher_service.topics,
                "stats": self.server.dispatcher_service.router.get_stats() if self.server.dispatcher_service.router else {}
            }
            
            self.wfile.write(json.dumps(diagnostic_info).encode())
        
        else:
            self.send_response(404)
            self.end_headers()
    
    def log_message(self, format, *args):
        """Rediriger les logs HTTP vers le logger du dispatcher."""
        logger.debug(f"HTTP Server: {format % args}")


class DispatcherService:
    """
    Service principal du Dispatcher.
    Coordonne la r√©ception des messages Kafka et leur routage vers Redis.
    """
    
    def __init__(self, broker=KAFKA_BROKER, symbols=SYMBOLS):
        """
        Initialise le service Dispatcher.
        
        Args:
            broker: Adresse du broker Kafka
            symbols: Liste des symboles √† surveiller
        """
        self.running = False
        self.kafka_client = None
        self.redis_client = None
        self.router = None
        self.symbols = symbols
        self.broker = broker
        self.start_time = time.time()
        self.topics = []
        self.http_server = None
    
    def handle_kafka_message(self, topic: str, message: Dict[str, Any]) -> None:
        """
        Callback pour traiter les messages Kafka.
        
        Args:
            topic: Topic Kafka source
            message: Message re√ßu
        """
        if not self.router or not self.running:
            logger.warning("Router non initialis√© ou service arr√™t√©, message ignor√©")
            return
        
        try:
            # Router le message
            success = self.router.route_message(topic, message)
            
            if success:
                logger.debug(f"Message rout√© depuis {topic}")
            else:
                logger.warning(f"√âchec du routage pour le message de {topic}")
        
        except Exception as e:
            logger.error(f"Erreur lors du traitement du message Kafka: {str(e)}")
    
    def start_http_server(self, port=5004):
        """
        D√©marre un serveur HTTP pour les endpoints de sant√©.
        
        Args:
            port: Port pour le serveur HTTP
        """
        try:
            self.http_server = HTTPServer(('0.0.0.0', port), HealthHandler)
            self.http_server.dispatcher_service = self
            
            # D√©marrer dans un thread s√©par√© pour ne pas bloquer
            self.http_thread = threading.Thread(target=self.http_server.serve_forever, daemon=True)
            self.http_thread.start()
            
            logger.info(f"‚úÖ Serveur HTTP d√©marr√© sur le port {port}")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du d√©marrage du serveur HTTP: {str(e)}")
    
    def setup_signal_handlers(self):
        """Configure les gestionnaires de signaux pour l'arr√™t propre."""
        def signal_handler(sig, frame):
            logger.info(f"Signal {sig} re√ßu, arr√™t en cours...")
            self.stop()
        
        # Enregistrer les gestionnaires pour SIGINT et SIGTERM
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
    
    def stop(self):
        """Arr√™te proprement le service Dispatcher."""
        if not self.running:
            return
        
        logger.info("Arr√™t du service Dispatcher...")
        self.running = False
        
        # Arr√™t du serveur HTTP s'il est d√©marr√©
        if self.http_server:
            self.http_server.shutdown()
            logger.info("Serveur HTTP arr√™t√©")
        
        # Arr√™t du client Kafka
        if self.kafka_client:
            self.kafka_client.close()
            logger.info("Client Kafka ferm√©")
        
        # Fermeture du client Redis
        if self.redis_client:
            self.redis_client.close()
            logger.info("Client Redis ferm√©")
        
        # Fermeture du router
        if self.router:
            self.router.close()
            logger.info("Router ferm√©")
        
        logger.info("Service Dispatcher termin√©")
    
    def run(self):
        """
        Fonction principale du service Dispatcher.
        """
        if self.running:
            logger.warning("Le service est d√©j√† en cours d'ex√©cution")
            return
        
        self.running = True
        self.setup_signal_handlers()
        
        logger.info("üöÄ D√©marrage du service Dispatcher RootTrading...")
        
        try:
            # Initialiser les clients
            self.kafka_client = KafkaClient(broker=self.broker, group_id=f"{KAFKA_GROUP_ID}-dispatcher")
            self.redis_client = RedisClient()
            
            # Initialiser le router de messages
            self.router = MessageRouter(redis_client=self.redis_client)
            
            # Construire la liste des topics √† suivre
            self.topics = []
            
            # Topics de donn√©es de march√© multi-timeframes pour chaque symbole
            timeframes = ['1m', '3m', '5m', '15m', '1h', '1d']
            for symbol in self.symbols:
                # Topics multi-timeframes
                for tf in timeframes:
                    self.topics.append(f"market.data.{symbol.lower()}.{tf}")
                # Garder aussi l'ancien format pour compatibilit√©
                self.topics.append(f"market.data.{symbol.lower()}")
            
            # Autres topics √† suivre
            self.topics.extend(["signals", "executions", "orders", "analyzer.signals"])
            
            logger.info(f"Abonnement aux topics Kafka: {', '.join(self.topics)}")
            
            # D√©marrer le serveur HTTP pour les endpoints de sant√©
            self.start_http_server()
            
            # D√©marrer la consommation Kafka
            self.kafka_client.consume(self.topics, self.handle_kafka_message)
            
            # Boucle principale
            while self.running:
                time.sleep(1.0)
        
        except KeyboardInterrupt:
            logger.info("Programme interrompu par l'utilisateur")
        except Exception as e:
            logger.error(f"‚ùå Erreur critique dans le service Dispatcher: {str(e)}")
            self.running = False
        finally:
            # Nettoyage et arr√™t propre
            self.stop()


def main():
    """Point d'entr√©e principal pour le service Dispatcher."""
    dispatcher = DispatcherService()
    dispatcher.run()


if __name__ == "__main__":
    main()