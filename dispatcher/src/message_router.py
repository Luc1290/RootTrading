"""
Module de routage des messages entre Kafka et Redis.
Transforme et route les messages vers les canaux appropri√©s.
"""
import logging
import time
import threading
from collections import deque
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple

from shared.src.config import SYMBOLS
from shared.src.redis_client import RedisClient
from dispatcher.src.database_persister import DatabasePersister

# Configuration du logging
logger = logging.getLogger(__name__)

class MessageRouter:
    """
    Router de messages entre Kafka et Redis.
    Re√ßoit les messages Kafka et les publie sur les canaux Redis appropri√©s.
    """
    
    def __init__(self, redis_client: Optional[RedisClient] = None):
        """
        Initialise le router de messages.
        
        Args:
            redis_client: Client Redis pr√©existant (optionnel)
        """
        self.redis_client = redis_client or RedisClient()
        
        # Client Redis d√©di√© pour les messages haute priorit√©
        self.high_priority_redis = RedisClient()
        
        # Ajout du persister pour sauvegarder en base
        self.db_persister = DatabasePersister()
        self.db_persister.start_persister()
        
        # Pr√©fixe pour les canaux Redis
        self.redis_prefix = "roottrading"
        
        # Mappings des topics vers les canaux
        self.topic_to_channel = {
            "market.data": "market:data",  # Multi-timeframes enrichies
            "signals.filtered": "signals:filtered",  # Signaux filtr√©s du signal_aggregator
            "executions": "trade:execution",
            "orders": "trade:order"
        }
        
        # Support multi-timeframes
        self.timeframes = ['1m', '3m', '5m', '15m']
        
        # Cache pour les donn√©es enrichies par symbole/timeframe
        self.enriched_data_cache: Dict[str, Dict[str, Any]] = {}
        for symbol in SYMBOLS:
            self.enriched_data_cache[symbol] = {}
            for tf in self.timeframes:
                self.enriched_data_cache[symbol][tf] = deque(maxlen=50)
        
        # Pr√©calculer les mappings pour les topics de donn√©es de march√© multi-timeframes
        self.market_data_channel_cache = {}
        for symbol in SYMBOLS:
            for tf in self.timeframes:
                topic = f"market.data.{symbol.lower()}.{tf}"
                self.market_data_channel_cache[topic] = f"{self.redis_prefix}:{self.topic_to_channel['market.data']}:{symbol.lower()}:{tf}"
        
        # File d'attente s√©par√©e pour les messages haute priorit√©
        self.high_priority_queue: deque = deque(maxlen=5000)
        
        # File d'attente pour les messages en cas de panne Redis
        self.message_queue: deque = deque(maxlen=10000)  # Limiter √† 10 000 messages
        self.queue_lock = threading.Lock()
        self.queue_processor_running = True
        
        # D√©marrer le thread de traitement de la file d'attente
        self.queue_processor_thread = threading.Thread(
            target=self._process_queue, 
            daemon=True,
            name="MessageQueueProcessor"
        )
        self.queue_processor_thread.start()
        
        # D√©marrer le thread de traitement prioritaire
        self.high_priority_processor_thread = threading.Thread(
            target=self._process_high_priority_queue, 
            daemon=True,
            name="HighPriorityProcessor"
        )
        self.high_priority_processor_thread.start()
        
        # Compteurs de statistiques
        self.stats = {
            "messages_received": 0,
            "messages_routed": 0,
            "high_priority_routed": 0,
            "messages_queued": 0,
            "queue_processed": 0,
            "errors": 0,
            "last_reset": time.time()
        }
        
        # Initialiser le compteur de s√©quence des messages
        self.message_sequence = 0
        
        # --- D√©duplication courte (1 s) --------------------
        self._dedup_cache: Dict[str, float] = {}       # {cl√©: timestamp}
        self._dedup_ttl   = 1.0      # secondes
        
        logger.info("‚úÖ MessageRouter initialis√© avec support priorit√©")

    def _determine_priority(self, topic: str) -> str:
        """
        D√©termine la priorit√© d'un message bas√© sur son topic.
        
        Args:
            topic: Topic Kafka
            
        Returns:
            Priorit√© du message ('high' ou 'normal')
        """
        # Donn√©es de march√© en temps r√©el = haute priorit√©
        if topic.startswith("market.data"):
            return 'high'
        # Signaux de trading = haute priorit√©
        elif topic.startswith("signals") or topic.startswith("analyzer.signals"):
            return 'high'
        # Par d√©faut = priorit√© normale
        else:
            return 'normal'

    def _publish_high_priority(self, channel: str, message: Dict[str, Any]) -> None:
        """
        Publie un message haute priorit√© sur Redis.
        Utilise une connexion d√©di√©e pour les messages critiques.
        
        Args:
            channel: Canal Redis
            message: Message √† publier
        """
        try:
            # Utiliser le client Redis d√©di√© haute priorit√©
            self.high_priority_redis.publish(channel, message)
            self.stats["high_priority_routed"] += 1
        except Exception as e:
            # En cas d'√©chec, mettre en file d'attente prioritaire
            with self.queue_lock:
                self.high_priority_queue.append((channel, message))
            logger.warning(f"‚ùó Publication haute priorit√© √©chou√©e, message mis en file d'attente: {str(e)}")
            raise

    def _process_high_priority_queue(self) -> None:
        """
        Traite les messages haute priorit√© en file d'attente.
        Fonctionne dans un thread s√©par√© avec traitement plus fr√©quent.
        """
        while self.queue_processor_running:
            try:
                # Traiter la file d'attente prioritaire si elle n'est pas vide
                with self.queue_lock:
                    queue_size = len(self.high_priority_queue)
                    if queue_size > 0:
                        # R√©cup√©rer le message le plus ancien
                        channel, message = self.high_priority_queue.popleft()
                        
                        try:
                            # Tenter de publier sur Redis
                            self.high_priority_redis.publish(channel, message)
                            
                            # Incr√©menter le compteur de messages haute priorit√© trait√©s
                            self.stats["high_priority_routed"] += 1
                            
                            if queue_size > 1:
                                logger.debug(f"Message haute priorit√© envoy√© depuis la file d'attente. Restants: {queue_size - 1}")
                        except Exception as e:
                            # En cas d'√©chec, remettre le message dans la file d'attente
                            self.high_priority_queue.append((channel, message))
                            logger.warning(f"√âchec de publication haute priorit√© depuis la file d'attente: {str(e)}")
                            
                            # Pause plus courte en cas d'erreur pour les messages haute priorit√©
                            time.sleep(0.2)
            except Exception as e:
                logger.error(f"‚ùå Erreur dans le traitement de la file d'attente haute priorit√©: {str(e)}")
            
            # Pause tr√®s courte pour les messages haute priorit√©
            time.sleep(0.01)  # 10 ms
    
    def _process_queue(self) -> None:
        """
        Traite les messages dans la file d'attente en cas de panne Redis.
        Fonctionne dans un thread s√©par√©.
        """
        while self.queue_processor_running:
            try:
                # Traiter la file d'attente si elle n'est pas vide
                with self.queue_lock:
                    queue_size = len(self.message_queue)
                    if queue_size > 0:
                        # R√©cup√©rer le message le plus ancien
                        if len(self.message_queue[0]) == 3:  # Nouveau format avec priorit√©
                            channel, message, priority = self.message_queue.popleft()
                        else:  # Ancien format pour r√©trocompatibilit√©
                            channel, message = self.message_queue.popleft()
                            priority = 'normal'
                        
                        try:
                            # Tenter de publier sur Redis
                            if priority == 'high':
                                self._publish_high_priority(channel, message)
                            else:
                                self.redis_client.publish(channel, message)
                            
                            # Incr√©menter le compteur de messages trait√©s
                            self.stats["queue_processed"] += 1
                            
                            if queue_size > 1:
                                logger.info(f"Message envoy√© depuis la file d'attente. Restants: {queue_size - 1}")
                        except Exception as e:
                            # En cas d'√©chec, remettre le message dans la file d'attente
                            self.message_queue.append((channel, message, priority))
                            logger.warning(f"√âchec de publication depuis la file d'attente: {str(e)}")
                            
                            # Pause plus longue en cas d'erreur
                            time.sleep(1.0)
            except Exception as e:
                logger.error(f"‚ùå Erreur dans le traitement de la file d'attente: {str(e)}")
                
            # Courte pause pour √©viter de consommer trop de CPU
            time.sleep(0.1)
    
    def _get_redis_channel(self, topic: str) -> Optional[str]:
        """
        D√©termine le canal Redis correspondant √† un topic Kafka.
        
        Args:
            topic: Topic Kafka
            
        Returns:
            Canal Redis ou None si non mapp√©
        """
        # V√©rifier d'abord dans le cache pr√©calcul√©
        if topic in self.market_data_channel_cache:
            return self.market_data_channel_cache[topic]
        
        # Chercher le type de topic (avant le premier point)
        parts = topic.split('.')
        topic_type = parts[0]
        
        # Cas sp√©cial pour les donn√©es de march√© (inclut le symbole)
        if topic_type == "market" and len(parts) >= 3:
            symbol = parts[2]
            channel = f"{self.redis_prefix}:{self.topic_to_channel['market.data']}:{symbol}"
            
            # Ajouter au cache pour les futures requ√™tes
            self.market_data_channel_cache[topic] = channel
            return channel
        
        # Autres types de topics
        for key, channel in self.topic_to_channel.items():
            if topic.startswith(key):
                return f"{self.redis_prefix}:{channel}"
        
        return None
    
    def _transform_message(self, topic: str, message: Dict[str, Any]) -> Dict[str, Any]:
        """
        Transforme le message si n√©cessaire et assure que tous les champs essentiels sont pr√©sents.
        Optimis√© pour les donn√©es ultra-enrichies avec indicateurs techniques.

        Args:
            topic: Topic Kafka source
            message: Message original
        
        Returns:
            Message transform√© et enrichi
        """
        transformed = message.copy()
        
        # Ajouter les m√©tadonn√©es de routage
        transformed["_routing"] = {
            "source_topic": topic,
            "received_at": datetime.now().isoformat(),
            "priority": self._determine_priority(topic)
        }
        
        # Traitement sp√©cifique selon le type de topic
        if any(topic.startswith(f"market.data.") and topic.endswith(f".{tf}") for tf in ["1m", "3m", "5m", "15m", "1d"]):
            # Extraction du symbole et timeframe depuis le topic
            parts = topic.split(".")
            if len(parts) >= 4:
                symbol = parts[2]
                timeframe = parts[3]
                
                # S'assurer que le symbole et timeframe sont dans le message
                if "symbol" not in transformed:
                    transformed["symbol"] = symbol
                if "timeframe" not in transformed:
                    transformed["timeframe"] = timeframe
                    
                # Validation des champs essentiels pour les donn√©es de march√©
                required_fields = ["time", "open", "high", "low", "close", "volume"]
                for field in required_fields:
                    if field not in transformed:
                        logger.warning(f"Champ requis manquant dans les donn√©es de march√©: {field}")
                        
                # Architecture PROPRE: Le Gateway n'envoie que des donn√©es OHLCV brutes
                # Pas d'indicateurs techniques dans les messages du Gateway
                transformed["_routing"]["data_type"] = "raw_market_data"
                
                # V√©rifier que c'est bien des donn√©es brutes (pas d'indicateurs)
                indicator_fields = ["rsi_14", "ema_12", "macd_line", "bb_upper"]
                has_indicators = any(ind in transformed for ind in indicator_fields)
                if has_indicators:
                    logger.warning(f"ATTENTION: Donn√©es avec indicateurs re√ßues du Gateway - architecture corrompue!")
                    transformed["_routing"]["data_type"] = "corrupted_enriched_data"
                        
        elif topic == "market.data" or topic.startswith("market.data.") and not any(topic.endswith(f".{tf}") for tf in ["1m", "3m", "5m", "15m", "1d"]):
            # Format legacy ou donn√©es brutes g√©n√©riques
            transformed["_routing"]["data_type"] = "raw_market_data_legacy"
            
        elif topic == "analyzer.signals" or topic == "signals":
            transformed["_routing"]["data_type"] = "signal"
            # Validation des champs de signal
            signal_fields = ["symbol", "side", "strategy", "timestamp"]
            for field in signal_fields:
                if field not in transformed:
                    logger.warning(f"Champ signal manquant: {field}")
                    
        elif topic == "executions":
            transformed["_routing"]["data_type"] = "execution"
            
        elif topic == "orders":
            transformed["_routing"]["data_type"] = "order"
            
        return transformed

    
    def route_message(self, topic: str, message: Dict[str, Any], priority: Optional[str] = None) -> bool:
        """
        Route un message Kafka vers le canal Redis appropri√© avec gestion de priorit√©.
        
        Args:
            topic: Topic Kafka source
            message: Message √† router
            priority: Priorit√© du message ('high', 'normal', ou None pour auto-d√©tection)
            
        Returns:
            True si le routage a r√©ussi, False sinon
        """
        try:
            # Incr√©menter le compteur de messages re√ßus
            self.stats["messages_received"] += 1
            
            # ----- D√©duplication ---------------------------------
            now = time.time()
            # Nettoyage des cl√©s expir√©es
            self._dedup_cache = {k: t for k, t in self._dedup_cache.items() if now - t < self._dedup_ttl}

            # Cl√© de d√©duplication adapt√©e au type de message
            if topic.startswith("analyzer.signals"):
                # Pour les signaux : topic + symbol + side + strategy + timestamp
                dedup_key = f"{topic}:{message.get('symbol')}:{message.get('side')}:{message.get('strategy')}:{message.get('timestamp')}"
            else:
                # Pour les donn√©es de march√© : topic + timestamp + close (si pr√©sent)
                dedup_key = f"{topic}:{message.get('close_time') or message.get('start_time')}:{message.get('close')}"
            if dedup_key in self._dedup_cache:
                logger.debug(f"Message ignor√© (doublon) : {dedup_key}")
                return False

            # Marquer comme vu
            self._dedup_cache[dedup_key] = now
            # ----------------------------------------------------
            
            # === PERSISTANCE EN BASE DE DONN√âES ===
            # Sauvegarder les donn√©es de march√© en base
            if topic.startswith("market.data") and self.db_persister:
                try:
                    self.db_persister.save_market_data(topic, message)
                    logger.debug(f"üíæ Donn√©es sauv√©es: {topic}")
                except Exception as e:
                    logger.error(f"‚ùå Erreur sauvegarde base: {e}")
            # =====================================
            
            # D√©terminer la priorit√© si non sp√©cifi√©e
            if priority is None:
                # Donn√©es de march√© en temps r√©el = haute priorit√©
                if topic.startswith("market.data") and message.get('is_closed', False):
                    priority = 'high'
                # Signaux = haute priorit√©
                elif topic.startswith("signals"):
                    priority = 'high'
                else:
                    priority = 'normal'
            
            # D√©terminer le canal Redis
            channel = self._get_redis_channel(topic)
            
            if not channel:
                logger.warning(f"Aucun canal Redis trouv√© pour le topic {topic}")
                return False
            
            # Transformer le message si n√©cessaire
            transformed_message = self._transform_message(topic, message)
            
            # Ajouter l'information de priorit√©
            transformed_message["_routing"]["priority"] = priority
            
            # Tentative de publication directe
            try:
                # Publier sur Redis avec priorit√©
                if priority == 'high':
                    # Pour les messages haute priorit√©, utiliser une connexion d√©di√©e
                    self._publish_high_priority(channel, transformed_message)
                else:
                    # Publication normale
                    self.redis_client.publish(channel, transformed_message)
                
                # Incr√©menter le compteur de messages rout√©s
                self.stats["messages_routed"] += 1
                
                # Log d√©taill√© en niveau debug
                logger.debug(f"Message rout√© ({priority}): {topic} -> {channel}")
                
                return True
            except Exception as e:
                # En cas d'√©chec, mettre le message en file d'attente
                with self.queue_lock:
                    # Ajouter la priorit√© dans le tuple
                    self.message_queue.append((channel, transformed_message, priority))
                    self.stats["messages_queued"] += 1
                
                logger.warning(f"‚ùó Publication Redis √©chou√©e, message mis en file d'attente: {str(e)}")
                return False
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du routage du message: {str(e)}")
            self.stats["errors"] += 1
            return False
    
    def batch_route_messages(self, messages: List[Tuple[str, Dict[str, Any]]]) -> int:
        """
        Route un lot de messages.
        
        Args:
            messages: Liste de tuples (topic, message)
            
        Returns:
            Nombre de messages rout√©s avec succ√®s
        """
        success_count = 0
        
        for topic, message in messages:
            if self.route_message(topic, message):
                success_count += 1
        
        return success_count
    
    def get_stats(self) -> Dict[str, Any]:
        """
        R√©cup√®re les statistiques du router avec informations de priorit√©.
        
        Returns:
            Dictionnaire de statistiques
        """
        # Calculer les statistiques d√©riv√©es
        now = time.time()
        elapsed = now - self.stats["last_reset"]
        
        stats = self.stats.copy()
        stats["uptime"] = elapsed
        stats["queue_size"] = len(self.message_queue)
        stats["high_priority_queue_size"] = len(self.high_priority_queue)
        
        if elapsed > 0:
            stats["messages_per_second"] = stats["messages_routed"] / elapsed
            stats["high_priority_per_second"] = stats["high_priority_routed"] / elapsed
        else:
            stats["messages_per_second"] = 0
            stats["high_priority_per_second"] = 0
        
        stats["success_rate"] = (
            stats["messages_routed"] / max(stats["messages_received"], 1) * 100
        )
        
        return stats
    
    def reset_stats(self) -> None:
        """
        R√©initialise les compteurs de statistiques.
        """
        self.stats = {
            "messages_received": 0,
            "messages_routed": 0,
            "messages_queued": 0,
            "queue_processed": 0,
            "errors": 0,
            "last_reset": time.time()
        }
        
        logger.info("Statistiques du router r√©initialis√©es")
    
    def close(self) -> None:
        """
        Ferme proprement les ressources du router.
        """
        logger.info("Arr√™t du MessageRouter...")
        
        # Arr√™ter le thread de traitement de la file d'attente
        self.queue_processor_running = False
        
        # Attendre la fin des threads (avec un timeout)
        if self.queue_processor_thread and self.queue_processor_thread.is_alive():
            self.queue_processor_thread.join(timeout=2.0)
        
        if self.high_priority_processor_thread and self.high_priority_processor_thread.is_alive():
            self.high_priority_processor_thread.join(timeout=2.0)
        
        # Vider la file d'attente si possible
        try:
            with self.queue_lock:
                queue_size = len(self.message_queue)
                high_priority_size = len(self.high_priority_queue)
                if queue_size > 0 or high_priority_size > 0:
                    logger.warning(f"‚ö†Ô∏è Messages non trait√©s lors de la fermeture: {queue_size} normaux, {high_priority_size} haute priorit√©")
        except Exception:
            pass
        
        # Fermer les clients Redis
        if self.redis_client:
            self.redis_client.close()
        
        if self.high_priority_redis:
            self.high_priority_redis.close()
        
        logger.info("Clients Redis ferm√©s")