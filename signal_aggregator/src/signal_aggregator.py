#!/usr/bin/env python3
import logging
from typing import Dict, List, Optional, Any, TYPE_CHECKING, Union
from datetime import datetime, timedelta, timezone
from collections import defaultdict, deque
import json
import numpy as np
import time

logger = logging.getLogger(__name__)

# Type alias pour le regime de march√©
if TYPE_CHECKING:
    from enhanced_regime_detector import MarketRegime
    MarketRegimeType = Union[MarketRegime, Any]
else:
    MarketRegimeType = Any

from enhanced_regime_detector import EnhancedRegimeDetector, MarketRegime


class MarketDataAccumulator:
    """Accumule les donn√©es de march√© pour construire un historique"""
    
    def __init__(self, max_history: int = 200):
        self.max_history = max_history
        self.data_history = defaultdict(lambda: deque(maxlen=max_history))
        self.last_update = defaultdict(float)
    
    def add_market_data(self, symbol: str, data: Dict[str, Any]) -> None:
        """Ajoute des donn√©es de march√© √† l'historique"""
        try:
            timestamp = data.get('timestamp', time.time())
            
            # √âviter les doublons (m√™me timestamp)
            if timestamp <= self.last_update[symbol]:
                return
                
            # Enrichir les donn√©es avec timestamp normalis√©
            enriched_data = data.copy()
            enriched_data['timestamp'] = timestamp
            enriched_data['datetime'] = datetime.fromtimestamp(timestamp)
            
            # Ajouter √† l'historique
            self.data_history[symbol].append(enriched_data)
            self.last_update[symbol] = timestamp
            
        except Exception as e:
            logger.error(f"Erreur ajout donn√©es historiques {symbol}: {e}")
    
    def get_history(self, symbol: str, limit: int = None) -> List[Dict[str, Any]]:
        """R√©cup√®re l'historique des donn√©es pour un symbole"""
        history = list(self.data_history[symbol])
        if limit and len(history) > limit:
            return history[-limit:]
        return history
    
    def get_history_count(self, symbol: str) -> int:
        """Retourne le nombre de points historiques disponibles"""
        return len(self.data_history[symbol])


class SignalAggregator:
    """Aggregates multiple strategy signals and resolves conflicts"""
    
    # Strategy groupings by market condition
    STRATEGY_GROUPS = {
        'trend': ['EMA_Cross', 'MACD', 'Breakout'],
        'mean_reversion': ['Bollinger', 'RSI', 'Divergence'],
        'adaptive': ['Ride_or_React']
    }
    
    def __init__(self, redis_client, regime_detector, performance_tracker):
        self.redis = redis_client
        self.regime_detector = regime_detector
        self.performance_tracker = performance_tracker
        
        # Accumulateur de donn√©es de march√© pour construire l'historique
        self.market_data_accumulator = MarketDataAccumulator(max_history=200)
        
        # Nouveau d√©tecteur de r√©gime am√©lior√©
        self.enhanced_regime_detector = EnhancedRegimeDetector(redis_client)
        # Connecter l'accumulateur au d√©tecteur
        self.enhanced_regime_detector.set_market_data_accumulator(self.market_data_accumulator)
        logger.info("‚úÖ Enhanced Regime Detector activ√© avec accumulateur historique")
        
        # Signal buffer for aggregation
        self.signal_buffer = defaultdict(list)
        self.last_signal_time = {}
        
        # Cache incr√©mental pour EMAs lisses (comme dans Gateway WebSocket)
        self.ema_incremental_cache = defaultdict(lambda: defaultdict(dict))
        # Hybrid approach: load thresholds from config
        from shared.src.config import (SIGNAL_COOLDOWN_MINUTES, VOTE_THRESHOLD, 
                                     CONFIDENCE_THRESHOLD)
        self.cooldown_period = timedelta(minutes=SIGNAL_COOLDOWN_MINUTES)
        
        # Voting thresholds adaptatifs - HYBRID OPTIMIZED (plus r√©actif)
        self.min_vote_threshold = VOTE_THRESHOLD
        self.min_confidence_threshold = CONFIDENCE_THRESHOLD
        
        # Seuils sp√©ciaux pour RANGE_TIGHT - HYBRID (plus permissif)
        self.range_tight_vote_threshold = max(0.30, VOTE_THRESHOLD - 0.05)
        self.range_tight_confidence_threshold = max(0.55, CONFIDENCE_THRESHOLD - 0.05)
        
        # Monitoring stats
        try:
            from .monitoring_stats import SignalMonitoringStats
            self.monitoring_stats = SignalMonitoringStats(redis_client)
        except ImportError:
            # Fallback pour import relatif
            import sys
            import os
            sys.path.append(os.path.dirname(__file__))
            from monitoring_stats import SignalMonitoringStats
            self.monitoring_stats = SignalMonitoringStats(redis_client)
        
        # Bayesian strategy weights avec DB
        try:
            from .bayesian_weights import BayesianStrategyWeights
            # Utiliser le db_pool pass√© au constructeur
            db_pool = getattr(self, 'db_pool', None)
            self.bayesian_weights = BayesianStrategyWeights(redis_client, db_pool)
            if db_pool:
                logger.info("‚úÖ Pond√©ration bay√©sienne avec sauvegarde PostgreSQL activ√©e")
            else:
                logger.info("‚úÖ Pond√©ration bay√©sienne avec cache Redis activ√©e")
        except ImportError:
            import sys
            import os
            sys.path.append(os.path.dirname(__file__))
            from bayesian_weights import BayesianStrategyWeights
            db_pool = getattr(self, 'db_pool', None)
            self.bayesian_weights = BayesianStrategyWeights(redis_client, db_pool)
            if db_pool:
                logger.info("‚úÖ Pond√©ration bay√©sienne avec sauvegarde PostgreSQL activ√©e")
            else:
                logger.info("‚úÖ Pond√©ration bay√©sienne avec cache Redis activ√©e")
        
        # Dynamic thresholds
        try:
            from .dynamic_thresholds import DynamicThresholdManager
            self.dynamic_thresholds = DynamicThresholdManager(
                redis_client,
                target_signal_rate=0.08  # 8% des signaux devraient passer (s√©lectif)
            )
            logger.info("‚úÖ Seuils dynamiques adaptatifs activ√©s")
        except ImportError:
            import sys
            import os
            sys.path.append(os.path.dirname(__file__))
            from dynamic_thresholds import DynamicThresholdManager
            self.dynamic_thresholds = DynamicThresholdManager(
                redis_client,
                target_signal_rate=0.08
            )
            logger.info("‚úÖ Seuils dynamiques adaptatifs activ√©s")
        
    async def _update_market_data_history(self, symbol: str) -> None:
        """Met √† jour l'historique des donn√©es de march√© pour un symbole"""
        try:
            # R√©cup√©rer les donn√©es actuelles depuis Redis
            key = f"market_data:{symbol}:5m"
            data = self.redis.get(key)
            if data:
                parsed = json.loads(data) if isinstance(data, str) else data
                if isinstance(parsed, dict) and 'ultra_enriched' in parsed:
                    # Ajouter les valeurs OHLC manquantes si n√©cessaires
                    if 'open' not in parsed:
                        close_price = parsed.get('close', 0)
                        parsed['open'] = close_price
                        parsed['high'] = close_price * 1.001  # +0.1%
                        parsed['low'] = close_price * 0.999   # -0.1%
                    
                    # Ajouter √† l'accumulateur
                    self.market_data_accumulator.add_market_data(symbol, parsed)
                    
                    count = self.market_data_accumulator.get_history_count(symbol)
                    if count % 10 == 0:  # Log tous les 10 points
                        logger.info(f"üìà Historique {symbol}: {count} points accumul√©s")
                        
        except Exception as e:
            logger.error(f"Erreur mise √† jour historique {symbol}: {e}")

    async def process_signal(self, signal: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Process a raw signal and return aggregated decision with ultra-confluent validation"""
        try:
            symbol = signal['symbol']
            strategy = signal['strategy']
            
            # Normalize strategy name by removing '_Strategy' suffix
            strategy = strategy.replace('_Strategy', '')
            
            # Mettre √† jour l'historique des donn√©es de march√©
            await self._update_market_data_history(symbol)
            
            # NOUVEAU: Gestion des signaux ultra-confluents avec scoring
            is_ultra_confluent = signal.get('metadata', {}).get('ultra_confluence', False)
            signal_score = signal.get('metadata', {}).get('total_score')
            
            # Note: Removed impossible condition bug
            
            # Normalize side value
            if 'side' in signal:
                side = signal['side'].upper()
                if side in ('BUY', 'LONG'):
                    signal['side'] = 'BUY'
                elif side in ('SELL', 'SHORT'):
                    signal['side'] = 'SELL'
                else:
                    logger.warning(f"Unknown side value: {side}")
                    return None
                    
            # NOUVEAU: Traitement prioritaire pour signaux ultra-confluents de haute qualit√©
            if is_ultra_confluent and signal_score:
                logger.info(f"üî• Signal ULTRA-CONFLUENT {strategy} {signal['side']} {symbol}: score={signal_score:.1f}")
                
                # Signaux de qualit√© institutionnelle (95+) passent avec traitement express
                if signal_score >= 95:
                    logger.info(f"‚≠ê SIGNAL INSTITUTIONNEL accept√© directement: {symbol} score={signal_score:.1f}")
                    return await self._process_institutional_signal(signal)
                # Signaux excellents (85+) ont priorit√© mais validation all√©g√©e
                elif signal_score >= 85:
                    logger.info(f"‚ú® SIGNAL EXCELLENT priorit√© haute: {symbol} score={signal_score:.1f}")
                    return await self._process_excellent_signal(signal)
                # Signaux faibles (<50) sont rejet√©s imm√©diatement
                elif signal_score < 50:
                    logger.info(f"‚ùå Signal ultra-confluent rejet√© (score faible): {symbol} score={signal_score:.1f}")
                    return None
            
            # NOUVEAU: Validation multi-timeframe avec 15m (SWING CRYPTO)
            # Validation 15m pour swing trading, filtrage plus strict
            if not await self._validate_signal_with_higher_timeframe(signal):
                logger.info(f"Signal {strategy} {signal['side']} sur {symbol} rejet√© par validation 15m swing")
                return None
            
            # Handle timestamp conversion
            timestamp_str = signal.get('timestamp', signal.get('created_at'))
            if timestamp_str:
                if isinstance(timestamp_str, str):
                    timestamp = datetime.fromisoformat(timestamp_str)
                    if timestamp.tzinfo is None:
                        timestamp = timestamp.replace(tzinfo=timezone.utc)
                else:
                    timestamp = datetime.fromtimestamp(timestamp_str / 1000 if timestamp_str > 1e10 else timestamp_str, tz=timezone.utc)
            else:
                timestamp = datetime.now(timezone.utc)
            
            # Check cooldown
            if await self._is_in_cooldown(symbol):
                logger.debug(f"Symbol {symbol} in cooldown, ignoring signal")
                return None
                
            # Add to buffer
            self.signal_buffer[symbol].append(signal)
            
            # Clean old signals (keep only last 120 seconds for confluence)
            cutoff_time = timestamp - timedelta(seconds=120)
            self.signal_buffer[symbol] = [
                s for s in self.signal_buffer[symbol]
                if self._get_signal_timestamp(s) > cutoff_time
            ]
            
            # Check if we have enough signals to make a decision - MODE CONFLUENCE (1+ signaux temporaire)
            if len(self.signal_buffer[symbol]) < 1:
                return None  # Wait for more signals
                
            # Get market regime FIRST pour filtrage intelligent (enhanced if available, sinon fallback)
            if self.enhanced_regime_detector:
                # Utiliser la version async - le Signal Aggregator s'ex√©cute d√©j√† dans un contexte async
                regime, regime_metrics = await self.enhanced_regime_detector.get_detailed_regime(symbol)
                
                # NOUVEAU: Filtrage intelligent bas√© sur les r√©gimes Enhanced
                signal_filtered = await self._apply_enhanced_regime_filtering(
                    signal, regime, regime_metrics, is_ultra_confluent, signal_score, len(self.signal_buffer[symbol])
                )
                if not signal_filtered:
                    return None  # Signal rejet√© par le filtrage intelligent
                
                # Calculate aggregated signal with regime-adaptive weights
                aggregated = await self._aggregate_signals_enhanced(
                    symbol, 
                    self.signal_buffer[symbol],
                    regime,
                    regime_metrics
                )
            else:
                # Fallback vers l'ancien syst√®me
                regime = await self.regime_detector.get_regime(symbol)
                aggregated = await self._aggregate_signals(
                    symbol, 
                    self.signal_buffer[symbol],
                    regime
                )
            
            if aggregated:
                # Store source signals count before clearing buffer
                source_signals_count = len(self.signal_buffer[symbol])
                
                # Clear buffer after successful aggregation
                self.signal_buffer[symbol].clear()
                self.last_signal_time[symbol] = timestamp
                
                # Add metadata
                if self.enhanced_regime_detector and hasattr(regime, 'value'):
                    aggregated.update({
                        'aggregation_method': 'enhanced_weighted_vote',
                        'regime': regime.value,
                        'regime_metrics': regime_metrics,
                        'timestamp': timestamp.isoformat(),
                        'source_signals': source_signals_count
                    })
                else:
                    aggregated.update({
                        'aggregation_method': 'weighted_vote',
                        'regime': regime,
                        'timestamp': timestamp.isoformat(),
                        'source_signals': source_signals_count
                    })
                
                return aggregated
                
            return None
            
        except Exception as e:
            logger.error(f"Error processing signal: {e}")
            return None
            
    async def _process_institutional_signal(self, signal: Dict[str, Any]) -> Dict[str, Any]:
        """Traitement express pour signaux de qualit√© institutionnelle (95+ points)"""
        try:
            symbol = signal['symbol']
            metadata = signal.get('metadata', {})
            
            # Traitement express - validation minimale
            current_price = signal['price']
            confidence = min(signal.get('confidence', 0.9), 1.0)  # Cap √† 1.0
            
            # Force bas√©e sur le score
            score = metadata.get('total_score', 95)
            if score >= 98:
                strength = 'very_strong'
            else:
                strength = 'strong'
                
            # Utiliser les niveaux de prix calcul√©s par ultra-confluence
            price_levels = metadata.get('price_levels', {})
            # Stop-loss correct selon le side: SELL stop au dessus, BUY stop en dessous
            side = signal.get('side', 'BUY')
            default_stop = current_price * (1.025 if side == 'SELL' else 0.975)
            stop_loss = price_levels.get('stop_loss', default_stop)  # Stop plus serr√© pour signaux premium
            
            # M√©tadonn√©es enrichies
            enhanced_metadata = {
                'aggregated': True,
                'institutional_grade': True,
                'ultra_confluence': True,
                'total_score': score,
                'quality': metadata.get('quality', 'institutional'),
                'confirmation_count': metadata.get('confirmation_count', 0),
                'express_processing': True,
                'timeframes_analyzed': metadata.get('timeframes_analyzed', []),
                'stop_price': stop_loss,
                'trailing_delta': 2.0,  # Trailing plus serr√© pour signaux premium
                'recommended_size_multiplier': 1.2  # Taille l√©g√®rement augment√©e
            }
            
            # Log pour debug stop-loss
            logger.info(f"üéØ Signal institutionnel {side} {symbol}: entry={current_price:.4f}, stop={stop_loss:.4f}")
            
            result = {
                'symbol': symbol,
                'side': signal['side'],
                'price': current_price,
                'strategy': 'UltraConfluence_Institutional',
                'confidence': confidence,
                'strength': strength,
                'stop_loss': stop_loss,
                'trailing_delta': 2.0,
                'contributing_strategies': ['UltraConfluence'],
                'metadata': enhanced_metadata
            }
            
            logger.info(f"‚≠ê Signal INSTITUTIONNEL trait√©: {symbol} {signal['side']} @ {current_price:.4f} (score={score:.1f})")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement signal institutionnel: {e}")
            return None
            
    async def _process_excellent_signal(self, signal: Dict[str, Any]) -> Dict[str, Any]:
        """Traitement prioritaire pour signaux excellents (85+ points)"""
        try:
            symbol = signal['symbol']
            metadata = signal.get('metadata', {})
            
            # Validation l√©g√®re mais pr√©sente
            if await self._is_in_cooldown(symbol):
                logger.debug(f"Signal excellent {symbol} en cooldown, ignor√©")
                return None
                
            # V√©rification ADX all√©g√©e pour signaux excellents
            adx_value = await self._get_current_adx(symbol)
            score = metadata.get('total_score', 85)
            
            if adx_value and adx_value < 20 and score < 90:  # Seuil ADX plus strict seulement pour scores < 90
                logger.info(f"Signal excellent rejet√©: ADX trop faible ({adx_value:.1f}) pour score {score:.1f}")
                return None
                
            current_price = signal['price']
            confidence = signal.get('confidence', 0.85)
            
            # Ajuster la confiance bas√©e sur le score
            confidence_boost = min((score - 85) / 15 * 0.1, 0.1)  # Max 10% boost
            confidence = min(confidence + confidence_boost, 1.0)
            
            # Force bas√©e sur le score et la confluence
            confirmation_count = metadata.get('confirmation_count', 0)
            if score >= 90 and confirmation_count >= 15:
                strength = 'very_strong'
            elif score >= 85:
                strength = 'strong'
            else:
                strength = 'moderate'
                
            # Prix et stop loss optimis√©s
            price_levels = metadata.get('price_levels', {})
            # Stop-loss correct selon le side: SELL stop au dessus, BUY stop en dessous
            side = signal.get('side', 'BUY')
            default_stop = current_price * (1.02 if side == 'SELL' else 0.98)
            stop_loss = price_levels.get('stop_loss', default_stop)  # Stop mod√©r√©
            
            enhanced_metadata = {
                'aggregated': True,
                'excellent_grade': True,
                'ultra_confluence': True,
                'total_score': score,
                'quality': metadata.get('quality', 'excellent'),
                'confirmation_count': confirmation_count,
                'priority_processing': True,
                'timeframes_analyzed': metadata.get('timeframes_analyzed', []),
                'stop_price': stop_loss,
                'trailing_delta': 2.5,
                'recommended_size_multiplier': 1.1
            }
            
            # Log pour debug stop-loss
            logger.info(f"üéØ Signal excellent {side} {symbol}: entry={current_price:.4f}, stop={stop_loss:.4f}")
            
            result = {
                'symbol': symbol,
                'side': signal['side'],
                'price': current_price,
                'strategy': 'UltraConfluence_Excellent',
                'confidence': confidence,
                'strength': strength,
                'stop_loss': stop_loss,
                'trailing_delta': 2.5,
                'contributing_strategies': ['UltraConfluence'],
                'metadata': enhanced_metadata
            }
            
            # D√©finir cooldown court pour signaux excellents
            await self.set_cooldown(symbol, 60)  # 1 minute seulement
            
            logger.info(f"‚ú® Signal EXCELLENT trait√©: {symbol} {signal['side']} @ {current_price:.4f} (score={score:.1f})")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement signal excellent: {e}")
            return None
            
    def _get_signal_timestamp(self, signal: Dict[str, Any]) -> datetime:
        """Extract timestamp from signal with multiple format support"""
        timestamp_str = signal.get('timestamp', signal.get('created_at'))
        if timestamp_str:
            if isinstance(timestamp_str, str):
                timestamp = datetime.fromisoformat(timestamp_str)
                if timestamp.tzinfo is None:
                    timestamp = timestamp.replace(tzinfo=timezone.utc)
                return timestamp
            else:
                return datetime.fromtimestamp(timestamp_str / 1000 if timestamp_str > 1e10 else timestamp_str, tz=timezone.utc)
        return datetime.now(timezone.utc)
            
    async def _aggregate_signals(self, symbol: str, signals: List[Dict], 
                               regime: str) -> Optional[Dict[str, Any]]:
        """Aggregate multiple signals into a single decision"""

        # Group signals by side
        BUY_signals = []
        SELL_signals = []

        for signal in signals:
            strategy = signal['strategy']
            
            # Check if strategy is appropriate for current regime
            if not self._is_strategy_active(strategy, regime):
                logger.debug(f"Strategy {strategy} not active in {regime} regime")
                continue
                
            # Get strategy weight based on performance
            weight = await self.performance_tracker.get_strategy_weight(strategy)
            
            # Apply confidence threshold with enhanced filtering for mixed signals
            confidence = signal.get('confidence', 0.5)
            signal_is_ultra_confluent = signal.get('metadata', {}).get('ultra_confluence', False)
            signal_score = signal.get('metadata', {}).get('total_score')
            
            # NOUVEAU: Seuils adaptatifs selon le type de signal
            if signal_is_ultra_confluent and signal_score:
                # Signaux ultra-confluents : seuil plus strict
                min_threshold = 0.7
            else:
                # Signaux classiques : seuil standard
                min_threshold = self.min_confidence_threshold
                
            if confidence < min_threshold:
                logger.debug(f"Signal {strategy} filtr√©: confidence {confidence:.2f} < {min_threshold:.2f}")
                continue

            # Get side (handle both 'side' and 'side' keys)
            side = signal.get('side', signal.get('side'))
            if side in ['BUY', 'BUY']:
                side = 'BUY'
            elif side in ['SELL', 'SELL']:
                side = 'SELL'

            # Weighted signal
            weighted_signal = {
                'strategy': strategy,
                'side': side,
                'confidence': confidence,
                'weight': weight,
                'score': confidence * weight
            }

            if side == 'BUY':
                BUY_signals.append(weighted_signal)
                # Enregistrer l'acceptation dans les stats
                self.monitoring_stats.record_signal_decision(
                    strategy=strategy,
                    regime=regime.name if hasattr(regime, 'name') else str(regime),
                    symbol=symbol,
                    accepted=True,
                    confidence=confidence
                )
            elif side == 'SELL':
                SELL_signals.append(weighted_signal)
                # Enregistrer l'acceptation dans les stats
                self.monitoring_stats.record_signal_decision(
                    strategy=strategy,
                    regime=regime.name if hasattr(regime, 'name') else str(regime),
                    symbol=symbol,
                    accepted=True,
                    confidence=confidence
                )

        # Calculate total scores with quality tracking
        BUY_score = sum(s['score'] for s in BUY_signals)
        SELL_score = sum(s['score'] for s in SELL_signals)
        
        # Log signal quality breakdown for debugging
        if BUY_signals or SELL_signals:
            ultra_buy = [s for s in BUY_signals if s.get('signal_type') == 'ultra_confluent']
            classic_buy = [s for s in BUY_signals if s.get('signal_type') == 'classic']
            ultra_sell = [s for s in SELL_signals if s.get('signal_type') == 'ultra_confluent']
            classic_sell = [s for s in SELL_signals if s.get('signal_type') == 'classic']
            
            logger.debug(f"üìä {symbol} signaux: "
                        f"BUY ultra={len(ultra_buy)} classic={len(classic_buy)} "
                        f"SELL ultra={len(ultra_sell)} classic={len(classic_sell)}")

        # Determine side
        if BUY_score > SELL_score and BUY_score >= self.min_vote_threshold:
            side = 'BUY'
            confidence = BUY_score / (BUY_score + SELL_score)
            contributing_strategies = [s['strategy'] for s in BUY_signals]
        elif SELL_score > BUY_score and SELL_score >= self.min_vote_threshold:
            side = 'SELL'
            confidence = SELL_score / (BUY_score + SELL_score)
            contributing_strategies = [s['strategy'] for s in SELL_signals]
        else:
            # No clear signal
            logger.debug(f"No clear signal for {symbol}: BUY={BUY_score:.2f}, SELL={SELL_score:.2f}")
            return None
            
        # Calculate averaged stop loss (plus de take profit avec TrailingStop pur)
        relevant_signals = BUY_signals if side == 'BUY' else SELL_signals

        total_weight = sum(s['weight'] for s in relevant_signals)
        if total_weight == 0:
            return None
            
        # NOUVEAU: Calcul de stop-loss adaptatif avec ATR dynamique
        stop_loss_sum = 0
        atr_stop_loss = await self._calculate_atr_based_stop_loss(symbol, signals[0]['price'], side)
        
        for signal in signals:
            signal_side = signal.get('side', signal.get('side'))
            if signal_side == side and signal['strategy'] in contributing_strategies:
                weight = await self.performance_tracker.get_strategy_weight(signal['strategy'])
                
                # Prioriser stop ATR si disponible, sinon fallback
                if atr_stop_loss is not None:
                    stop_price = atr_stop_loss
                    logger.info(f"üéØ Stop ATR adaptatif utilis√© pour {symbol}: {stop_price:.4f}")
                else:
                    # Extract stop_price from metadata (fallback)
                    metadata = signal.get('metadata', {})
                    # Stop-loss correct selon le side: BUY stop en dessous, SELL stop au dessus - CRYPTO OPTIMIZED
                    default_stop = signal['price'] * (1.08 if side == 'SELL' else 0.92)  # 8% crypto stops (√©tait 0.2%!)
                    stop_price = metadata.get('stop_price', signal.get('stop_loss', default_stop))
                    logger.debug(f"üìä Stop fixe utilis√© pour {symbol}: {stop_price:.4f}")
                
                stop_loss_sum += stop_price * weight
                
        stop_loss = stop_loss_sum / total_weight
        
        # Get the latest price from one of the signals
        current_price = signals[0]['price'] if signals else 0.0
        
        # Create main strategy name from contributing strategies
        main_strategy = contributing_strategies[0] if contributing_strategies else 'SignalAggregator'
        
        # NOUVEAU: Volume-based confidence boost (classique)
        confidence = self._apply_volume_boost(confidence, signals)
        
        # Bonus multi-strat√©gies
        confidence = self._apply_multi_strategy_bonus(confidence, contributing_strategies)
        
        # D√©terminer la force du signal bas√©e sur la confiance - CONFLUENCE CRYPTO (tr√®s strict)
        if confidence >= 0.90:  # CONFLUENCE: Tr√®s strict pour very_strong (90%+)
            strength = 'very_strong'
        elif confidence >= 0.80:  # CONFLUENCE: Strict pour strong (80%+)
            strength = 'strong'
        elif confidence >= 0.70:  # CONFLUENCE: Plus strict pour moderate (70%+)
            strength = 'moderate'
        else:
            strength = 'weak'
            
        # Trailing stop fixe √† 3% pour syst√®me pur (TrailingStop g√®re le reste)
        trailing_delta = 3.0
        
        # NOUVEAU: Validation minimum 2 strat√©gies pour publier un signal
        if len(contributing_strategies) < 2:
            logger.info(f"‚ùå Signal rejet√©: minimum 2 strat√©gies requises, seulement {len(contributing_strategies)} trouv√©e(s) pour {symbol}")
            return None
        
        return {
            'symbol': symbol,
            'side': side,  # Use 'side' instead of 'side' for coordinator compatibility
            'price': current_price,  # Add price field required by coordinator
            'strategy': f"Aggregated_{len(contributing_strategies)}",  # Create strategy name
            'confidence': confidence,
            'strength': strength,  # Ajouter la force du signal
            'stop_loss': stop_loss,
            'trailing_delta': trailing_delta,  # NOUVEAU: Trailing stop activ√©
            'contributing_strategies': contributing_strategies,
            'BUY_score': BUY_score,
            'SELL_score': SELL_score,
            'metadata': {
                'aggregated': True,
                'contributing_strategies': contributing_strategies,
                'strategy_count': len(contributing_strategies),
                'stop_price': stop_loss,
                'trailing_delta': trailing_delta  # NOUVEAU: Ajouter au metadata
            }
        }
    
    async def _aggregate_signals_enhanced(self, symbol: str, signals: List[Dict], 
                                        regime: Any, regime_metrics: Dict[str, float]) -> Optional[Dict[str, Any]]:
        """
        Version am√©lior√©e de l'agr√©gation avec poids adaptatifs selon le r√©gime
        """
        # Obtenir les poids des strat√©gies pour ce r√©gime
        regime_weights = self.enhanced_regime_detector.get_strategy_weights_for_regime(regime)
        
        # Group signals by side
        BUY_signals = []
        SELL_signals = []

        for signal in signals:
            strategy = signal['strategy']
            
            # Get strategy weight based on performance
            performance_weight = await self.performance_tracker.get_strategy_weight(strategy)
            
            # Get regime-specific weight
            regime_weight = regime_weights.get(strategy, 1.0)
            
            # NOUVEAU: Pond√©ration bay√©sienne des strat√©gies
            bayesian_weight = self.bayesian_weights.get_bayesian_weight(strategy)
            
            # Combined weight (performance * regime * bayesian)
            combined_weight = performance_weight * regime_weight * bayesian_weight
            
            # Apply adaptive confidence threshold based on regime
            confidence = signal.get('confidence', 0.5)
            confidence_threshold = self.min_confidence_threshold
            
            # Seuils adaptatifs pour certains r√©gimes
            if hasattr(regime, 'name') and regime.name == 'RANGE_TIGHT':
                confidence_threshold = self.range_tight_confidence_threshold
                logger.debug(f"üìä Seuil RANGE_TIGHT adaptatif: {confidence_threshold} pour {strategy}")
            
            # NOUVEAU: Appliquer les seuils dynamiques
            dynamic_thresholds = self.dynamic_thresholds.get_current_thresholds()
            confidence_threshold = max(confidence_threshold, dynamic_thresholds['confidence_threshold'])
            
            if confidence < confidence_threshold:
                logger.debug(f"Signal {strategy} rejet√©: confiance {confidence:.2f} < {confidence_threshold:.2f}")
                # Enregistrer le rejet dans les stats
                self.monitoring_stats.record_signal_decision(
                    strategy=strategy,
                    regime=regime.name if hasattr(regime, 'name') else str(regime),
                    symbol=symbol,
                    accepted=False,
                    confidence=confidence,
                    reason=f"confiance {confidence:.2f} < {confidence_threshold:.2f}"
                )
                continue

            # Get side (handle both 'side' and 'side' keys)
            side = signal.get('side', signal.get('side'))
            if side in ['BUY', 'BUY']:
                side = 'BUY'
            elif side in ['SELL', 'SELL']:
                side = 'SELL'

            # Enhanced weighted signal with quality boost for ultra-confluent signals
            quality_boost = 1.0
            signal_is_ultra_confluent = signal.get('metadata', {}).get('ultra_confluence', False)
            signal_score = signal.get('metadata', {}).get('total_score')
            
            if signal_is_ultra_confluent and signal_score:
                # Boost bas√© sur le score ultra-confluent
                if signal_score >= 90:
                    quality_boost = 1.5  # +50% de poids
                elif signal_score >= 80:
                    quality_boost = 1.3  # +30% de poids
                elif signal_score >= 70:
                    quality_boost = 1.2  # +20% de poids
                    
            # Appliquer le modificateur ADX si pr√©sent
            adx_modifier = signal.get('metadata', {}).get('adx_weight_modifier', 1.0)
            final_combined_weight = combined_weight * quality_boost * adx_modifier
            
            weighted_signal = {
                'strategy': strategy,
                'side': side,
                'confidence': confidence,
                'performance_weight': performance_weight,
                'regime_weight': regime_weight,
                'quality_boost': quality_boost,
                'combined_weight': final_combined_weight,
                'score': confidence * final_combined_weight,
                'signal_type': 'ultra_confluent' if signal_is_ultra_confluent else 'classic',
                'signal_score': signal_score
            }

            if side == 'BUY':
                BUY_signals.append(weighted_signal)
                # Enregistrer l'acceptation dans les stats
                self.monitoring_stats.record_signal_decision(
                    strategy=strategy,
                    regime=regime.name if hasattr(regime, 'name') else str(regime),
                    symbol=symbol,
                    accepted=True,
                    confidence=confidence
                )
            elif side == 'SELL':
                SELL_signals.append(weighted_signal)
                # Enregistrer l'acceptation dans les stats
                self.monitoring_stats.record_signal_decision(
                    strategy=strategy,
                    regime=regime.name if hasattr(regime, 'name') else str(regime),
                    symbol=symbol,
                    accepted=True,
                    confidence=confidence
                )

        # Calculate total scores
        BUY_score = sum(s['score'] for s in BUY_signals)
        SELL_score = sum(s['score'] for s in SELL_signals)

        # Enhanced decision logic based on regime avec seuils dynamiques
        min_threshold = self._get_regime_threshold(regime)
        
        # Adapter le seuil de vote pour RANGE_TIGHT
        if hasattr(regime, 'name') and regime.name == 'RANGE_TIGHT':
            min_threshold = self.range_tight_vote_threshold
            logger.debug(f"üìä Seuil de vote RANGE_TIGHT adaptatif: {min_threshold}")
        
        # NOUVEAU: Appliquer les seuils dynamiques
        dynamic_thresholds = self.dynamic_thresholds.get_current_thresholds()
        min_threshold = max(min_threshold, dynamic_thresholds['vote_threshold'])
        logger.debug(f"üéØ Seuil vote dynamique appliqu√©: {min_threshold}")
        
        # Determine side
        if BUY_score > SELL_score and BUY_score >= min_threshold:
            side = 'BUY'
            confidence = BUY_score / (BUY_score + SELL_score)
            contributing_strategies = list(set(s['strategy'] for s in BUY_signals))  # D√©-dupliquer
            relevant_signals = BUY_signals
        elif SELL_score > BUY_score and SELL_score >= min_threshold:
            side = 'SELL'
            confidence = SELL_score / (BUY_score + SELL_score)
            contributing_strategies = list(set(s['strategy'] for s in SELL_signals))  # D√©-dupliquer
            relevant_signals = SELL_signals
        else:
            # No clear signal
            logger.debug(f"No clear signal for {symbol} in {regime.value}: BUY={BUY_score:.2f}, SELL={SELL_score:.2f}")
            return None
            
        # Calculate averaged stop loss
        total_weight = sum(s['combined_weight'] for s in relevant_signals)
        if total_weight == 0:
            return None
            
        # NOUVEAU: Calcul de stop-loss adaptatif Enhanced avec ATR dynamique
        stop_loss_sum = 0
        atr_stop_loss = await self._calculate_atr_based_stop_loss(symbol, signals[0]['price'], side)
        
        for signal in signals:
            signal_side = signal.get('side', signal.get('side'))
            if signal_side == side and signal['strategy'] in contributing_strategies:
                # Find the corresponding weighted signal
                weighted_sig = next((s for s in relevant_signals if s['strategy'] == signal['strategy']), None)
                if weighted_sig:
                    weight = weighted_sig['combined_weight']
                    
                    # Prioriser stop ATR adaptatif si disponible
                    if atr_stop_loss is not None:
                        stop_price = atr_stop_loss
                        logger.info(f"üéØ Stop ATR Enhanced utilis√© pour {symbol}: {stop_price:.4f}")
                    else:
                        # Fallback: Extract stop_price from metadata
                        metadata = signal.get('metadata', {})
                        # Stop-loss correct selon le side: BUY stop en dessous, SELL stop au dessus - CRYPTO OPTIMIZED
                        default_stop = signal['price'] * (1.08 if side == 'SELL' else 0.92)  # 8% crypto stops (√©tait 0.2%!)
                        stop_price = metadata.get('stop_price', signal.get('stop_loss', default_stop))
                        logger.debug(f"üìä Stop fixe Enhanced utilis√© pour {symbol}: {stop_price:.4f}")
                    
                    stop_loss_sum += stop_price * weight
                
        stop_loss = stop_loss_sum / total_weight
        
        # Get the latest price from one of the signals
        current_price = signals[0]['price'] if signals else 0.0
        
        # Create main strategy name from contributing strategies
        main_strategy = contributing_strategies[0] if contributing_strategies else 'SignalAggregator'
        
        # Performance-based adaptive boost
        confidence = await self._apply_performance_boost(confidence, contributing_strategies)
        
        # Regime-adaptive confidence boost
        confidence = self._apply_regime_confidence_boost(confidence, regime, regime_metrics)
        
        # NOUVEAU: Volume-based confidence boost
        confidence = self._apply_volume_boost(confidence, signals)
        
        # Bonus multi-strat√©gies
        confidence = self._apply_multi_strategy_bonus(confidence, contributing_strategies)
        
        # D√©terminer la force du signal bas√©e sur la confiance et le r√©gime
        strength = self._determine_signal_strength(confidence, regime)
        
        # VRAIE logique pour 'moderate' avec ‚â•2 strat√©gies
        # Assouplir la force si multiple strategies en r√©gime strict
        if (strength == 'moderate' and len(contributing_strategies) >= 2 and 
            hasattr(regime, 'name') and regime.name in ['RANGE_TIGHT', 'RANGE_VOLATILE']):
            logger.info(f"‚úÖ Force 'moderate' VRAIMENT accept√©e: {len(contributing_strategies)} strat√©gies convergent "
                       f"en {regime.name} pour {symbol}")
            # Force sera valid√©e comme acceptable plus tard
        
        # Trailing stop fixe √† 8% pour syst√®me crypto pur
        trailing_delta = 8.0  # Crypto optimized (√©tait 3.0%)
        
        # NOUVEAU: Validation minimum 2 strat√©gies pour publier un signal
        if len(contributing_strategies) < 2:
            logger.info(f"‚ùå Signal rejet√©: minimum 2 strat√©gies requises, seulement {len(contributing_strategies)} trouv√©e(s) pour {symbol}")
            return None
        
        # VALIDATION FINALE: Override pour 'moderate' avec ‚â•2 strat√©gies
        final_strength = strength
        if (strength == 'moderate' and len(contributing_strategies) >= 2 and 
            hasattr(regime, 'name') and regime.name in ['RANGE_TIGHT', 'RANGE_VOLATILE']):
            # Force accept√©e malgr√© les r√®gles strictes du r√©gime
            logger.info(f"üöÄ Override 'moderate' appliqu√©: {len(contributing_strategies)} strat√©gies "
                       f"en {regime.name} pour {symbol}")
        
        # NOUVEAU: Validation finale avec seuils dynamiques
        vote_weight = max(BUY_score, SELL_score)
        if not self.dynamic_thresholds.should_accept_signal(confidence, vote_weight):
            logger.info(f"Signal {side} {symbol} rejet√© par seuils dynamiques - confiance: {confidence:.3f}, vote: {vote_weight:.3f}")
            return None
        
        # NOUVEAU: V√©rifier le debounce pour √©viter les signaux group√©s
        if not await self._check_signal_debounce(symbol, side):
            logger.info(f"Signal {side} {symbol} rejet√© par filtre debounce")
            return None
        
        return {
            'symbol': symbol,
            'side': side,
            'price': current_price,
            'strategy': f"Aggregated_{len(contributing_strategies)}",
            'confidence': confidence,
            'strength': final_strength,
            'stop_loss': stop_loss,
            'trailing_delta': trailing_delta,
            'contributing_strategies': contributing_strategies,
            'BUY_score': BUY_score,
            'SELL_score': SELL_score,
            'regime_analysis': {
                'regime': regime.value,
                'metrics': regime_metrics,
                'applied_weights': {s['strategy']: s['regime_weight'] for s in relevant_signals}
            },
            'metadata': {
                'aggregated': True,
                'contributing_strategies': contributing_strategies,
                'strategy_count': len(contributing_strategies),
                'stop_price': stop_loss,
                'trailing_delta': trailing_delta,
                'regime_adaptive': True,
                'regime': regime.value,
                'volume_boosted': True,  # Indicateur que le volume a √©t√© pris en compte
                'volume_analysis': self._extract_volume_summary(signals)
            }
        }
    
    def _get_regime_threshold(self, regime: Any) -> float:
        """Retourne le seuil de vote minimum selon le r√©gime"""
        if MarketRegime is None:
            return self.min_vote_threshold
            
        thresholds = {
            MarketRegime.STRONG_TREND_UP: 0.6,
            MarketRegime.STRONG_TREND_DOWN: 0.6,
            MarketRegime.TREND_UP: 0.5,
            MarketRegime.TREND_DOWN: 0.5,
            MarketRegime.WEAK_TREND_UP: 0.4,
            MarketRegime.WEAK_TREND_DOWN: 0.4,
            MarketRegime.RANGE_TIGHT: 0.7,  # Plus strict en range serr√©
            MarketRegime.RANGE_VOLATILE: 0.6,
            MarketRegime.UNDEFINED: 0.8  # Tr√®s prudent si ind√©fini
        }
        return thresholds.get(regime, self.min_vote_threshold)
    
    def _get_single_strategy_threshold(self, regime: Any) -> float:
        """Retourne le seuil de confiance pour les signaux d'une seule strat√©gie selon le r√©gime"""
        if MarketRegime is None:
            return 0.8
            
        thresholds = {
            MarketRegime.STRONG_TREND_UP: 0.7,
            MarketRegime.STRONG_TREND_DOWN: 0.7,
            MarketRegime.TREND_UP: 0.75,
            MarketRegime.TREND_DOWN: 0.75,
            MarketRegime.WEAK_TREND_UP: 0.8,
            MarketRegime.WEAK_TREND_DOWN: 0.8,
            MarketRegime.RANGE_TIGHT: 0.85,  # Tr√®s strict en range serr√©
            MarketRegime.RANGE_VOLATILE: 0.8,
            MarketRegime.UNDEFINED: 0.9  # Tr√®s prudent si ind√©fini
        }
        return thresholds.get(regime, 0.8)
    
    def _apply_regime_confidence_boost(self, confidence: float, regime: Any, metrics: Dict[str, float]) -> float:
        """Applique un boost de confiance bas√© sur les m√©triques du r√©gime"""
        # Boost bas√© sur la force de la tendance (ADX)
        adx = metrics.get('adx', 20)
        if adx > 40:  # Tendance tr√®s forte
            confidence *= 1.1
        elif adx > 30:  # Tendance forte
            confidence *= 1.05
        
        # Boost bas√© sur le momentum (ROC)
        roc = abs(metrics.get('roc', 0))
        if roc > 5:  # Momentum fort
            confidence *= 1.05
        
        # Penalty pour les r√©gimes ind√©finis ou instables
        if MarketRegime is not None:
            if regime == MarketRegime.UNDEFINED:
                confidence *= 0.9
            elif regime in [MarketRegime.RANGE_VOLATILE]:
                # Ne pas p√©naliser les strat√©gies de mean-reversion en range
                # Note: cette logique est maintenant dans _apply_enhanced_regime_filtering
                confidence *= 0.95
        
        return min(1.0, confidence)  # Cap √† 1.0
    
    async def _get_technical_context(self, symbol: str) -> Dict[str, Any]:
        """
        R√©cup√®re le contexte technique enrichi pour un symbole
        
        Returns:
            Dictionnaire avec les indicateurs techniques actuels
        """
        try:
            # CORRECTION: Import direct avec chemin complet au lieu de manipulation sys.path
            from shared.src.technical_indicators import TechnicalIndicators
            indicators = TechnicalIndicators()
            
            # R√©cup√©rer les donn√©es 5m depuis Redis
            market_data_key = f"market_data:{symbol}:5m"
            data_5m = self.redis.get(market_data_key)
            
            context = {
                'macd': None,
                'obv': None, 
                'roc': None,
                'available': False
            }
            
            if not data_5m or not isinstance(data_5m, dict):
                return context
                
            # Extraire les prix historiques
            prices = data_5m.get('prices', [])
            volumes = data_5m.get('volumes', [])
            highs = data_5m.get('highs', [])
            lows = data_5m.get('lows', [])
            
            if len(prices) < 30:  # Minimum pour les calculs
                return context
            
            # Calculer MACD
            macd_data = indicators.calculate_macd(prices)
            if macd_data['macd_line'] is not None:
                context['macd'] = macd_data
            
            # Calculer OBV approximatif (si volumes disponibles)
            if len(volumes) >= len(prices):
                try:
                    obv_value = indicators.calculate_obv(prices, volumes)
                    if obv_value is not None:
                        context['obv'] = obv_value
                except:
                    pass  # OBV optionnel
            
            # Calculer ROC
            try:
                roc_value = indicators.calculate_roc(prices, period=10)
                if roc_value is not None:
                    context['roc'] = roc_value
            except:
                pass  # ROC optionnel
            
            context['available'] = True
            return context
            
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration contexte technique pour {symbol}: {e}")
            return {'macd': None, 'obv': None, 'roc': None, 'available': False}
    
    def _validate_macd_trend(self, technical_context: Dict[str, Any], expected_trend: str) -> Optional[bool]:
        """
        Valide si le MACD confirme la tendance attendue
        
        Args:
            technical_context: Contexte technique
            expected_trend: 'bullish' ou 'bearish'
            
        Returns:
            True/False si MACD confirme, None si pas de donn√©es
        """
        try:
            macd_data = technical_context.get('macd')
            if not macd_data or not macd_data.get('macd_line'):
                return None
                
            macd_line = macd_data['macd_line']
            macd_signal = macd_data.get('macd_signal')
            macd_histogram = macd_data.get('macd_histogram')
            
            if macd_signal is None:
                return None
            
            if expected_trend == 'bullish':
                # Tendance haussi√®re: MACD au-dessus signal ET histogram positif
                return macd_line > macd_signal and (macd_histogram is None or macd_histogram > 0)
            elif expected_trend == 'bearish':
                # Tendance baissi√®re: MACD en-dessous signal ET histogram n√©gatif
                return macd_line < macd_signal and (macd_histogram is None or macd_histogram < 0)
                
            return None
            
        except Exception as e:
            logger.error(f"Erreur validation MACD: {e}")
            return None
    
    def _validate_obv_trend(self, technical_context: Dict[str, Any], side: str) -> Optional[bool]:
        """
        Valide si l'OBV confirme le c√¥t√© du signal avec analyse de tendance historique
        
        Args:
            technical_context: Contexte technique
            side: 'BUY' ou 'SELL'
            
        Returns:
            True si OBV confirme, False sinon, None si pas de donn√©es
        """
        try:
            obv_current = technical_context.get('obv')
            if obv_current is None:
                return None
            
            # Essayer de r√©cup√©rer l'historique OBV r√©cent
            symbol = technical_context.get('symbol', 'UNKNOWN')
            
            try:
                # R√©cup√©rer les derni√®res donn√©es depuis Redis pour calculer la tendance OBV
                import json
                recent_key = f"market_data:{symbol}:recent"
                recent_data = self.redis_client.lrange(recent_key, 0, 9)  # 10 derni√®res valeurs
                
                if len(recent_data) >= 3:  # Besoin d'au moins 3 points pour une tendance
                    obv_history = []
                    
                    for data_str in recent_data:
                        try:
                            data = json.loads(data_str)
                            if 'obv' in data and data['obv'] is not None:
                                obv_history.append(float(data['obv']))
                        except (json.JSONDecodeError, KeyError, ValueError):
                            continue
                    
                    # Ajouter l'OBV actuel
                    obv_history.append(float(obv_current))
                    
                    if len(obv_history) >= 3:
                        # Calculer la tendance OBV sur les derniers points
                        recent_slope = self._calculate_obv_slope(obv_history[-3:])
                        overall_slope = self._calculate_obv_slope(obv_history)
                        
                        # Validation bas√©e sur la tendance OBV
                        if side == 'BUY':
                            # Pour BUY: OBV doit √™tre en tendance haussi√®re (volume d'achat croissant)
                            obv_confirms = recent_slope > 0 or (overall_slope > 0 and recent_slope >= -0.1)
                            logger.debug(f"üìà OBV validation BUY {symbol}: recent_slope={recent_slope:.2f}, overall_slope={overall_slope:.2f} ‚Üí {obv_confirms}")
                            return obv_confirms
                        else:  # SELL
                            # Pour SELL: OBV doit √™tre en tendance baissi√®re (volume de vente croissant) 
                            obv_confirms = recent_slope < 0 or (overall_slope < 0 and recent_slope <= 0.1)
                            logger.debug(f"üìâ OBV validation SELL {symbol}: recent_slope={recent_slope:.2f}, overall_slope={overall_slope:.2f} ‚Üí {obv_confirms}")
                            return obv_confirms
                            
            except Exception as redis_error:
                logger.warning(f"Impossible de r√©cup√©rer l'historique OBV pour {symbol}: {redis_error}")
            
            # Fallback: validation simplifi√©e si pas d'historique disponible
            # Comparer l'OBV actuel avec une valeur de r√©f√©rence basique
            volume_ratio = technical_context.get('volume_ratio', 1.0)
            
            if side == 'BUY':
                # BUY: favorable si volume ratio √©lev√© (indique plus d'activit√© d'achat)
                return volume_ratio >= 1.0
            else:  # SELL  
                # SELL: on accepte m√™me avec volume normal (vente peut se faire avec moins de volume)
                return volume_ratio >= 0.7
            
        except Exception as e:
            logger.error(f"Erreur validation OBV: {e}")
            return None
    
    def _calculate_obv_slope(self, obv_values: List[float]) -> float:
        """
        Calcule la pente de la tendance OBV
        
        Args:
            obv_values: Liste des valeurs OBV chronologiques
            
        Returns:
            Pente (positive = tendance haussi√®re, n√©gative = tendance baissi√®re)
        """
        try:
            if len(obv_values) < 2:
                return 0.0
                
            # Calcul simple de la pente moyenne
            n = len(obv_values)
            x_values = list(range(n))
            
            # R√©gression lin√©aire simple: slope = Œ£((x-xÃÑ)(y-»≥)) / Œ£((x-xÃÑ)¬≤)
            x_mean = sum(x_values) / n
            y_mean = sum(obv_values) / n
            
            numerator = sum((x - x_mean) * (y - y_mean) for x, y in zip(x_values, obv_values))
            denominator = sum((x - x_mean) ** 2 for x in x_values)
            
            if denominator == 0:
                return 0.0
                
            slope = numerator / denominator
            return slope
            
        except Exception as e:
            logger.error(f"Erreur calcul pente OBV: {e}")
            return 0.0
    
    def _check_roc_acceleration(self, technical_context: Dict[str, Any], side: str) -> bool:
        """
        V√©rifie si le ROC indique une acc√©l√©ration dans la direction du signal
        
        Args:
            technical_context: Contexte technique
            side: 'BUY' ou 'SELL'
            
        Returns:
            True si acc√©l√©ration d√©tect√©e, False sinon
        """
        try:
            roc_value = technical_context.get('roc')
            if roc_value is None:
                return False
            
            # ROC positif = acc√©l√©ration haussi√®re, ROC n√©gatif = acc√©l√©ration baissi√®re
            if side == 'BUY':
                # Pour BUY: chercher acc√©l√©ration haussi√®re (ROC > 2%)
                return roc_value > 2.0
            elif side == 'SELL':
                # Pour SELL: chercher acc√©l√©ration baissi√®re (ROC < -2%)
                return roc_value < -2.0
                
            return False
            
        except Exception as e:
            logger.error(f"Erreur v√©rification ROC: {e}")
            return False
    
    async def _calculate_atr_based_stop_loss(self, symbol: str, entry_price: float, side: str) -> Optional[float]:
        """
        Calcule un stop-loss adaptatif bas√© sur l'ATR pour optimiser selon la volatilit√©
        
        Args:
            symbol: Symbole du trading
            entry_price: Prix d'entr√©e
            side: 'BUY' ou 'SELL'
            
        Returns:
            Prix de stop-loss adaptatif ou None si impossible
        """
        try:
            # CORRECTION: Import direct avec chemin complet au lieu de manipulation sys.path
            from shared.src.technical_indicators import TechnicalIndicators
            indicators = TechnicalIndicators()
            
            # R√©cup√©rer les donn√©es OHLC depuis Redis
            market_data_key = f"market_data:{symbol}:5m"
            data_5m = self.redis.get(market_data_key)
            
            if not data_5m or not isinstance(data_5m, dict):
                logger.debug(f"Donn√©es 5m non disponibles pour ATR {symbol}")
                return None
                
            # Extraire les donn√©es OHLC
            highs = data_5m.get('highs', [])
            lows = data_5m.get('lows', [])
            closes = data_5m.get('closes', data_5m.get('prices', []))
            
            if len(highs) < 14 or len(lows) < 14 or len(closes) < 14:
                logger.debug(f"Pas assez de donn√©es OHLC pour ATR {symbol}")
                return None
            
            # Calculer ATR(14)
            atr_value = indicators.calculate_atr(highs, lows, closes, period=14)
            if atr_value is None:
                logger.debug(f"Calcul ATR √©chou√© pour {symbol}")
                return None
            
            # R√©cup√©rer ADX pour adapter le multiplicateur
            adx_value = await self._get_current_adx(symbol)
            
            # Multiplicateur ATR adaptatif selon l'ADX (force de tendance)
            if adx_value is not None:
                if adx_value > 40:  # Tendance tr√®s forte
                    atr_multiplier = 2.0  # Stop plus serr√© en tendance forte
                    logger.debug(f"ADX forte ({adx_value:.1f}): multiplicateur ATR 2.0x")
                elif adx_value > 25:  # Tendance mod√©r√©e
                    atr_multiplier = 2.5  # Standard
                    logger.debug(f"ADX mod√©r√©e ({adx_value:.1f}): multiplicateur ATR 2.5x")
                else:  # Tendance faible ou range
                    atr_multiplier = 3.0  # Stop plus large en range
                    logger.debug(f"ADX faible ({adx_value:.1f}): multiplicateur ATR 3.0x")
            else:
                atr_multiplier = 2.5  # Par d√©faut
                logger.debug(f"ADX non disponible: multiplicateur ATR par d√©faut 2.5x")
            
            # Calculer le stop-loss selon le c√¥t√©
            atr_distance = atr_value * atr_multiplier
            
            if side == 'BUY':
                # BUY: stop en dessous du prix d'entr√©e
                stop_loss = entry_price - atr_distance
            else:  # SELL
                # SELL: stop au-dessus du prix d'entr√©e
                stop_loss = entry_price + atr_distance
            
            # Validation: s'assurer que le stop n'est pas trop proche (minimum 0.5%)
            min_distance_percent = 0.005  # 0.5%
            min_distance = entry_price * min_distance_percent
            
            if side == 'BUY':
                if entry_price - stop_loss < min_distance:
                    stop_loss = entry_price - min_distance
                    logger.debug(f"Stop BUY ajust√© au minimum 0.5%: {stop_loss:.4f}")
            else:  # SELL
                if stop_loss - entry_price < min_distance:
                    stop_loss = entry_price + min_distance
                    logger.debug(f"Stop SELL ajust√© au minimum 0.5%: {stop_loss:.4f}")
            
            # Validation: s'assurer que le stop n'est pas trop loin (maximum 10%)
            max_distance_percent = 0.10  # 10%
            max_distance = entry_price * max_distance_percent
            
            if side == 'BUY':
                if entry_price - stop_loss > max_distance:
                    stop_loss = entry_price - max_distance
                    logger.debug(f"Stop BUY plafonn√© √† 10%: {stop_loss:.4f}")
            else:  # SELL
                if stop_loss - entry_price > max_distance:
                    stop_loss = entry_price + max_distance
                    logger.debug(f"Stop SELL plafonn√© √† 10%: {stop_loss:.4f}")
            
            distance_percent = abs(stop_loss - entry_price) / entry_price * 100
            logger.info(f"üéØ Stop ATR calcul√© pour {symbol} {side}: {stop_loss:.4f} "
                       f"(distance: {distance_percent:.2f}%, ATR: {atr_value:.4f}, mult: {atr_multiplier}x)")
            
            return round(stop_loss, 6)
            
        except Exception as e:
            logger.error(f"Erreur calcul stop ATR pour {symbol}: {e}")
            return None
    
    async def _apply_performance_boost(self, confidence: float, contributing_strategies: List[str]) -> float:
        """Applique un boost adaptatif bas√© sur la performance des strat√©gies"""
        if not hasattr(self, 'performance_tracker') or not self.performance_tracker:
            return confidence
        
        try:
            boost_factor = 1.0
            
            for strategy in contributing_strategies:
                # Obtenir le poids de performance (1.0 = neutre, >1.0 = surperformance)
                performance_weight = await self.performance_tracker.get_strategy_weight(strategy)
                
                if performance_weight > 1.1:  # Plus de 10% au-dessus du benchmark
                    # Boost progressif selon la surperformance
                    individual_boost = 1.0 + (performance_weight - 1.0) * 0.2  # Max +20% pour 2x performance
                    boost_factor *= individual_boost
                    logger.debug(f"üöÄ Boost performance pour {strategy}: {performance_weight:.2f} -> boost {individual_boost:.2f}")
                
                elif performance_weight < 0.9:  # Plus de 10% en-dessous du benchmark
                    # Malus mod√©r√© pour sous-performance
                    individual_malus = max(0.95, 1.0 - (1.0 - performance_weight) * 0.1)  # Max -5%
                    boost_factor *= individual_malus
                    logger.debug(f"üìâ Malus performance pour {strategy}: {performance_weight:.2f} -> malus {individual_malus:.2f}")
            
            # Limiter le boost total
            boost_factor = min(1.15, max(0.95, boost_factor))  # Entre -5% et +15%
            
            if boost_factor != 1.0:
                logger.info(f"üìä Boost performance global: {boost_factor:.2f} pour {contributing_strategies}")
            
            return confidence * boost_factor
            
        except Exception as e:
            logger.error(f"Erreur dans boost performance: {e}")
            return confidence
    
    def _determine_signal_strength(self, confidence: float, regime: Any) -> str:
        """D√©termine la force du signal bas√©e sur la confiance et le r√©gime"""
        # Seuils standardis√©s align√©s avec analyzer
        # moderate ‚â• 0.55, strong ‚â• 0.75, very_strong ‚â• 0.9
        if confidence >= 0.9:
            return 'very_strong'
        elif confidence >= 0.75:
            return 'strong'
        elif confidence >= 0.55:
            return 'moderate'
        else:
            return 'weak'
    
    def _strength_to_normalized_force(self, strength: str) -> float:
        """Convertit la force textuelle en valeur normalis√©e 0-1"""
        strength_mapping = {
            'weak': 0.25,
            'moderate': 0.5,
            'strong': 0.75,
            'very_strong': 1.0
        }
        return strength_mapping.get(strength, 0.5)
        
    def _is_strategy_active(self, strategy: str, regime: str) -> bool:
        """Check if a strategy should be active in current regime"""
        
        # Adaptive strategies are always active
        if strategy in self.STRATEGY_GROUPS['adaptive']:
            return True
            
        # Handle enhanced regime codes
        if regime.startswith('STRONG_TREND') or regime.startswith('TREND'):
            return strategy in self.STRATEGY_GROUPS['trend']
            
        # Handle range regimes (RANGE_TIGHT, RANGE_VOLATILE, etc.)
        elif regime.startswith('RANGE'):
            return strategy in self.STRATEGY_GROUPS['mean_reversion']
            
        # Handle other enhanced regimes
        elif regime in ['BREAKOUT_UP', 'BREAKOUT_DOWN']:
            # Breakout regimes favor trend strategies
            return strategy in self.STRATEGY_GROUPS['trend']
        elif regime == 'VOLATILE':
            # In volatile markets, adaptive strategies work best
            return strategy in self.STRATEGY_GROUPS['adaptive']
            
        # In undefined regime, all strategies are active
        return True
        
    async def _is_in_cooldown(self, symbol: str) -> bool:
        """Check if symbol is in cooldown period"""
        
        # Check local cooldown
        if symbol in self.last_signal_time:
            time_since_last = datetime.now(timezone.utc) - self.last_signal_time[symbol]
            if time_since_last < self.cooldown_period:
                return True
                
        # Check Redis for distributed cooldown
        cooldown_key = f"signal_cooldown:{symbol}"
        cooldown = self.redis.get(cooldown_key)
        
        return cooldown is not None
        
    async def set_cooldown(self, symbol: str, duration_seconds: int = 180):
        """Set cooldown for a symbol"""
        cooldown_key = f"signal_cooldown:{symbol}"
        self.redis.set(cooldown_key, "1", expiration=duration_seconds)
    
    async def _validate_signal_with_higher_timeframe(self, signal: Dict[str, Any]) -> bool:
        """
        Valide un signal 1m avec le contexte 15m enrichi pour √©viter les faux signaux.
        
        Logique de validation enrichie :
        - Signal BUY : valid√© si tendance 15m haussi√®re + BB position favorable + Stochastic non surachat
        - Signal SELL : valid√© si tendance 15m baissi√®re + BB position favorable + Stochastic non survente
        - Utilise ATR pour adapter dynamiquement les seuils

        Args:
            signal: Signal 1m √† valider
            
        Returns:
            True si le signal est valid√©, False sinon
        """
        try:
            symbol = signal['symbol']
            side = signal['side']

            # R√©cup√©rer les donn√©es 15m r√©centes depuis Redis (MODE SWING CRYPTO)
            market_data_key = f"market_data:{symbol}:15m"
            data_5m = self.redis.get(market_data_key)
            
            if not data_5m:
                # Si pas de donn√©es 15m, on accepte le signal (mode d√©grad√©)
                logger.warning(f"Pas de donn√©es 15m pour {symbol}, validation swing en mode d√©grad√©")
                return True
            
            # Le RedisClient parse automatiquement les donn√©es JSON
            if not isinstance(data_5m, dict):
                logger.warning(f"Donn√©es 5m invalides pour {symbol}: type {type(data_5m)}")
                return True
            
            # CORRECTION: V√©rifier la fra√Æcheur des donn√©es 5m
            last_update = data_5m.get('last_update')
            if last_update:
                from datetime import datetime, timezone
                try:
                    if isinstance(last_update, str):
                        update_time = datetime.fromisoformat(last_update.replace('Z', '+00:00'))
                    else:
                        update_time = datetime.fromtimestamp(last_update, tz=timezone.utc)
                    
                    age_seconds = (datetime.now(timezone.utc) - update_time).total_seconds()
                    if age_seconds > 120:  # Plus de 2 minutes = donn√©es stales
                        logger.warning(f"Donn√©es 5m trop anciennes pour {symbol} ({age_seconds:.0f}s), bypass validation")
                        return True
                except Exception as e:
                    logger.warning(f"Erreur parsing timestamp 5m pour {symbol}: {e}")
                    return True
            
            # Calculer la tendance 5m avec une EMA simple (MODE SCALPING)
            prices = data_5m.get('prices', [])
            if len(prices) < 5:
                # Pas assez de donn√©es pour une tendance fiable (seuil r√©duit pour scalping)
                return True
            
            # HARMONISATION: EMA 21 vs EMA 50 pour coh√©rence avec les strat√©gies
            if len(prices) < 50:
                return True  # Pas assez de donn√©es pour EMA 50
            
            # AM√âLIORATION : Utiliser EMAs incr√©mentales pour courbes lisses
            current_price = prices[-1] if prices else 0
            ema_21 = self._get_or_calculate_ema_incremental(symbol, current_price, 21)
            ema_50 = self._get_or_calculate_ema_incremental(symbol, current_price, 50)
            
            # LOGIQUE SOPHISTIQU√âE : Analyser la force et le momentum de la tendance
            
            # Calculer la v√©locit√© des EMAs (momentum) - m√©thode am√©lior√©e
            # R√©cup√©rer les EMAs pr√©c√©dentes depuis le cache pour v√©locit√©
            timeframe = "1m"
            cache = self.ema_incremental_cache.get(symbol, {}).get(timeframe, {})
            ema_21_prev = cache.get('ema_21_prev', ema_21)
            ema_50_prev = cache.get('ema_50_prev', ema_50)
            
            # Calculer v√©locit√© avec EMAs lisses
            ema_21_velocity = (ema_21 - ema_21_prev) / ema_21_prev if ema_21_prev > 0 else 0
            ema_50_velocity = (ema_50 - ema_50_prev) / ema_50_prev if ema_50_prev > 0 else 0
            
            # Stocker les valeurs actuelles comme "pr√©c√©dentes" pour le prochain calcul
            cache['ema_21_prev'] = ema_21
            cache['ema_50_prev'] = ema_50
            
            # Calculer la force de la tendance
            trend_strength = abs(ema_21 - ema_50) / ema_50 if ema_50 > 0 else 0
            
            # Classification sophistiqu√©e de la tendance
            if ema_21 > ema_50 * 1.015:  # +1.5% = forte haussi√®re
                trend_5m = "STRONG_BULLISH"
            elif ema_21 > ema_50 * 1.005:  # +0.5% = faible haussi√®re
                trend_5m = "WEAK_BULLISH"
            elif ema_21 < ema_50 * 0.985:  # -1.5% = forte baissi√®re  
                trend_5m = "STRONG_BEARISH"
            elif ema_21 < ema_50 * 0.995:  # -0.5% = faible baissi√®re
                trend_5m = "WEAK_BEARISH"
            else:
                trend_5m = "NEUTRAL"
            
            # D√©tecter si la tendance s'affaiblit (divergence)
            trend_weakening = False
            if trend_5m in ["STRONG_BULLISH", "WEAK_BULLISH"] and ema_21_velocity < 0:
                trend_weakening = True  # Tendance haussi√®re qui ralentit
            elif trend_5m in ["STRONG_BEARISH", "WEAK_BEARISH"] and ema_21_velocity > 0:
                trend_weakening = True  # Tendance baissi√®re qui ralentit
            
            # DEBUG: Log d√©taill√© pour comprendre les rejets
            logger.info(f"üîç {symbol} | Prix={current_price:.4f} | EMA21={ema_21:.4f} | EMA50={ema_50:.4f} | Tendance={trend_5m} | Signal={side} | Velocity21={ema_21_velocity*100:.2f}% | Weakening={trend_weakening}")
            
            # LOGIQUE SOPHISTIQU√âE DE VALIDATION
            rejection_reason = None
            
            if side == "BUY":
                # √âviter d'acheter dans une forte mont√©e (risque de sommet)
                if trend_5m == "STRONG_BULLISH" and not trend_weakening:
                    rejection_reason = "forte tendance haussi√®re en cours, risque de sommet"
                # √âviter d'acheter un crash violent (couteau qui tombe)
                elif trend_5m == "STRONG_BEARISH" and ema_21_velocity < -0.01:  # Acc√©l√©ration baissi√®re > 1%
                    rejection_reason = "crash violent en cours, √©viter le couteau qui tombe"
                    
            elif side == "SELL":
                # √âviter de vendre dans une forte baisse (risque de creux)  
                if trend_5m == "STRONG_BEARISH" and not trend_weakening:
                    rejection_reason = "forte tendance baissi√®re en cours, risque de creux"
                # √âviter de vendre une pump violente (FOMO manqu√©)
                elif trend_5m == "STRONG_BULLISH" and ema_21_velocity > 0.01:  # Acc√©l√©ration haussi√®re > 1%
                    rejection_reason = "pump violent en cours, √©viter de rater la mont√©e"
            
            # Appliquer le rejet si raison trouv√©e
            if rejection_reason:
                logger.info(f"Signal {side} {symbol} rejet√© : {rejection_reason}")
                return False
            
            # NOUVELLE VALIDATION ENRICHIE : Bollinger Bands position pour timing optimal
            bb_position = data_5m.get('bb_position')
            if bb_position is not None:
                if side == "BUY" and bb_position > 0.8:  # Prix proche de la bande haute
                    logger.info(f"Signal BUY {symbol} rejet√© : BB position trop haute ({bb_position:.2f})")
                    return False
                elif side == "SELL" and bb_position < 0.2:  # Prix proche de la bande basse
                    logger.info(f"Signal SELL {symbol} rejet√© : BB position trop basse ({bb_position:.2f})")
                    return False
            
            # NOUVELLE VALIDATION : Stochastic pour confirmer oversold/overbought
            stoch_k = data_5m.get('stoch_k')
            stoch_d = data_5m.get('stoch_d')
            if stoch_k is not None and stoch_d is not None:
                if side == "BUY" and stoch_k > 85 and stoch_d > 85:  # Surachat confirm√©
                    logger.info(f"Signal BUY {symbol} rejet√© : Stochastic surachat K={stoch_k:.1f} D={stoch_d:.1f}")
                    return False
                elif side == "SELL" and stoch_k < 15 and stoch_d < 15:  # Survente confirm√©
                    logger.info(f"Signal SELL {symbol} rejet√© : Stochastic survente K={stoch_k:.1f} D={stoch_d:.1f}")
                    return False
            
            # VALIDATION ADAPTATIVE : Ajuster seuils RSI selon ATR (volatilit√©)
            atr_15m = data_5m.get('atr_14')
            current_price = data_5m.get('close', prices[-1] if prices else 0)
            atr_percent = (atr_15m / current_price * 100) if atr_15m and current_price > 0 else 2.0
            
            # Seuils RSI adaptatifs selon volatilit√©
            if atr_percent > 5.0:  # Haute volatilit√©
                rsi_buy_threshold = 75  # Plus tol√©rant
                rsi_sell_threshold = 25
            elif atr_percent > 3.0:  # Volatilit√© moyenne
                rsi_buy_threshold = 80
                rsi_sell_threshold = 20
            else:  # Faible volatilit√©
                rsi_buy_threshold = 85  # Plus strict
                rsi_sell_threshold = 15
            
            # Validation RSI avec seuils adaptatifs
            rsi_5m = data_5m.get('rsi_14')
            if rsi_5m:
                if side == "BUY" and rsi_5m > rsi_buy_threshold:
                    logger.info(f"Signal BUY {symbol} rejet√© : RSI 5m surachat ({rsi_5m:.1f} > {rsi_buy_threshold}) - ATR={atr_percent:.1f}%")
                    return False
                elif side == "SELL" and rsi_5m < rsi_sell_threshold:
                    logger.info(f"Signal SELL {symbol} rejet√© : RSI 5m survente ({rsi_5m:.1f} < {rsi_sell_threshold}) - ATR={atr_percent:.1f}%")
                    return False

            logger.debug(f"Signal {side} {symbol} valid√© par analyse multi-indicateurs 5m - tendance={trend_5m} BB={bb_position} ATR={atr_percent:.1f}%")
            return True
            
        except Exception as e:
            logger.error(f"Erreur validation multi-timeframe: {e}")
            return True  # Mode d√©grad√© : accepter le signal
    
    def _calculate_ema(self, prices: List[float], period: int) -> float:
        """Calcule une EMA simple (fallback)"""
        if not prices or period <= 0:
            return prices[-1] if prices else 0
        
        multiplier = 2 / (period + 1)
        ema = prices[0]
        
        for price in prices[1:]:
            ema = (price * multiplier) + (ema * (1 - multiplier))
        
        return ema
    
    def _get_or_calculate_ema_incremental(self, symbol: str, current_price: float, period: int) -> float:
        """
        R√©cup√®re ou calcule EMA de mani√®re incr√©mentale pour √©viter les dents de scie.
        Utilise le m√™me principe que le Gateway WebSocket.
        """
        timeframe = "1m"  # Timeframe principal du Signal Aggregator
        cache_key = f'ema_{period}'
        
        # Initialiser le cache si n√©cessaire
        if symbol not in self.ema_incremental_cache:
            self.ema_incremental_cache[symbol] = {}
        if timeframe not in self.ema_incremental_cache[symbol]:
            self.ema_incremental_cache[symbol][timeframe] = {}
            
        cache = self.ema_incremental_cache[symbol][timeframe]
        
        # R√©cup√©rer EMA pr√©c√©dente du cache
        prev_ema = cache.get(cache_key)
        
        if prev_ema is None:
            # Premi√®re fois : utiliser le prix actuel comme base
            new_ema = current_price
        else:
            # Calcul incr√©mental standard
            from shared.src.technical_indicators import calculate_ema_incremental
            new_ema = calculate_ema_incremental(current_price, prev_ema, period)
        
        # Mettre √† jour le cache
        cache[cache_key] = new_ema
        
        return new_ema
    
    def _get_or_calculate_indicator_incremental(self, symbol: str, current_candle: Dict, indicator_type: str, **params) -> Optional[float]:
        """
        M√©thode g√©n√©rique pour calculer n'importe quel indicateur de mani√®re incr√©mentale.
        √âvite les dents de scie pour MACD, RSI, ATR, Stochastic, etc.
        
        Args:
            symbol: Symbole trad√©
            current_candle: Bougie actuelle avec OHLCV
            indicator_type: Type d'indicateur ('macd', 'rsi', 'atr', 'stoch', etc.)
            **params: Param√®tres sp√©cifiques (period, etc.)
        """
        timeframe = "1m"
        
        # Initialiser le cache si n√©cessaire
        if symbol not in self.ema_incremental_cache:
            self.ema_incremental_cache[symbol] = {}
        if timeframe not in self.ema_incremental_cache[symbol]:
            self.ema_incremental_cache[symbol][timeframe] = {}
            
        cache = self.ema_incremental_cache[symbol][timeframe]
        
        try:
            if indicator_type == 'macd':
                # MACD incr√©mental (line, signal, histogram)
                prev_ema_fast = cache.get('macd_ema_fast')
                prev_ema_slow = cache.get('macd_ema_slow') 
                prev_macd_signal = cache.get('macd_signal')
                
                from shared.src.technical_indicators import calculate_macd_incremental
                result = calculate_macd_incremental(
                    current_candle['close'], prev_ema_fast, prev_ema_slow, prev_macd_signal
                )
                
                # Mettre √† jour le cache
                cache['macd_ema_fast'] = result['ema_fast']
                cache['macd_ema_slow'] = result['ema_slow']
                cache['macd_signal'] = result['macd_signal']
                cache['macd_line'] = result['macd_line']
                cache['macd_histogram'] = result['macd_histogram']
                
                return result
                
            elif indicator_type == 'rsi':
                # RSI incr√©mental (n√©cessite historique de gains/pertes)
                period = params.get('period', 14)
                prev_rsi = cache.get(f'rsi_{period}')
                prev_avg_gain = cache.get(f'rsi_{period}_avg_gain')
                prev_avg_loss = cache.get(f'rsi_{period}_avg_loss')
                prev_price = cache.get('prev_close')
                
                if prev_price is None:
                    # Premi√®re fois : utiliser valeur neutre
                    cache['prev_close'] = current_candle['close']
                    return 50.0
                
                # Calculer gain/perte pour cette p√©riode
                price_change = current_candle['close'] - prev_price
                gain = max(price_change, 0)
                loss = max(-price_change, 0)
                
                if prev_avg_gain is None or prev_avg_loss is None:
                    # Initialisation
                    avg_gain = gain
                    avg_loss = loss
                else:
                    # Calcul incr√©mental des moyennes
                    alpha = 1.0 / period
                    avg_gain = alpha * gain + (1 - alpha) * prev_avg_gain
                    avg_loss = alpha * loss + (1 - alpha) * prev_avg_loss
                
                # Calculer RSI
                if avg_loss == 0:
                    rsi = 100.0
                else:
                    rs = avg_gain / avg_loss
                    rsi = 100.0 - (100.0 / (1.0 + rs))
                
                # Mettre √† jour le cache
                cache[f'rsi_{period}'] = rsi
                cache[f'rsi_{period}_avg_gain'] = avg_gain
                cache[f'rsi_{period}_avg_loss'] = avg_loss
                cache['prev_close'] = current_candle['close']
                
                return rsi
                
            elif indicator_type == 'sma':
                # SMA incr√©mental
                period = params.get('period', 20)
                prev_sma = cache.get(f'sma_{period}')
                
                from shared.src.technical_indicators import calculate_sma_incremental
                new_sma = calculate_sma_incremental(current_candle['close'], prev_sma, period)
                
                cache[f'sma_{period}'] = new_sma
                return new_sma
                
            elif indicator_type == 'atr':
                # ATR incr√©mental pour stop-loss plus pr√©cis
                period = params.get('period', 14)
                prev_atr = cache.get(f'atr_{period}')
                prev_close = cache.get('atr_prev_close')
                
                if prev_close is None:
                    cache['atr_prev_close'] = current_candle['close']
                    cache[f'atr_{period}'] = current_candle['high'] - current_candle['low']
                    return cache[f'atr_{period}']
                
                # Calcul True Range
                tr1 = current_candle['high'] - current_candle['low']
                tr2 = abs(current_candle['high'] - prev_close)
                tr3 = abs(current_candle['low'] - prev_close)
                true_range = max(tr1, tr2, tr3)
                
                # ATR incr√©mental (EMA du True Range)
                if prev_atr is None:
                    new_atr = true_range
                else:
                    alpha = 2.0 / (period + 1)
                    new_atr = alpha * true_range + (1 - alpha) * prev_atr
                
                cache[f'atr_{period}'] = new_atr
                cache['atr_prev_close'] = current_candle['close']
                return new_atr
                
            elif indicator_type == 'stoch':
                # Stochastic incr√©mental (K% et D%)
                period_k = params.get('period_k', 14)
                period_d = params.get('period_d', 3)
                
                # Maintenir historique des highs/lows pour K%
                highs_key = f'stoch_highs_{period_k}'
                lows_key = f'stoch_lows_{period_k}'
                
                if highs_key not in cache:
                    cache[highs_key] = []
                if lows_key not in cache:
                    cache[lows_key] = []
                
                # Ajouter valeurs actuelles
                cache[highs_key].append(current_candle['high'])
                cache[lows_key].append(current_candle['low'])
                
                # Maintenir seulement les derni√®res 'period_k' valeurs
                if len(cache[highs_key]) > period_k:
                    cache[highs_key] = cache[highs_key][-period_k:]
                if len(cache[lows_key]) > period_k:
                    cache[lows_key] = cache[lows_key][-period_k:]
                
                if len(cache[highs_key]) < period_k:
                    return {'stoch_k': 50.0, 'stoch_d': 50.0}  # Valeurs neutres
                
                # Calcul K%
                highest_high = max(cache[highs_key])
                lowest_low = min(cache[lows_key])
                
                if highest_high == lowest_low:
                    stoch_k = 50.0
                else:
                    stoch_k = ((current_candle['close'] - lowest_low) / (highest_high - lowest_low)) * 100
                
                # Calcul D% (SMA de K%)
                k_history_key = f'stoch_k_history_{period_d}'
                if k_history_key not in cache:
                    cache[k_history_key] = []
                    
                cache[k_history_key].append(stoch_k)
                if len(cache[k_history_key]) > period_d:
                    cache[k_history_key] = cache[k_history_key][-period_d:]
                
                stoch_d = sum(cache[k_history_key]) / len(cache[k_history_key])
                
                result = {'stoch_k': stoch_k, 'stoch_d': stoch_d}
                cache['stoch_k'] = stoch_k
                cache['stoch_d'] = stoch_d
                return result
                
            elif indicator_type == 'bollinger':
                # Bollinger Bands incr√©mental
                period = params.get('period', 20)
                std_dev = params.get('std_dev', 2.0)
                
                # Maintenir historique des prix pour calcul √©cart-type
                prices_key = f'bb_prices_{period}'
                if prices_key not in cache:
                    cache[prices_key] = []
                    
                cache[prices_key].append(current_candle['close'])
                if len(cache[prices_key]) > period:
                    cache[prices_key] = cache[prices_key][-period:]
                
                if len(cache[prices_key]) < period:
                    return None  # Pas assez de donn√©es
                
                # Calcul SMA (middle band)
                sma = sum(cache[prices_key]) / period
                
                # Calcul √©cart-type
                variance = sum((price - sma) ** 2 for price in cache[prices_key]) / period
                std = variance ** 0.5
                
                # Calcul des bandes
                bb_upper = sma + (std_dev * std)
                bb_lower = sma - (std_dev * std)
                bb_width = (bb_upper - bb_lower) / sma if sma > 0 else 0
                
                # Position relative du prix (0 = bande basse, 1 = bande haute)
                if bb_upper == bb_lower:
                    bb_position = 0.5
                else:
                    bb_position = (current_candle['close'] - bb_lower) / (bb_upper - bb_lower)
                
                result = {
                    'bb_upper': bb_upper,
                    'bb_middle': sma,
                    'bb_lower': bb_lower,
                    'bb_position': bb_position,
                    'bb_width': bb_width
                }
                
                # Mettre √† jour le cache
                for key, value in result.items():
                    cache[key] = value
                    
                return result
                
            else:
                # Fallback pour indicateurs non impl√©ment√©s
                logger.debug(f"Indicateur incr√©mental non impl√©ment√©: {indicator_type}")
                return None
                
        except Exception as e:
            logger.error(f"Erreur calcul incr√©mental {indicator_type} pour {symbol}: {e}")
            return None
    
    async def _get_current_adx(self, symbol: str) -> Optional[float]:
        """
        R√©cup√®re la valeur ADX actuelle depuis Redis
        
        Args:
            symbol: Symbole concern√©
            
        Returns:
            Valeur ADX ou None si non disponible
        """
        try:
            # Essayer d'abord les donn√©es 1m (plus r√©centes)
            market_data_key = f"market_data:{symbol}:1m"
            data_1m = self.redis.get(market_data_key)
            
            if data_1m and isinstance(data_1m, dict):
                adx = data_1m.get('adx_14')
                if adx is not None:
                    return float(adx)
            
            # Fallback sur les donn√©es 5m
            market_data_key_5m = f"market_data:{symbol}:5m"
            data_5m = self.redis.get(market_data_key_5m)
            
            if data_5m and isinstance(data_5m, dict):
                adx = data_5m.get('adx_14')
                if adx is not None:
                    return float(adx)
                    
            logger.debug(f"ADX non disponible pour {symbol}")
            return None
            
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration ADX pour {symbol}: {e}")
            return None


class EnhancedSignalAggregator(SignalAggregator):
    """Version am√©lior√©e avec plus de filtres et validations"""
    
    def __init__(self, redis_client, regime_detector, performance_tracker, db_pool=None):
        super().__init__(redis_client, regime_detector, performance_tracker)
        self.db_pool = db_pool  # Stocker le db_pool pour les modules bay√©siens
        
        # V√©rifier si les modules am√©lior√©s sont disponibles
        if not EnhancedRegimeDetector:
            logger.warning("EnhancedSignalAggregator initialis√© en mode d√©grad√© (modules am√©lior√©s non disponibles)")
            self.enhanced_mode = False
        else:
            self.enhanced_mode = True
        
        # Nouveaux param√®tres
        self.correlation_threshold = 0.7  # Corr√©lation minimale entre signaux
        self.divergence_penalty = 0.5  # P√©nalit√© pour signaux divergents
        self.regime_transition_cooldown = timedelta(minutes=5)
        self.last_regime_change = {}
        
        # Suivi des faux signaux
        self.false_signal_tracker = defaultdict(int)
        self.false_signal_threshold = 3  # Max faux signaux avant d√©sactivation temporaire
        
        # NOUVEAU: Debounce pour √©viter les signaux group√©s
        self.signal_debounce = defaultdict(lambda: {'last_buy': None, 'last_sell': None})
        self.debounce_periods = {
            'same_side': 3,  # Nombre de bougies minimum entre signaux du m√™me c√¥t√© (BUY-BUY ou SELL-SELL)
            'opposite_side': 1  # Nombre de bougies minimum entre signaux oppos√©s (BUY-SELL)
        }
        self.candle_duration = timedelta(minutes=1)  # Dur√©e d'une bougie (√† adapter selon l'intervalle)
        
    async def _validate_signal_correlation(self, signals: List[Dict]) -> float:
        """
        Valide la corr√©lation entre les signaux multiples
        
        Returns:
            Score de corr√©lation (0-1)
        """
        if len(signals) < 2:
            return 1.0
        
        # Analyser les m√©tadonn√©es des signaux
        correlation_score = 1.0
        
        # V√©rifier que les signaux pointent dans la m√™me direction g√©n√©rale
        price_targets = []
        stop_losses = []
        
        for signal in signals:
            metadata = signal.get('metadata', {})
            
            # Extraire les niveaux cl√©s
            if 'stop_price' in metadata:
                stop_losses.append(metadata['stop_price'])
            
            # Analyser les indicateurs sous-jacents
            if 'rsi' in metadata:
                rsi = metadata['rsi']
                side = signal.get('side', signal.get('side'))
                
                # P√©naliser si RSI contradictoire
                if side == 'BUY' and rsi > 70:
                    correlation_score *= 0.7
                elif side == 'SELL' and rsi < 30:
                    correlation_score *= 0.7
        
        # V√©rifier la coh√©rence des stops
        if len(stop_losses) >= 2:
            stop_std = np.std(stop_losses) / np.mean(stop_losses)
            if stop_std > 0.02:  # Plus de 2% d'√©cart
                correlation_score *= 0.8
        
        return correlation_score
    
    def update_strategy_performance(self, strategy: str, is_win: bool, return_pct: float = 0.0):
        """
        Met √† jour les performances bay√©siennes d'une strat√©gie
        √Ä appeler quand un trade se termine
        """
        try:
            self.bayesian_weights.update_performance(strategy, is_win, return_pct)
            logger.info(f"üìà Performance mise √† jour pour {strategy}: {'WIN' if is_win else 'LOSS'} ({return_pct:+.2%})")
        except Exception as e:
            logger.error(f"Erreur mise √† jour performance {strategy}: {e}")
    
    def get_performance_summary(self) -> Dict:
        """Retourne un r√©sum√© des performances et seuils"""
        try:
            return {
                'bayesian_weights': self.bayesian_weights.get_performance_summary(),
                'dynamic_thresholds': self.dynamic_thresholds.get_statistics()
            }
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration r√©sum√© performances: {e}")
            return {}

    async def _check_signal_debounce(self, symbol: str, side: str, interval: str = None) -> bool:
        """
        V√©rifie si un signal respecte le d√©lai de debounce pour √©viter les signaux group√©s
        
        Args:
            symbol: Symbole du signal
            side: C√¥t√© du signal (BUY ou SELL)
            interval: Intervalle temporel (optionnel, d√©tect√© automatiquement si non fourni)
            
        Returns:
            True si le signal est autoris√©, False s'il doit √™tre filtr√©
        """
        try:
            current_time = datetime.now(timezone.utc)
            debounce_info = self.signal_debounce[symbol]
            
            # D√©terminer la dur√©e d'une bougie selon l'intervalle
            interval_map = {
                '1m': timedelta(minutes=1),
                '3m': timedelta(minutes=3),
                '5m': timedelta(minutes=5),
                '15m': timedelta(minutes=15),
                '30m': timedelta(minutes=30),
                '1h': timedelta(hours=1),
                '4h': timedelta(hours=4)
            }
            
            # Utiliser l'intervalle fourni ou d√©tecter depuis Redis
            if not interval:
                # Essayer de r√©cup√©rer l'intervalle depuis les donn√©es de march√©
                market_key = f"market_interval:{symbol}"
                interval = self.redis.get(market_key) or '15m'  # Par d√©faut 15m pour swing trading
            
            candle_duration = interval_map.get(interval, timedelta(minutes=15))
            
            # Adapter les p√©riodes de debounce selon l'intervalle
            # Pour 15m: 3 bougies = 45 min entre signaux m√™me c√¥t√©
            # Debounce adaptatif bas√© sur l'ADX (Hybrid approach)
            current_adx = await self._get_current_adx(symbol)
            base_same = self.debounce_periods['same_side']
            base_opposite = self.debounce_periods['opposite_side']
            
            # Calculer multiplicateur ADX pour debounce adaptatif
            if current_adx is not None:
                if current_adx >= 42:  # Tendance tr√®s forte
                    adx_multiplier = 0.5  # Debounce r√©duit de moiti√©
                    trend_strength = "tr√®s forte"
                elif current_adx >= 32:  # Tendance forte
                    adx_multiplier = 0.7  # Debounce r√©duit
                    trend_strength = "forte" 
                elif current_adx >= 23:  # Tendance mod√©r√©e
                    adx_multiplier = 1.0  # Debounce normal
                    trend_strength = "mod√©r√©e"
                else:  # Range/tendance faible
                    adx_multiplier = 1.8  # Debounce augment√©
                    trend_strength = "faible/range"
            else:
                adx_multiplier = 1.0  # Fallback si ADX non disponible
                trend_strength = "inconnue"
            
            # Appliquer multiplicateur
            debounce_same = int(base_same * adx_multiplier)
            debounce_opposite = int(base_opposite * adx_multiplier)
            
            logger.debug(f"üìä Debounce adaptatif {symbol}: ADX={current_adx:.1f} (tendance {trend_strength}) ‚Üí m√™me={debounce_same}, oppos√©={debounce_opposite} bougies")
            
            # D√©terminer le dernier signal du m√™me c√¥t√© et du c√¥t√© oppos√©
            if side == 'BUY':
                last_same_side = debounce_info['last_buy']
                last_opposite_side = debounce_info['last_sell']
            else:  # SELL
                last_same_side = debounce_info['last_sell']
                last_opposite_side = debounce_info['last_buy']
            
            # V√©rifier le debounce pour le m√™me c√¥t√©
            if last_same_side:
                time_since_same = (current_time - last_same_side).total_seconds()
                min_time_same = debounce_same * candle_duration.total_seconds()
                
                if time_since_same < min_time_same:
                    logger.info(f"‚ùå Signal {side} {symbol} filtr√© par debounce m√™me c√¥t√©: "
                              f"{time_since_same:.0f}s < {min_time_same:.0f}s requis ({debounce_same} bougies {interval})")
                    return False
            
            # V√©rifier le debounce pour le c√¥t√© oppos√©
            if last_opposite_side:
                time_since_opposite = (current_time - last_opposite_side).total_seconds()
                min_time_opposite = debounce_opposite * candle_duration.total_seconds()
                
                if time_since_opposite < min_time_opposite:
                    logger.info(f"‚ö†Ô∏è Signal {side} {symbol} filtr√© par debounce c√¥t√© oppos√©: "
                              f"{time_since_opposite:.0f}s < {min_time_opposite:.0f}s requis ({debounce_opposite} bougies {interval})")
                    return False
            
            # Signal autoris√© - mettre √† jour le tracking
            if side == 'BUY':
                debounce_info['last_buy'] = current_time
            else:
                debounce_info['last_sell'] = current_time
            
            logger.debug(f"‚úÖ Signal {side} {symbol} passe le filtre debounce (intervalle: {interval})")
            return True
            
        except Exception as e:
            logger.error(f"Erreur dans check_signal_debounce: {e}")
            return True  # En cas d'erreur, laisser passer le signal
    
    async def _check_regime_transition(self, symbol: str) -> bool:
        """
        V√©rifie si on est en transition de r√©gime (moment d√©licat)
        
        Returns:
            True si en transition, False sinon
        """
        try:
            # R√©cup√©rer l'historique des r√©gimes
            regime_history_key = f"regime_history:{symbol}"
            try:
                # Essayer d'utiliser la m√©thode Redis standard
                history = self.redis.lrange(regime_history_key, 0, 10)
            except AttributeError:
                # Fallback pour RedisClientPool customis√©
                history_str = self.redis.get(regime_history_key)
                if history_str:
                    history = json.loads(history_str) if isinstance(history_str, str) else history_str
                    if isinstance(history, list):
                        history = history[:10]  # Prendre les 10 premiers
                    else:
                        history = []
                else:
                    history = []
            
            if len(history) < 3:
                return False
            
            # Analyser les changements r√©cents
            recent_regimes = []
            for h in history[:3]:
                if isinstance(h, str):
                    regime_data = json.loads(h)
                else:
                    regime_data = h
                recent_regimes.append(regime_data.get('regime'))
            
            unique_regimes = len(set(recent_regimes))
            
            # Si plus de 2 r√©gimes diff√©rents dans les 3 derniers = transition
            if unique_regimes > 2:
                return True
            
            # V√©rifier le temps depuis le dernier changement
            if symbol in self.last_regime_change:
                time_since_change = datetime.now() - self.last_regime_change[symbol]
                if time_since_change < self.regime_transition_cooldown:
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"Erreur v√©rification transition r√©gime: {e}")
            return False
    
    async def _apply_market_context_filters(self, signal: Dict) -> bool:
        """
        Applique des filtres bas√©s sur le contexte de march√© global
        
        Returns:
            True si le signal passe les filtres, False sinon
        """
        symbol = signal['symbol']
        
        # 1. V√©rifier les heures de trading (√©viter les heures creuses)
        current_hour = datetime.now().hour
        if current_hour in [22, 23, 0, 1, 2, 3, 4, 5]:  # Heures creuses crypto
            # Augmenter le seuil de confiance pendant ces heures
            min_confidence = 0.8
        else:
            min_confidence = self.min_confidence_threshold
        
        if signal.get('confidence', 0) < min_confidence:
            logger.debug(f"Signal filtr√©: confiance insuffisante pendant heures creuses")
            return False
        
        # 2. V√©rifier le spread bid/ask
        spread_key = f"spread:{symbol}"
        spread = self.redis.get(spread_key)
        if spread and float(spread) > 0.003:  # Spread > 0.3%
            logger.info(f"Signal filtr√©: spread trop large ({float(spread):.3%})")
            return False
        
        # 3. V√©rifier la liquidit√© r√©cente
        volume_key = f"volume_1h:{symbol}"
        recent_volume = self.redis.get(volume_key)
        if recent_volume and float(recent_volume) < 100000:  # Volume < 100k
            logger.info(f"Signal filtr√©: volume insuffisant ({float(recent_volume):.0f})")
            return False
        
        # 4. V√©rifier les corr√©lations avec BTC (pour les altcoins)
        if symbol != "BTCUSDC":
            btc_correlation = await self._check_btc_correlation(symbol)
            if btc_correlation < -0.7:  # Forte corr√©lation n√©gative
                logger.info(f"Signal filtr√©: corr√©lation BTC n√©gative ({btc_correlation:.2f})")
                return False
        
        return True
    
    async def _check_btc_correlation(self, symbol: str) -> float:
        """
        V√©rifie la corr√©lation avec BTC sur les derni√®res heures
        """
        try:
            # R√©cup√©rer les prix r√©cents
            try:
                symbol_prices = self.redis.lrange(f"prices_1h:{symbol}", 0, 24)
                btc_prices = self.redis.lrange(f"prices_1h:BTCUSDC", 0, 24)
            except AttributeError:
                # Fallback pour RedisClientPool customis√©
                symbol_prices_str = self.redis.get(f"prices_1h:{symbol}")
                btc_prices_str = self.redis.get(f"prices_1h:BTCUSDC")
                
                symbol_prices = []
                btc_prices = []
                
                if symbol_prices_str:
                    parsed = json.loads(symbol_prices_str) if isinstance(symbol_prices_str, str) else symbol_prices_str
                    symbol_prices = parsed[-24:] if isinstance(parsed, list) else []
                
                if btc_prices_str:
                    parsed = json.loads(btc_prices_str) if isinstance(btc_prices_str, str) else btc_prices_str
                    btc_prices = parsed[-24:] if isinstance(parsed, list) else []
            
            if len(symbol_prices) < 10 or len(btc_prices) < 10:
                return 0.0
            
            # Convertir en float
            symbol_prices = [float(p) for p in symbol_prices]
            btc_prices = [float(p) for p in btc_prices]
            
            # Calculer la corr√©lation
            symbol_returns = np.diff(np.array(symbol_prices))
            btc_returns = np.diff(np.array(btc_prices))
            
            if len(symbol_returns) > 0 and len(btc_returns) > 0:
                min_length = min(len(symbol_returns), len(btc_returns))
                correlation = np.corrcoef(
                    symbol_returns[:min_length],
                    btc_returns[:min_length]
                )[0, 1]
                
                return correlation if not np.isnan(correlation) else 0.0
            
        except Exception as e:
            logger.error(f"Erreur calcul corr√©lation BTC: {e}")
            
        return 0.0
    
    async def _track_signal_accuracy(self, signal: Dict):
        """
        Suit la pr√©cision des signaux pour ajuster les poids dynamiquement
        """
        # Stocker le signal pour v√©rification future
        signal_key = f"pending_signal:{signal['symbol']}:{signal['strategy']}"
        signal_data = {
            'entry_price': signal['price'],
            'side': signal['side'],
            'timestamp': datetime.now().isoformat(),
            'stop_loss': signal.get('stop_loss'),
            'confidence': signal.get('confidence')
        }
        
        # G√©rer les diff√©rents types de clients Redis
        try:
            self.redis.set(signal_key, json.dumps(signal_data), ex=3600)
        except TypeError:
            # Fallback pour RedisClientPool customis√©
            self.redis.set(signal_key, json.dumps(signal_data), expiration=3600)
    
    async def _get_recovery_duration(self, symbol: str) -> float:
        """Get the duration since entering recovery period"""
        try:
            # Get danger history to find when we exited danger
            history_key = f"danger_history:{symbol}"
            history = []
            
            # Try to get recent history
            try:
                for i in range(20):  # Check last 20 entries
                    entry = self.redis.lindex(history_key, i)
                    if entry:
                        history.append(json.loads(entry))
            except:
                pass
                
            # Find when we exited danger zone
            exit_time = None
            for i, entry in enumerate(history):
                if entry['level'] < 5.0 and i > 0 and history[i-1]['level'] >= 7.0:
                    exit_time = datetime.fromisoformat(entry['timestamp'])
                    break
                    
            if exit_time:
                duration = (datetime.now() - exit_time).total_seconds()
                return duration
                
        except Exception as e:
            logger.error(f"Error calculating recovery duration: {e}")
            
        return 0  # Default to start of recovery
    
    async def _apply_enhanced_regime_filtering(self, signal: Dict[str, Any], regime, regime_metrics: Dict[str, float], 
                                             is_ultra_confluent: bool, signal_score: Optional[float], 
                                             strategy_count: int = 1) -> bool:
        """
        Applique un filtrage intelligent bas√© sur les r√©gimes Enhanced.
        
        Args:
            signal: Signal √† filtrer
            regime: R√©gime Enhanced d√©tect√©
            regime_metrics: M√©triques du r√©gime
            is_ultra_confluent: Si le signal est ultra-confluent
            signal_score: Score du signal (si disponible)
            strategy_count: Nombre de strat√©gies qui s'accordent sur ce signal
            
        Returns:
            True si le signal doit √™tre accept√©, False sinon
        """
        try:
            symbol = signal['symbol']
            signal_strength = signal.get('strength', 'moderate')
            signal_confidence = signal.get('confidence', 0.5)
            strategy = signal.get('strategy', 'Unknown')
            # Normaliser le nom de strat√©gie (retirer _Strategy)
            strategy = strategy.replace('_Strategy', '')
            side = signal.get('side', 'UNKNOWN')
            
            # NOUVEAU: R√©cup√©rer donn√©es techniques pour validation Enhanced
            technical_context = await self._get_technical_context(symbol)
            
            # Seuils adaptatifs selon le r√©gime Enhanced + contexte technique
            if regime.name == 'STRONG_TREND_UP':
                # Tendance haussi√®re forte: favoriser les BUY, p√©naliser les SELL
                if side == 'SELL':
                    min_confidence = 0.80  # P√©naliser SELL en forte tendance haussi√®re
                    required_strength = ['very_strong']
                    logger.debug(f"üí™ {regime.name}: SELL p√©nalis√©, seuils stricts pour {symbol}")
                else:  # BUY
                    # Validation MACD pour confirmer la force de tendance
                    if self._validate_macd_trend(technical_context, 'bullish'):
                        min_confidence = 0.35  # Encore plus permissif si MACD confirme
                        logger.debug(f"üí™ {regime.name}: MACD confirme, seuils tr√®s assouplis pour {symbol}")
                    else:
                        min_confidence = 0.4
                        logger.debug(f"üí™ {regime.name}: seuils assouplis pour {symbol}")
                    required_strength = ['weak', 'moderate', 'strong', 'very_strong']
                
            elif regime.name == 'TREND_UP':
                # Tendance haussi√®re: favoriser les BUY, p√©naliser mod√©r√©ment les SELL
                if side == 'SELL':
                    min_confidence = 0.75  # P√©naliser SELL en tendance haussi√®re
                    required_strength = ['strong', 'very_strong']
                    logger.debug(f"üìà {regime.name}: SELL p√©nalis√©, seuils √©lev√©s pour {symbol}")
                else:  # BUY
                    # Validation OBV pour confirmer le volume
                    if self._validate_obv_trend(technical_context, side):
                        min_confidence = 0.45  # Bonus si OBV confirme
                        logger.debug(f"üìà {regime.name}: OBV confirme, seuils bonus (0.45) pour {symbol}")
                    else:
                        min_confidence = 0.5  # ASSOUPLI √† 0.50 (√©tait 0.7)
                        logger.debug(f"üìà {regime.name}: seuils ASSOUPLIS (0.5) pour {symbol}")
                    required_strength = ['moderate', 'strong', 'very_strong']
                
            elif regime.name == 'WEAK_TREND_UP':
                # Tendance haussi√®re faible: l√©g√®re p√©nalisation des SELL
                if side == 'SELL':
                    min_confidence = 0.70  # P√©naliser l√©g√®rement SELL en tendance haussi√®re faible
                    required_strength = ['strong', 'very_strong']
                    logger.debug(f"üìä {regime.name}: SELL l√©g√®rement p√©nalis√© pour {symbol}")
                else:  # BUY
                    # Validation ROC pour d√©tecter l'acc√©l√©ration
                    roc_boost = self._check_roc_acceleration(technical_context, side)
                    if roc_boost:
                        min_confidence = 0.50  # Bonus si ROC d√©tecte acc√©l√©ration
                        logger.debug(f"üìä {regime.name}: ROC acc√©l√©ration d√©tect√©e, seuils bonus (0.50) pour {symbol}")
                    else:
                        min_confidence = 0.55  # ASSOUPLI √† 0.55 (√©tait 0.65)
                        logger.debug(f"üìä {regime.name}: seuils ASSOUPLIS (0.55) pour {symbol}")
                    required_strength = ['moderate', 'strong', 'very_strong']
                
            elif regime.name == 'RANGE_TIGHT':
                # Gestion sp√©ciale pour ADX tr√®s faible (march√© plat)
                adx = regime_metrics.get('adx', 0)
                if adx <= 5:  # ADX pr√®s de 0
                    # Exiger confirmation volume √©lev√©
                    volume_ratio = signal.get('metadata', {}).get('volume_ratio', 1.0)
                    if volume_ratio < 2.0:
                        logger.info(f"üö´ Signal rejet√© en RANGE_TIGHT: ADX={adx:.1f} et volume_ratio={volume_ratio:.1f} < 2.0")
                        return False
                    
                    # Marquer pour r√©duction de poids 0.5x
                    signal['metadata'] = signal.get('metadata', {})
                    signal['metadata']['adx_weight_modifier'] = 0.5
                    logger.info(f"‚öñÔ∏è ADX faible ({adx:.1f}): poids r√©duit √† 0.5x pour {symbol}")
                
                # Range serr√©: ASSOUPLI pour mean-reversion
                if strategy in self.STRATEGY_GROUPS.get('mean_reversion', []):
                    # ASSOUPLI pour strat√©gies de mean-reversion
                    min_confidence = 0.6  # ASSOUPLI de 0.75 √† 0.6
                    required_strength = ['moderate', 'strong', 'very_strong']  # Ajouter moderate
                    logger.debug(f"üîí {regime.name}: seuils ASSOUPLIS pour mean-reversion {symbol}")
                else:
                    # ASSOUPLI pour autres strat√©gies aussi
                    min_confidence = 0.7  # ASSOUPLI de 0.8 √† 0.7
                    required_strength = ['strong', 'very_strong']
                    logger.debug(f"üîí {regime.name}: seuils ASSOUPLIS (0.7) pour {symbol}")
                
            elif regime.name == 'RANGE_VOLATILE':
                # Range volatil: s√©lectif mais moins que tight
                min_confidence = 0.7
                required_strength = ['strong', 'very_strong']
                logger.debug(f"‚ö° {regime.name}: seuils stricts pour {symbol}")
                
            elif regime.name in ['WEAK_TREND_DOWN', 'TREND_DOWN', 'STRONG_TREND_DOWN']:
                # Tendances baissi√®res: favoriser les SELL, bloquer les BUY faibles
                if side == 'BUY':
                    min_confidence = 0.80  # Assoupli de 0.85 √† 0.80 pour les BUY en downtrend
                    required_strength = ['very_strong']
                else:  # SELL
                    min_confidence = 0.7  # Seuil ajust√© pour les SELL (0.7 recommand√©)
                    required_strength = ['moderate', 'strong', 'very_strong']
                logger.debug(f"üìâ {regime.name}: adaptation BUY/SELL pour {symbol}")
                
            else:
                # R√©gime inconnu ou UNDEFINED: seuils par d√©faut
                min_confidence = 0.6
                required_strength = ['strong', 'very_strong']
                logger.debug(f"‚ùì {regime.name}: seuils par d√©faut pour {symbol}")
            
            # Exception pour signaux ultra-confluents de haute qualit√©
            if is_ultra_confluent and signal_score:
                if signal_score >= 85:
                    # Signaux excellents: r√©duire les seuils
                    min_confidence *= 0.8
                    if 'moderate' not in required_strength:
                        required_strength.append('moderate')
                    logger.info(f"‚≠ê Signal ultra-confluent excellent (score={signal_score:.1f}): seuils r√©duits pour {symbol}")
                elif signal_score >= 75:
                    # Signaux tr√®s bons: r√©duire mod√©r√©ment
                    min_confidence *= 0.9
                    logger.info(f"‚ú® Signal ultra-confluent tr√®s bon (score={signal_score:.1f}): seuils ajust√©s pour {symbol}")
            
            # Appliquer les filtres
            if signal_confidence < min_confidence:
                logger.info(f"üö´ Signal rejet√© en {regime.name}: confiance {signal_confidence:.2f} < {min_confidence:.2f} "
                           f"pour {strategy} {side} {symbol}")
                return False
                
            # NOUVEAU: Accepter les signaux 'moderate' si 2+ strat√©gies s'accordent
            if signal_strength == 'moderate' and strategy_count >= 2:
                logger.info(f"‚úÖ Signal 'moderate' accept√© avec {strategy_count} strat√©gies en {regime.name}: "
                           f"{strategy} {side} {symbol}")
            elif signal_strength not in required_strength:
                logger.info(f"üö´ Signal rejet√© en {regime.name}: force '{signal_strength}' insuffisante "
                           f"(requis: {required_strength}) pour {strategy} {side} {symbol}")
                return False
            
            # Signal accept√©
            adx = regime_metrics.get('adx', 0)
            logger.info(f"‚úÖ Signal accept√© en {regime.name} (ADX={adx:.1f}): "
                       f"{strategy} {side} {symbol} force={signal_strength} confiance={signal_confidence:.2f}")
            return True
            
        except Exception as e:
            logger.error(f"Erreur dans le filtrage Enhanced: {e}")
            return True  # En cas d'erreur, laisser passer le signal
    
    def _apply_volume_boost(self, confidence: float, signals: List[Dict[str, Any]]) -> float:
        """
        Applique un boost de confiance bas√© sur le volume_ratio des signaux
        
        Args:
            confidence: Confiance actuelle du signal agr√©g√©
            signals: Liste des signaux contributeurs
            
        Returns:
            Confiance boost√©e par le volume
        """
        try:
            volume_ratios = []
            volume_scores = []
            
            # Extraire les ratios de volume et scores des m√©tadonn√©es
            for signal in signals:
                metadata = signal.get('metadata', {})
                
                # Chercher volume_ratio directement ou dans les sous-donn√©es
                volume_ratio = metadata.get('volume_ratio')
                if volume_ratio is None:
                    # Peut-√™tre dans volume_spike ou autre champ volume
                    volume_ratio = metadata.get('volume_spike', 1.0)
                
                volume_score = metadata.get('volume_score', 0.5)
                
                if volume_ratio and isinstance(volume_ratio, (int, float)):
                    volume_ratios.append(float(volume_ratio))
                
                if volume_score and isinstance(volume_score, (int, float)):
                    volume_scores.append(float(volume_score))
            
            if not volume_ratios and not volume_scores:
                return confidence  # Pas de donn√©es volume, pas de boost
            
            # Calculer le boost bas√© sur volume_ratio
            volume_boost = 1.0
            if volume_ratios:
                avg_volume_ratio = sum(volume_ratios) / len(volume_ratios)
                
                if avg_volume_ratio >= 3.0:
                    # Volume tr√®s √©lev√©: boost significatif (+15%)
                    volume_boost = 1.15
                    logger.info(f"üîä Volume tr√®s √©lev√© d√©tect√©: ratio={avg_volume_ratio:.1f} -> boost +15%")
                elif avg_volume_ratio >= 2.0:
                    # Volume √©lev√©: boost mod√©r√© (+10%)
                    volume_boost = 1.10
                    logger.info(f"üì¢ Volume √©lev√© d√©tect√©: ratio={avg_volume_ratio:.1f} -> boost +10%")
                elif avg_volume_ratio >= 1.5:
                    # Volume augment√©: boost l√©ger (+5%)
                    volume_boost = 1.05
                    logger.debug(f"üìà Volume augment√©: ratio={avg_volume_ratio:.1f} -> boost +5%")
                elif avg_volume_ratio <= 0.5:
                    # Volume tr√®s faible: p√©nalit√© (-5%)
                    volume_boost = 0.95
                    logger.debug(f"üìâ Volume faible: ratio={avg_volume_ratio:.1f} -> malus -5%")
            
            # Boost suppl√©mentaire bas√© sur volume_score des strat√©gies
            if volume_scores:
                avg_volume_score = sum(volume_scores) / len(volume_scores)
                
                if avg_volume_score >= 0.8:
                    # Score volume excellent: boost additionnel (+5%)
                    volume_boost *= 1.05
                    logger.debug(f"‚≠ê Score volume excellent: {avg_volume_score:.2f} -> boost additionnel +5%")
                elif avg_volume_score <= 0.3:
                    # Score volume faible: p√©nalit√© (-3%)
                    volume_boost *= 0.97
                    logger.debug(f"‚ö†Ô∏è Score volume faible: {avg_volume_score:.2f} -> malus -3%")
            
            # Appliquer le boost final
            boosted_confidence = confidence * volume_boost
            
            if volume_boost != 1.0:
                logger.info(f"üéöÔ∏è Boost volume global: {confidence:.3f} -> {boosted_confidence:.3f} "
                           f"(facteur: {volume_boost:.3f})")
            
            return min(1.0, boosted_confidence)  # Cap √† 1.0
            
        except Exception as e:
            logger.error(f"Erreur dans boost volume: {e}")
            return confidence  # En cas d'erreur, retourner confiance originale
    
    def _apply_multi_strategy_bonus(self, confidence: float, contributing_strategies: List[str]) -> float:
        """
        Applique un bonus de confiance si plusieurs strat√©gies convergent
        
        Args:
            confidence: Confiance actuelle
            contributing_strategies: Liste des strat√©gies contributrices
            
        Returns:
            Confiance boost√©e par la convergence multi-strat√©gies
        """
        try:
            strategy_count = len(contributing_strategies)
            
            if strategy_count >= 2:
                # Bonus +0.05 pour 2+ strat√©gies align√©es
                bonus = 0.05
                boosted_confidence = confidence + bonus
                
                logger.info(f"ü§ù Bonus multi-strat√©gies: {strategy_count} strat√©gies -> "
                           f"{confidence:.3f} + {bonus:.2f} = {boosted_confidence:.3f}")
                
                return min(1.0, boosted_confidence)  # Cap √† 1.0
            
            return confidence
            
        except Exception as e:
            logger.error(f"Erreur dans bonus multi-strat√©gies: {e}")
            return confidence
    
    def _extract_volume_summary(self, signals: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Extrait un r√©sum√© des donn√©es de volume des signaux pour les m√©tadonn√©es
        
        Args:
            signals: Liste des signaux contributeurs
            
        Returns:
            Dictionnaire avec le r√©sum√© des donn√©es volume
        """
        try:
            volume_ratios = []
            volume_scores = []
            
            for signal in signals:
                metadata = signal.get('metadata', {})
                
                volume_ratio = metadata.get('volume_ratio')
                if volume_ratio is None:
                    volume_ratio = metadata.get('volume_spike', 1.0)
                
                volume_score = metadata.get('volume_score', 0.5)
                
                if volume_ratio and isinstance(volume_ratio, (int, float)):
                    volume_ratios.append(float(volume_ratio))
                
                if volume_score and isinstance(volume_score, (int, float)):
                    volume_scores.append(float(volume_score))
            
            summary = {
                'signals_with_volume': len(volume_ratios),
                'total_signals': len(signals)
            }
            
            if volume_ratios:
                summary.update({
                    'avg_volume_ratio': round(sum(volume_ratios) / len(volume_ratios), 2),
                    'max_volume_ratio': round(max(volume_ratios), 2),
                    'min_volume_ratio': round(min(volume_ratios), 2)
                })
            
            if volume_scores:
                summary.update({
                    'avg_volume_score': round(sum(volume_scores) / len(volume_scores), 3),
                    'max_volume_score': round(max(volume_scores), 3)
                })
            
            return summary
            
        except Exception as e:
            logger.error(f"Erreur extraction r√©sum√© volume: {e}")
            return {'error': 'extraction_failed'}