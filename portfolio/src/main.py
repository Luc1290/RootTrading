"""
Point d'entr√©e principal pour le microservice Portfolio.
D√©marre l'API REST et les t√¢ches en arri√®re-plan.
Version optimis√©e avec meilleure gestion des erreurs et des caches.
"""
import argparse
import asyncio
import logging
import signal
import sys
import time
import os
import threading
from datetime import datetime, timedelta
import traceback
import requests
from typing import Dict, List, Optional, Union
import json
import concurrent.futures

import uvicorn
from fastapi import FastAPI
from contextlib import contextmanager

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from portfolio.src import binance_account_manager
from shared.src import redis_client
from shared.src.config import SYMBOLS, LOG_LEVEL, BINANCE_API_KEY, BINANCE_SECRET_KEY
from shared.src.redis_client import RedisClient

from portfolio.src.api import app
from portfolio.src.models import PortfolioModel, DBManager, SharedCache
from portfolio.src.pockets import PocketManager
from portfolio.src.binance_account_manager import BinanceAccountManager, BinanceApiError

# Configuration du logging
log_level = getattr(logging, LOG_LEVEL.upper(), logging.INFO)
logging.basicConfig(
    level=log_level,
    format='%(asctime)s - %(name)s - %(levelname)s - %(threadName)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('portfolio.log')
    ]
)
logger = logging.getLogger("portfolio")

# √âv√©nement d'arr√™t global
stop_event = threading.Event()
# Cache global des prix actuels
current_prices = {}
# Mutex pour les op√©rations sensibles
cache_lock = threading.RLock()

def notify_balance_update(balances, total_value):
    """
    Notifie les autres services d'une mise √† jour des balances via Redis.
    
    Args:
        balances: Liste des balances mises √† jour
        total_value: Valeur totale du portefeuille
    """
    try:
        # Cr√©er un message de notification avec timestamp pour versioning
        notification = {
            "event": "balance_updated",
            "timestamp": int(time.time() * 1000),
            "total_value": total_value,
            "balance_count": len(balances),
            "updated_at": datetime.now().isoformat()
        }
        
        # Publier sur un canal d√©di√© aux notifications
        redis = RedisClient()
        redis.publish("roottrading:notification:balance_updated", notification)
        logger.info(f"‚úÖ Notification de mise √† jour des balances envoy√©e via Redis")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'envoi de la notification Redis: {str(e)}")
        logger.error(traceback.format_exc())

def parse_arguments():
    """Parse les arguments de ligne de commande."""
    parser = argparse.ArgumentParser(description='Portfolio RootTrading')
    parser.add_argument(
        '--host', 
        type=str, 
        default='0.0.0.0', 
        help='H√¥te pour l\'API REST'
    )
    parser.add_argument(
        '--port', 
        type=int, 
        default=8000, 
        help='Port pour l\'API REST'
    )
    parser.add_argument(
        '--no-sync', 
        action='store_true', 
        help='D√©sactive la synchronisation automatique'
    )
    parser.add_argument(
        '--binance-sync-interval', 
        type=int, 
        default=300,  # 5 minutes
        help='Intervalle de synchronisation Binance en secondes'
    )
    parser.add_argument(
        '--db-sync-interval', 
        type=int, 
        default=300,  # 5 minutes
        help='Intervalle de synchronisation DB en secondes'
    )
    parser.add_argument(
        '--redis-enabled',
        action='store_true',
        default=True,
        help='Active l\'utilisation de Redis'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Active le mode debug'
    )
    return parser.parse_args()

def handle_market_data(channel: str, data: dict):
    """
    Traite les donn√©es de march√© re√ßues de Redis.
    Met √† jour les prix du portefeuille.
    
    Args:
        channel: Canal Redis d'o√π proviennent les donn√©es
        data: Donn√©es de march√©
    """
    global current_prices
    
    symbol = data.get('symbol')
    price = data.get('close')
    
    if not symbol or price is None:
        return
    
    # Mettre √† jour le cache de prix avec lock pour thread-safety
    with cache_lock:
        if symbol:
            current_prices[symbol] = price
    
    # Ne traiter que les chandeliers ferm√©s pour la mise √† jour de la base de donn√©es
    if not data.get('is_closed', False):
        return
    
    logger.debug(f"Mise √† jour du prix: {symbol} @ {price}")
    
    # Mettre √† jour le prix dans la base de donn√©es
    # N'effectuer cette op√©ration que p√©riodiquement pour r√©duire la charge DB
    now = datetime.now()
    minute = now.minute
    
    # N'ins√©rer dans la base de donn√©es que toutes les 5 minutes ou pour les chandeliers de 15min+
    timeframe = data.get('timeframe', '1m')
    if timeframe in ['15m', '30m', '1h', '4h', '1d'] or minute % 5 == 0:
        try:
            db = DBManager()
            
            # Ins√©rer dans market_data
            query = """
            INSERT INTO market_data (time, symbol, open, high, low, close, volume)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (time, symbol) DO UPDATE
            SET open = EXCLUDED.open,
                high = EXCLUDED.high,
                low = EXCLUDED.low,
                close = EXCLUDED.close,
                volume = EXCLUDED.volume
            """
            
            timestamp = datetime.fromtimestamp(data['start_time'] / 1000)
            
            params = (
                timestamp,
                symbol,
                data['open'],
                data['high'],
                data['low'],
                data['close'],
                data['volume']
            )
            
            db.execute_query(query, params, commit=True)
            db.close()
        
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la mise √† jour du prix: {str(e)}")
            logger.error(traceback.format_exc())

def handle_balance_update(channel: str, data: dict):
    """
    Traite les mises √† jour de solde re√ßues de Redis.
    Met √† jour les soldes du portefeuille.
    
    Args:
        channel: Canal Redis d'o√π proviennent les donn√©es
        data: Donn√©es de solde
    """
    if not isinstance(data, list):
        logger.warning(f"Format de solde invalide: {data}")
        return
    
    try:
        from shared.src.schemas import AssetBalance
        
        # Convertir en AssetBalance
        balances = []
        for balance_data in data:
            if not isinstance(balance_data, dict):
                continue
            
            # Adapter le format en fonction de la source des donn√©es
            # Format Binance: {"asset": "BTC", "free": "0.1", "locked": "0.0"}
            # Format interne: {"asset": "BTC", "disponible": "0.1", "en_ordre": "0.0", "total": "0.1", "eur_value": "4000.0"}
            
            asset = balance_data.get('asset')
            
            # V√©rifier si c'est le format Binance ou le format interne
            if 'free' in balance_data:
                free = float(balance_data.get('free', 0))
                locked = float(balance_data.get('locked', 0))
                total = free + locked
                value_usdc = balance_data.get('value_usdc')
            else:
                free = float(balance_data.get('disponible', 0))
                locked = float(balance_data.get('en_ordre', 0))
                total = float(balance_data.get('total', 0))
                value_usdc = float(balance_data.get('eur_value', 0))  # Utiliser le champ eur_value comme value_usdc
                
            balance = AssetBalance(
                asset=asset,
                free=free,
                locked=locked,
                total=total,
                value_usdc=value_usdc
            )
            balances.append(balance)
        
        if not balances:
            logger.warning("‚ö†Ô∏è Aucune balance √† mettre √† jour re√ßue")
            return
        
        # Mettre √† jour les soldes
        portfolio = PortfolioModel()
        portfolio.update_balances(balances)
        
        # Mettre √† jour les poches
        total_value = sum(b.value_usdc or 0 for b in balances)
        if total_value > 0:
            pocket_manager = PocketManager()
            pocket_manager.update_pockets_allocation(total_value)
            pocket_manager.close()
        
        portfolio.close()
        
        logger.info(f"‚úÖ Soldes mis √† jour: {len(balances)} actifs, valeur totale: {total_value:.2f} USDC")
        
        # Envoyer une notification de mise √† jour
        notify_balance_update(balances, total_value)
    
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la mise √† jour des soldes: {str(e)}")
        logger.error(traceback.format_exc())

def get_current_prices() -> Dict[str, float]:
    """
    R√©cup√®re les prix actuels des actifs.
    Utilise d'abord le cache, puis tente de r√©cup√©rer depuis la base de donn√©es.
    
    Returns:
        Dictionnaire {symbole: prix}
    """
    global current_prices
    
    # Si cache vide, essayer de remplir depuis la base de donn√©es
    with cache_lock:
        if not current_prices:
            try:
                db = DBManager()
                # R√©cup√©rer les derniers prix pour chaque symbole
                query = """
                WITH latest_data AS (
                    SELECT 
                        symbol, 
                        MAX(time) as latest_time
                    FROM 
                        market_data
                    GROUP BY 
                        symbol
                )
                SELECT 
                    m.symbol, 
                    m.close
                FROM 
                    market_data m
                JOIN 
                    latest_data l ON m.symbol = l.symbol AND m.time = l.latest_time
                """
                
                result = db.execute_query(query, fetch_all=True)
                db.close()
                
                if result:
                    # Mettre √† jour le cache
                    for row in result:
                        symbol = row['symbol']
                        price = float(row['close'])
                        current_prices[symbol] = price
            
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des prix actuels: {str(e)}")
    
    return current_prices

async def update_balances_from_binance():
    """
    R√©cup√®re et met √† jour les balances depuis Binance.
    Version am√©lior√©e avec meilleure gestion d'erreur et retry.
    
    Returns:
        True si la mise √† jour a r√©ussi, False sinon
    """
    logger.info("Mise √† jour des balances depuis Binance...")
    
    try:
        # V√©rifier si les cl√©s API sont configur√©es
        if not BINANCE_API_KEY or not BINANCE_SECRET_KEY:
            logger.warning("‚ö†Ô∏è Cl√©s API Binance non configur√©es, impossible de r√©cup√©rer les balances")
            return False
        
        logger.info(f"Cl√©s API Binance disponibles: API_KEY={BINANCE_API_KEY[:3]}...")

        # Cr√©er le gestionnaire Binance
        account_manager = BinanceAccountManager(
            api_key=BINANCE_API_KEY,
            api_secret=BINANCE_SECRET_KEY
        )
        
        # R√©cup√©rer les balances avec retry int√©gr√© dans la classe
        try:
            binance_balances = account_manager.get_balances()
            if not binance_balances:
                logger.warning("‚ö†Ô∏è Aucune balance re√ßue depuis Binance")
                return False
        except BinanceApiError as e:
            logger.error(f"‚ùå Erreur API Binance: {str(e)}")
            return False
        except Exception as e:
            logger.error(f"‚ùå Erreur inattendue: {str(e)}")
            logger.error(traceback.format_exc())
            return False
        
        logger.info(f"‚úÖ {len(binance_balances)} balances r√©cup√©r√©es depuis Binance")
        
        # Convertir en AssetBalance
        from shared.src.schemas import AssetBalance
        asset_balances = []
        
        # Prix actuel des actifs pour l'√©valuation en USDC
        prices = get_current_prices()
        
        # Si on n'a pas les prix ou pas assez, essayer de les r√©cup√©rer via l'API Binance
        if not prices or len(prices) < 20:
            try:
                prices = account_manager.get_ticker_prices()
                # Mettre √† jour le cache global avec lock pour thread-safety
                with cache_lock:
                    for symbol, price in prices.items():
                        if symbol.endswith('USDC'):
                            current_prices[symbol] = price
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des prix Binance: {str(e)}")
        
        # Utiliser la m√©thode optimis√©e pour calculer toutes les valeurs USDC
        try:
            valued_balances = account_manager.calculate_asset_values()
            
            # Convertir en objets AssetBalance
            for balance in valued_balances:
                asset_balance = AssetBalance(
                    asset=balance["asset"],
                    free=balance["free"],
                    locked=balance["locked"],
                    total=balance["total"],
                    value_usdc=balance.get("value_usdc")
                )
                asset_balances.append(asset_balance)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du calcul des valeurs en USDC: {str(e)}")
            
            # Fallback: conversion basique sans valeurs USDC
            for balance in binance_balances:
                asset_balance = AssetBalance(
                    asset=balance["asset"],
                    free=balance["free"],
                    locked=balance["locked"],
                    total=balance["total"],
                    value_usdc=None
                )
                asset_balances.append(asset_balance)
        
        # Mettre √† jour les balances dans la base de donn√©es
        db = DBManager()
        portfolio = PortfolioModel(db_manager=db)
        success = portfolio.update_balances(asset_balances)
        
        if not success:
            logger.error("‚ùå √âchec de la mise √† jour des balances dans la base de donn√©es")
            portfolio.close()
            db.close()
            return False
        
        # R√©cup√©rer le r√©sum√© pour la notification
        summary = portfolio.get_portfolio_summary()
        total_value = summary.total_value
        
        # Mise √† jour des poches
        try:
            pocket_manager = PocketManager(db_manager=db)
            pocket_success = pocket_manager.update_pockets_allocation(total_value)
            if not pocket_success:
                logger.warning("‚ö†Ô∏è Probl√®me lors de la mise √† jour des poches")
            pocket_manager.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la mise √† jour des poches: {str(e)}")
        
        portfolio.close()
        db.close()

        # Publier sur Redis
        try:
            redis = RedisClient()
            
            # ‚úÖ Ici on publie sur Redis en live (pubsub)
            redis.publish("roottrading:account:balances", asset_balances)

            # ‚úÖ Ici on √©crit durablement dans Redis
            redis.hset('account:balances', mapping={b.asset: b.total for b in asset_balances})
            total_balance = sum(b.value_usdc or 0 for b in asset_balances)
            redis.set('account:total_balance', total_balance)
            logger.info(f"‚úÖ Balances enregistr√©es durablement dans Redis. Total estim√©: {total_balance:.2f} USDC")
            
            # Envoyer une notification de mise √† jour
            notify_balance_update(asset_balances, total_balance)
            
            # Fermer la connexion Redis
            redis.close()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'enregistrement dans Redis: {str(e)}")
        
        return True

    except Exception as e:
        logger.error(f"‚ùå Erreur non g√©r√©e lors de la mise √† jour des balances: {str(e)}")
        logger.error(traceback.format_exc())
        return False

async def binance_sync_worker():
    """
    Worker asynchrone pour la synchronisation avec Binance.
    Cette version utilise asyncio pour g√©rer les op√©rations asynchrones.
    """
    logger.info("üîÑ Worker de synchronisation Binance d√©marr√©")
    
    while not stop_event.is_set():
        try:
            # Mettre √† jour les balances
            success = await update_balances_from_binance()
            
            if success:
                logger.info("‚úÖ Synchronisation Binance r√©ussie")
                # Attendre l'intervalle normal
                await asyncio.sleep(300)  # 5 minutes par d√©faut
            else:
                # Attendre moins longtemps en cas d'√©chec
                logger.warning("‚ö†Ô∏è √âchec de synchronisation Binance, nouvelle tentative dans 60 secondes")
                await asyncio.sleep(60)
                
        except asyncio.CancelledError:
            logger.info("üõë Worker de synchronisation Binance annul√©")
            break
        except Exception as e:
            logger.error(f"‚ùå Erreur dans le worker Binance: {str(e)}")
            logger.error(traceback.format_exc())
            await asyncio.sleep(60)
    
    logger.info("üõë Worker de synchronisation Binance arr√™t√©")

def binance_sync_task(interval: int):
    """
    T√¢che p√©riodique pour synchroniser les balances avec Binance.
    Version am√©lior√©e avec ex√©cution asynchrone.
    
    Args:
        interval: Intervalle entre les synchronisations en secondes
    """
    logger.info(f"D√©marrage de la t√¢che de synchronisation Binance (intervalle: {interval}s)")
    
    # Cr√©er et configurer une nouvelle boucle d'√©v√©nements
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    # Premi√®re synchronisation au d√©marrage
    try:
        loop.run_until_complete(update_balances_from_binance())
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la synchronisation initiale avec Binance: {str(e)}")
    
    # Cr√©er la t√¢che de synchronisation p√©riodique
    worker_task = None
    
    try:
        # D√©marrer le worker asynchrone
        worker_task = loop.create_task(binance_sync_worker())
        
        # Ex√©cuter la boucle d'√©v√©nements jusqu'√† ce que stop_event soit d√©fini
        while not stop_event.is_set():
            loop.run_until_complete(asyncio.sleep(1))
            
    except KeyboardInterrupt:
        logger.info("Interruption clavier d√©tect√©e dans la t√¢che Binance")
    except Exception as e:
        logger.error(f"‚ùå Erreur dans la t√¢che de synchronisation Binance: {str(e)}")
        logger.error(traceback.format_exc())
    finally:
        # Annuler la t√¢che worker si elle existe
        if worker_task and not worker_task.done():
            worker_task.cancel()
            try:
                loop.run_until_complete(worker_task)
            except asyncio.CancelledError:
                pass
            
        # Fermer la boucle d'√©v√©nements
        loop.close()
        
    logger.info("T√¢che de synchronisation Binance arr√™t√©e")

async def db_sync_worker():
    """
    Worker asynchrone pour la synchronisation avec la base de donn√©es.
    """
    logger.info("üîÑ Worker de synchronisation DB d√©marr√©")
    sync_failures = 0
    
    while not stop_event.is_set():
        try:
            # Synchroniser les poches avec les trades actifs
            logger.info("Synchronisation des poches...")
            pocket_manager = PocketManager()
            sync_success = pocket_manager.sync_with_trades()
            
            # Mettre √† jour les statistiques quotidiennes
            logger.info("Mise √† jour des statistiques...")
            db = DBManager()
            db.execute_query(
                "CALL update_daily_stats(%s)",
                (datetime.now().date(),),
                commit=True
            )
            db.close()
            
            # R√©cup√©rer la valeur totale du portefeuille pour envoyer la notification
            portfolio = PortfolioModel()
            summary = portfolio.get_portfolio_summary()
            total_value = summary.total_value
            
            # Notifier de la synchronisation
            if sync_success:
                sync_failures = 0
                logger.info("‚úÖ Synchronisation DB termin√©e avec succ√®s")
                
                # Envoyer notification de mise √† jour
                notify_balance_update(summary.balances, total_value)
                
                # Attendre l'intervalle normal
                await asyncio.sleep(300)  # 5 minutes par d√©faut
            else:
                sync_failures += 1
                logger.warning(f"‚ö†Ô∏è √âchec de la synchronisation DB (tentative {sync_failures})")
                
                # Si plusieurs √©checs cons√©cutifs, essayer une r√©conciliation compl√®te
                if sync_failures >= 3:
                    logger.warning(f"‚ö†Ô∏è {sync_failures} √©checs cons√©cutifs, tentative de r√©conciliation compl√®te...")
                    try:
                        pocket_manager.recalculate_active_cycles()
                        pocket_manager.update_pockets_allocation(total_value)
                        logger.info("‚úÖ R√©conciliation compl√®te effectu√©e")
                        sync_failures = 0
                    except Exception as e:
                        logger.error(f"‚ùå √âchec de la r√©conciliation compl√®te: {str(e)}")
                
                # Attendre moins longtemps en cas d'√©chec
                await asyncio.sleep(60)
            
            pocket_manager.close()
            portfolio.close()
            
        except asyncio.CancelledError:
            logger.info("üõë Worker de synchronisation DB annul√©")
            break
        except Exception as e:
            logger.error(f"‚ùå Erreur dans le worker DB: {str(e)}")
            logger.error(traceback.format_exc())
            sync_failures += 1
            await asyncio.sleep(60)
    
    logger.info("üõë Worker de synchronisation DB arr√™t√©")

def db_sync_task(interval: int):
    """
    T√¢che p√©riodique pour synchroniser les poches avec les trades actifs dans la base de donn√©es.
    Version am√©lior√©e avec ex√©cution asynchrone.
    
    Args:
        interval: Intervalle entre les synchronisations en secondes
    """
    logger.info(f"D√©marrage de la t√¢che de synchronisation DB (intervalle: {interval}s)")
    
    # Cr√©er et configurer une nouvelle boucle d'√©v√©nements
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    # Premi√®re synchronisation au d√©marrage
    try:
        # Synchroniser les poches avec les trades actifs
        pocket_manager = PocketManager()
        sync_success = pocket_manager.sync_with_trades()
        pocket_manager.close()
        
        if sync_success:
            logger.info("‚úÖ Synchronisation DB initiale r√©ussie")
        else:
            logger.warning("‚ö†Ô∏è √âchec de la synchronisation DB initiale")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la synchronisation DB initiale: {str(e)}")
    
    # Cr√©er la t√¢che de synchronisation p√©riodique
    worker_task = None
    
    try:
        # D√©marrer le worker asynchrone
        worker_task = loop.create_task(db_sync_worker())
        
        # Ex√©cuter la boucle d'√©v√©nements jusqu'√† ce que stop_event soit d√©fini
        while not stop_event.is_set():
            loop.run_until_complete(asyncio.sleep(1))
            
    except KeyboardInterrupt:
        logger.info("Interruption clavier d√©tect√©e dans la t√¢che DB")
    except Exception as e:
        logger.error(f"‚ùå Erreur dans la t√¢che de synchronisation DB: {str(e)}")
        logger.error(traceback.format_exc())
    finally:
        # Annuler la t√¢che worker si elle existe
        if worker_task and not worker_task.done():
            worker_task.cancel()
            try:
                loop.run_until_complete(worker_task)
            except asyncio.CancelledError:
                pass
            
        # Fermer la boucle d'√©v√©nements
        loop.close()
        
    logger.info("T√¢che de synchronisation DB arr√™t√©e")

def create_tables_if_needed():
    """
    V√©rifie et cr√©e les tables n√©cessaires si elles n'existent pas d√©j√†.
    Version optimis√©e avec transaction unique et gestion des tables suppl√©mentaires.
    """
    try:
        db = DBManager()
        
        # D√©marrer une transaction unique
        db.execute_query("BEGIN")
        
        # Liste des tables √† v√©rifier et cr√©er
        tables = {
            'portfolio_balances': """
                CREATE TABLE IF NOT EXISTS portfolio_balances (
                    id SERIAL PRIMARY KEY,
                    asset VARCHAR(10) NOT NULL,
                    free NUMERIC(24, 8) NOT NULL,
                    locked NUMERIC(24, 8) NOT NULL,
                    total NUMERIC(24, 8) NOT NULL,
                    value_usdc NUMERIC(24, 8),
                    timestamp TIMESTAMP NOT NULL DEFAULT NOW()
                );
                
                CREATE INDEX IF NOT EXISTS portfolio_balances_asset_idx ON portfolio_balances(asset);
                CREATE INDEX IF NOT EXISTS portfolio_balances_timestamp_idx ON portfolio_balances(timestamp);
                CREATE INDEX IF NOT EXISTS portfolio_balances_asset_timestamp_idx ON portfolio_balances(asset, timestamp);
            """,
            
            'capital_pockets': """
                CREATE TABLE IF NOT EXISTS capital_pockets (
                    id SERIAL PRIMARY KEY,
                    pocket_type VARCHAR(20) NOT NULL CHECK (pocket_type IN ('active', 'buffer', 'safety')),
                    allocation_percent NUMERIC(5, 2) NOT NULL,
                    current_value NUMERIC(24, 8) NOT NULL,
                    used_value NUMERIC(24, 8) NOT NULL,
                    available_value NUMERIC(24, 8) NOT NULL,
                    active_cycles INTEGER NOT NULL DEFAULT 0,
                    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
                );
                
                CREATE INDEX IF NOT EXISTS capital_pockets_type_idx ON capital_pockets(pocket_type);
            """,
            
            'pocket_transactions': """
                CREATE TABLE IF NOT EXISTS pocket_transactions (
                    id SERIAL PRIMARY KEY,
                    pocket_type VARCHAR(20) NOT NULL,
                    transaction_type VARCHAR(20) NOT NULL,
                    amount NUMERIC(24, 8) NOT NULL,
                    cycle_id VARCHAR(36) NOT NULL,
                    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
                    CONSTRAINT unique_pocket_cycle_transaction UNIQUE (pocket_type, cycle_id, transaction_type)
                );
                
                CREATE INDEX IF NOT EXISTS pocket_transactions_cycle_idx ON pocket_transactions(cycle_id);
                CREATE INDEX IF NOT EXISTS pocket_transactions_type_idx ON pocket_transactions(transaction_type);
            """,
            
            'market_data': """
                CREATE TABLE IF NOT EXISTS market_data (
                    time TIMESTAMP NOT NULL,
                    symbol VARCHAR(20) NOT NULL,
                    open NUMERIC(24, 8) NOT NULL,
                    high NUMERIC(24, 8) NOT NULL,
                    low NUMERIC(24, 8) NOT NULL,
                    close NUMERIC(24, 8) NOT NULL,
                    volume NUMERIC(24, 8) NOT NULL,
                    PRIMARY KEY (time, symbol)
                );
                
                CREATE INDEX IF NOT EXISTS market_data_symbol_idx ON market_data(symbol);
                CREATE INDEX IF NOT EXISTS market_data_time_idx ON market_data(time);
            """
        }
        
        # V√©rifier et cr√©er chaque table
        for table_name, create_query in tables.items():
            check_query = f"""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = '{table_name}'
            );
            """
            
            result = db.execute_query(check_query, fetch_one=True, commit=False)
            
            if not result or not result.get('exists', False):
                logger.warning(f"Table {table_name} non trouv√©e, cr√©ation en cours...")
                
                # Cr√©er la table
                db.execute_query(create_query, commit=False)
                logger.info(f"‚úÖ Table {table_name} cr√©√©e avec succ√®s")
        
        # Valider toutes les cr√©ations de tables
        db.execute_query("COMMIT")
        
        # V√©rifier si la proc√©dure update_daily_stats existe
        check_proc_query = """
        SELECT EXISTS (
            SELECT FROM pg_proc 
            WHERE proname = 'update_daily_stats'
        );
        """
        
        result = db.execute_query(check_proc_query, fetch_one=True)
        
        if not result or not result.get('exists', False):
            logger.warning("Proc√©dure update_daily_stats non trouv√©e, cr√©ation en cours...")
            
            # Cr√©er la proc√©dure
            create_proc_query = """
            CREATE OR REPLACE PROCEDURE update_daily_stats(p_date DATE)
            LANGUAGE plpgsql
            AS $$
            BEGIN
                -- Ins√©rer ou mettre √† jour les statistiques quotidiennes
                -- Code de la proc√©dure ici
                
                -- Exemple simple (√† adapter selon les besoins r√©els)
                INSERT INTO daily_stats (date, total_value, trade_count)
                SELECT 
                    p_date, 
                    (SELECT SUM(value_usdc) FROM portfolio_balances WHERE DATE(timestamp) = p_date),
                    (SELECT COUNT(*) FROM trade_cycles WHERE DATE(created_at) = p_date)
                ON CONFLICT (date) DO UPDATE
                SET 
                    total_value = EXCLUDED.total_value,
                    trade_count = EXCLUDED.trade_count;
                    
                -- Assurez-vous que la table daily_stats existe
                EXCEPTION WHEN undefined_table THEN
                    -- Cr√©er la table si elle n'existe pas
                    CREATE TABLE daily_stats (
                        date DATE PRIMARY KEY,
                        total_value NUMERIC(24, 8),
                        trade_count INTEGER,
                        created_at TIMESTAMP DEFAULT NOW()
                    );
                    
                    -- R√©essayer
                    INSERT INTO daily_stats (date, total_value, trade_count)
                    SELECT 
                        p_date, 
                        (SELECT SUM(value_usdc) FROM portfolio_balances WHERE DATE(timestamp) = p_date),
                        (SELECT COUNT(*) FROM trade_cycles WHERE DATE(created_at) = p_date);
            END;
            $$;
            """
            
            db.execute_query(create_proc_query, commit=True)
            logger.info("‚úÖ Proc√©dure update_daily_stats cr√©√©e avec succ√®s")
        
        db.close()
        return True
    
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la v√©rification/cr√©ation des tables: {str(e)}")
        logger.error(traceback.format_exc())
        
        # Essayer d'annuler la transaction en cas d'erreur
        try:
            db.execute_query("ROLLBACK")
        except:
            pass
            
        if db:
            db.close()
            
        return False

def subscribe_to_redis_channels():
    """
    S'abonne aux canaux Redis pour recevoir les donn√©es de march√© et les soldes.
    
    Returns:
        Client Redis ou None en cas d'erreur
    """
    try:
        redis_client = RedisClient()
        
        # S'abonner aux donn√©es de march√©
        market_channels = [f"roottrading:market:data:{symbol.lower()}" for symbol in SYMBOLS]
        redis_client.subscribe(market_channels, handle_market_data)
        logger.info(f"‚úÖ Abonn√© aux canaux de donn√©es de march√©: {len(market_channels)} canaux")
        
        # S'abonner aux mises √† jour de solde
        balance_channel = "roottrading:account:balances"
        redis_client.subscribe(balance_channel, handle_balance_update)
        logger.info(f"‚úÖ Abonn√© au canal des soldes: {balance_channel}")
        
        return redis_client
    
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'abonnement aux canaux Redis: {str(e)}")
        logger.error(traceback.format_exc())
        return None

def initialize_default_balances():
    """
    Initialise les balances avec des valeurs par d√©faut si aucune balance n'existe.
    
    Returns:
        True si l'initialisation a r√©ussi ou n'√©tait pas n√©cessaire, False sinon
    """
    try:
        db = DBManager()
        portfolio = PortfolioModel(db_manager=db)
        
        # V√©rifier si des balances existent
        balances = portfolio.get_latest_balances()
        
        # Si aucune balance n'existe, cr√©er des valeurs par d√©faut
        if not balances:
            logger.info("‚ö†Ô∏è Aucune balance trouv√©e, initialisation avec des valeurs par d√©faut...")
            from shared.src.schemas import AssetBalance
            default_balance = [
                AssetBalance(
                    asset="USDC",
                    free=100.0,
                    locked=0.0,
                    total=100.0,
                    value_usdc=100.0
                )
            ]
            portfolio.update_balances(default_balance)
            
            # Initialiser les poches avec cette valeur
            pocket_manager = PocketManager(db_manager=db)
            pocket_manager.update_pockets_allocation(100.0)
            pocket_manager.close()
            
            logger.info("‚úÖ Balances et poches initialis√©es avec des valeurs par d√©faut")
        else:
            logger.info(f"‚úÖ {len(balances)} balances existantes trouv√©es")
        
        portfolio.close()
        return True
    
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'initialisation des balances: {str(e)}")
        logger.error(traceback.format_exc())
        return False

def initialize_system():
    """
    Initialise le syst√®me: tables DB, valeurs par d√©faut, etc.
    
    Returns:
        True si l'initialisation a r√©ussi, False sinon
    """
    # V√©rifier et cr√©er les tables si n√©cessaire
    if not create_tables_if_needed():
        logger.error("‚ùå Impossible de cr√©er les tables n√©cessaires")
        return False
    
    # Initialiser les balances par d√©faut si n√©cessaire
    if not initialize_default_balances():
        logger.warning("‚ö†Ô∏è Initialisation des balances par d√©faut √©chou√©e, poursuite avec prudence")
    
    # V√©rifier la connexion Redis si activ√©e
    try:
        redis = RedisClient()
        redis.ping()
        redis.close()
        logger.info("‚úÖ Connexion Redis v√©rifi√©e")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Redis non disponible: {str(e)}")
    
    return True

async def startup_tasks():
    """
    T√¢ches √† ex√©cuter au d√©marrage de l'API.
    Cette fonction est appel√©e par le lifespan de FastAPI.
    """
    # Synchronisation initiale
    try:
        success = await update_balances_from_binance()
        if success:
            logger.info("‚úÖ Synchronisation Binance initiale r√©ussie")
        else:
            logger.warning("‚ö†Ô∏è √âchec de la synchronisation Binance initiale")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la synchronisation initiale: {str(e)}")
    
    # D√©marrer les t√¢ches p√©riodiques
    asyncio.create_task(periodic_balance_update())
    logger.info("‚úÖ T√¢ches de d√©marrage termin√©es")

async def periodic_balance_update():
    """
    Met √† jour p√©riodiquement les soldes et les poches.
    Version am√©lior√©e avec gestion des erreurs et backoff.
    """
    update_count = 0
    error_count = 0
    
    while True:
        try:
            # V√©rifier si on doit s'arr√™ter
            if stop_event.is_set():
                logger.info("üõë Arr√™t de la mise √† jour p√©riodique")
                break
                
            # R√©duire la fr√©quence √† 30 secondes pour √™tre plus r√©actif
            update_count += 1
            
            # √Ä chaque 2√®me mise √† jour (60 secondes), faire une mise √† jour compl√®te
            if update_count % 2 == 0:
                logger.info("Mise √† jour p√©riodique compl√®te des balances...")
                await update_balances_from_binance()
            
            # Synchroniser les poches
            db = DBManager()
            pocket_manager = PocketManager(db_manager=db)
            pocket_manager.sync_with_trades()
            
            # R√©cup√©rer les donn√©es pour la notification
            portfolio = PortfolioModel(db_manager=db)
            summary = portfolio.get_portfolio_summary()
            total_value = summary.total_value
            
            # Envoyer une notification de mise √† jour m√™me sans changement
            # Cela permet au coordinator de rester inform√©
            notify_balance_update(summary.balances, total_value)
            
            portfolio.close()
            pocket_manager.close()
            db.close()
            
            logger.info("‚úÖ Mise √† jour p√©riodique termin√©e")
            
            # R√©initialiser le compteur d'erreurs apr√®s un succ√®s
            error_count = 0
            
        except asyncio.CancelledError:
            logger.info("üõë T√¢che p√©riodique annul√©e")
            break
        except Exception as e:
            error_count += 1
            logger.error(f"‚ùå Erreur lors de la mise √† jour p√©riodique (#{error_count}): {str(e)}")
            logger.error(traceback.format_exc())
            
            # Backoff exponentiel en cas d'erreurs r√©p√©t√©es
            if error_count > 3:
                wait_time = min(30 * (2 ** (error_count - 3)), 300)  # Max 5 minutes
                logger.warning(f"‚ö†Ô∏è Trop d'erreurs cons√©cutives, attente de {wait_time}s avant nouvelle tentative")
                await asyncio.sleep(wait_time)
        
        # Attendre 30 secondes avant la prochaine mise √† jour
        await asyncio.sleep(30)

def shutdown_handler(signum, frame):
    """
    Gestionnaire de signal pour l'arr√™t propre.
    
    Args:
        signum: Num√©ro du signal
        frame: Frame actuelle
    """
    logger.info(f"Signal {signum} re√ßu, arr√™t en cours...")
    stop_event.set()

def main():
    """
    Fonction principale qui d√©marre le service Portfolio.
    Version am√©lior√©e avec meilleure gestion d'erreur et des v√©rifications r√©guli√®res.
    """
    # Parser les arguments
    args = parse_arguments()
    
    # Si mode debug, augmenter le niveau de log
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.info("üêû Mode debug activ√©")
    
    # Configurer les gestionnaires de signaux
    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)
    
    logger.info("üöÄ D√©marrage du service Portfolio RootTrading...")
    
    # Initialiser le syst√®me
    if not initialize_system():
        logger.error("‚ùå √âchec de l'initialisation du syst√®me, arr√™t du service")
        return
    
    # S'abonner aux canaux Redis si activ√©
    redis_client = None
    if args.redis_enabled:
        redis_client = subscribe_to_redis_channels()
    
    # Configurer le lifespan de FastAPI pour les t√¢ches de d√©marrage/arr√™t
    app.add_event_handler("startup", startup_tasks)
    
    threads = []
    
    # D√©marrer la t√¢che de synchronisation Binance
    if not args.no_sync:
        binance_thread = threading.Thread(
            target=binance_sync_task,
            args=(args.binance_sync_interval,),
            daemon=True,
            name="binance-sync"
        )
        binance_thread.start()
        threads.append(binance_thread)
        
        # D√©marrer la t√¢che de synchronisation DB
        db_thread = threading.Thread(
            target=db_sync_task,
            args=(args.db_sync_interval,),
            daemon=True,
            name="db-sync"
        )
        db_thread.start()
        threads.append(db_thread)
    
    try:
        # D√©marrer l'API FastAPI
        logger.info(f"D√©marrage de l'API REST sur {args.host}:{args.port}...")
        
        # Configuration de uvicorn avec options suppl√©mentaires
        uvicorn_config = uvicorn.Config(
            app,
            host=args.host,
            port=args.port,
            log_level="info",
            workers=1,
            limit_concurrency=100,  # Limiter la concurrence
            timeout_keep_alive=65  # Fermer les connexions inactives apr√®s 65s
        )
        
        # D√©marrer le serveur
        server = uvicorn.Server(uvicorn_config)
        server.run()
    
    except KeyboardInterrupt:
        logger.info("Interruption clavier d√©tect√©e")
    except Exception as e:
        logger.error(f"‚ùå Erreur critique: {str(e)}")
        logger.error(traceback.format_exc())
    finally:
        # Arr√™ter proprement
        logger.info("Arr√™t du service Portfolio...")
        stop_event.set()
        
        # Attendre l'arr√™t des threads de synchronisation
        for thread in threads:
            if thread.is_alive():
                logger.info(f"Attente de l'arr√™t du thread {thread.name}...")
                thread.join(timeout=5.0)
                if thread.is_alive():
                    logger.warning(f"‚ö†Ô∏è Le thread {thread.name} ne s'est pas arr√™t√© proprement")
        
        # Fermer la connexion Redis
        if redis_client:
            redis_client.close()
            
        # Vider explicitement les caches
        SharedCache.clear()
        
        logger.info("‚úÖ Service Portfolio arr√™t√© avec succ√®s")

if __name__ == "__main__":
    main()